# Copyright 2024 Flant JSC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

name: Build and push for dev

env:
  MODULES_REGISTRY: ${{ vars.DEV_REGISTRY }}
  CI_COMMIT_REF_NAME: ${{ github.ref_name }}
  MODULES_MODULE_NAME: ${{ vars.MODULE_NAME }}
  MODULES_MODULE_SOURCE: ${{ vars.DEV_MODULE_SOURCE }}
  MODULES_REGISTRY_LOGIN: ${{ vars.DEV_MODULES_REGISTRY_LOGIN }}
  MODULES_REGISTRY_PASSWORD: ${{ secrets.DEV_MODULES_REGISTRY_PASSWORD }}
  GO_VERSION: "1.22.7"
  GOLANGCI_LINT_VERSION: "1.64.8"
  SOURCE_REPO: "${{secrets.SOURCE_REPO}}"

on:
  workflow_dispatch:
    inputs:
      pr_number:
        description: |
          Pull request number, like 563, or leave empty and choose a branch
          For branches main, release-*, tag will be generated as branch name
        required: false
        type: number
  pull_request:
    types: [opened, reopened, synchronize, labeled, unlabeled]
  push:
    branches:
      - main
      - release-*

defaults:
  run:
    shell: bash

concurrency:
  group: "${{ github.workflow }}-${{ github.event.number || github.ref }}"
  cancel-in-progress: true

jobs:
  set_vars:
    runs-on: ubuntu-latest
    name: Set MODULES_MODULE_TAG
    outputs:
      modules_module_tag: ${{ steps.modules_module_tag.outputs.MODULES_MODULE_TAG }}
      module_edition: ${{ steps.modules_module_tag.outputs.MODULE_EDITION }}
      runner_type: ${{ steps.modules_module_tag.outputs.RUNNER_TYPE }}
    steps:
      - name: Get Pull Request Labels
        id: get-labels
        uses: actions/github-script@v7
        with:
          script: |
            if (context.eventName === "pull_request" || context.eventName === "pull_request_target" ) {
              const prNumber = context.payload.pull_request.number;
              const { data: labels } = await github.rest.issues.listLabelsOnIssue({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: prNumber,
              });
              return labels.map(label => label.name);
            } else {
              return [];
            }
          result-encoding: string

      - name: Set vars
        id: modules_module_tag
        run: |
          if [[ "${{ github.ref_name }}" == 'main' ]]; then
            MODULES_MODULE_TAG="${{ github.ref_name }}"
          elif [[ "${{ github.ref_name }}" =~ ^release-[0-9]+\.[0-9]+ ]]; then
            MODULES_MODULE_TAG="${{ github.ref_name }}"
          elif [[ -n "${{ github.event.pull_request.number }}" ]]; then
            MODULES_MODULE_TAG="pr${{ github.event.pull_request.number }}"
          elif [[ -n "${{ github.event.inputs.pr_number }}" ]]; then
            MODULES_MODULE_TAG="pr${{ github.event.inputs.pr_number }}"
          else
            echo "::error title=Module image tag is required::Can't detect module tag from workflow context. Dev build uses branch name as tag for main and release branches, and PR number for builds from pull requests. Check workflow for correctness."
            exit 1
          fi

          echo "MODULES_MODULE_TAG=$MODULES_MODULE_TAG" >> "$GITHUB_OUTPUT"

          # Slect edition for build, default EE
          if echo "${{ steps.get-labels.outputs.result }}" | grep -q "edition/ce"; then
            echo "MODULE_EDITION=CE" >> $GITHUB_OUTPUT
          else
            echo "MODULE_EDITION=EE" >> "$GITHUB_OUTPUT"
          fi

          # Select runner
          if echo "${{ steps.get-labels.outputs.result }}" | grep -q "build/github/ubuntu"; then
            echo "RUNNER_TYPE=[\"ubuntu-22.04\"]" >> "$GITHUB_OUTPUT"
          elif echo "${{ steps.get-labels.outputs.result }}" | grep -q "build/self-hosted/regular"; then
            echo "RUNNER_TYPE=[\"self-hosted\", \"regular\"]" >> "$GITHUB_OUTPUT"
          else
            echo "RUNNER_TYPE=[\"self-hosted\", \"large\"]" >> "$GITHUB_OUTPUT"
          fi

  show_dev_manifest:
    runs-on: ubuntu-latest
    name: Show manifest
    needs: set_vars
    env:
      MODULES_MODULE_TAG: ${{needs.set_vars.outputs.modules_module_tag}}
    steps:
      - name: Show dev config
        run: |
          cat << OUTER
          Create ModuleConfig and ModulePullOverride resources to test this MR:
          cat <<EOF | kubectl apply -f -
          ---
          apiVersion: deckhouse.io/v1alpha1
          kind: ModulePullOverride
          metadata:
            name: ${MODULES_MODULE_NAME}
          spec:
            imageTag: ${MODULES_MODULE_TAG}
            source: deckhouse

          ---
          apiVersion: deckhouse.io/v1alpha1
          kind: ModuleConfig
          metadata:
            name: ${MODULES_MODULE_NAME}
          spec:
            enabled: true
            settings:
              dvcr:
                storage:
                  type: PersistentVolumeClaim
                  persistentVolumeClaim:
                    size: 50G
              virtualMachineCIDRs:
                - 10.66.10.0/24
                - 10.66.20.0/24
                - 10.66.30.0/24
            version: 1
          EOF

          Or patch an existing ModulePullOverride:

          kubectl patch mpo ${MODULES_MODULE_NAME} --type merge -p '{"spec":{"imageTag":"${MODULES_MODULE_TAG}"}}'

          OUTER

  lint_go:
    runs-on: ubuntu-22.04
    name: Run go linter
    steps:
      - name: Set up Go ${{ env.GO_VERSION }}
        uses: actions/setup-go@v5
        with:
          go-version: "${{ env.GO_VERSION }}"

      - name: Install Task
        uses: arduino/setup-task@v2
        with:
          version: 3.37.2

      - uses: actions/checkout@v4
        with:
          ref: ${{ github.event.pull_request.head.sha || github.sha }}

      - name: Install golangci-lint
        run: |
          echo "Installing golangci-lint..."
          curl -sSfL https://raw.githubusercontent.com/golangci/golangci-lint/master/install.sh | sh -s -- -b $(go env GOPATH)/bin v${{ env.GOLANGCI_LINT_VERSION}}
          echo "$(go env GOPATH)/bin" >> $GITHUB_PATH
          echo "golangci-lint v${{ env.GOLANGCI_LINT_VERSION}} installed successfully!"

      - name: Lint all directories with golangci-lint
        id: linters
        # continue-on-error: true
        shell: bash
        run: |
          # Find directories containing .golangci.yaml
          mapfile -t config_dirs < <(find . -type f -name '.golangci.yaml' -printf '%h\0' | xargs -0 -n1 | sort -u)
          count=${#config_dirs[@]}
          echo "::notice title=Lint Setup::🔍 Found $count directories with linter configurations"

          report=""
          error_count=0
          find_errors=0

          for dir in "${config_dirs[@]}"; do
            # echo "::group::📂 Linting directory: $dir"
            # cd "$dir" || { echo "::error::Failed to access directory $dir"; exit 1; }

            cd "$dir" || { echo "::error::Failed to access directory $dir"; continue; }
            
            # Run linter with multiple formats
            
            output=$(golangci-lint run --out-format=json 2>/dev/null | jq '{warning: .Report.Warnings, error: .Report.Error}' || true)
            find_errors=$(echo $output | jq '.error | select(.!=null)' | wc -l)
            
            # Track errors
            if [ $find_errors -ne 0 ]; then
              error_count=$(( error_count + 1 ))
              echo "::group::📂 Linting directory ❌: $dir"
            else
              echo "::group::📂 Linting directory ✅: $dir"
            fi
            
            report_out_warning=$(echo $output | jq '.warning')
            report_out_error=$(echo $output | jq '.error')

            # Build report section
            report+="\n\n### Directory: $dir\n"
            report+="Find Errors: $find_errors\n"
            report+="Output:\n\`\`\`\n$report_out_warning\n$report_out_error\n\`\`\`\n"
            report+="---\n"

            cd - &>/dev/null
            
            if [ $find_errors -ne 0 ]; then
              echo -e "⚠️ Warnings:\n$report_out_warning"
              echo -e "❌ Errors:\n$report_out_error\n"
            else
              echo -e "✅ All check passed\n"
            fi

            echo "::endgroup::"
          done

          echo "directory_count=$count" >> "$GITHUB_OUTPUT"

          has_errors=$( [[ "$error_count" -gt 0 ]] && echo true || echo false)
          echo "has_errors=$has_errors" >> "$GITHUB_OUTPUT"

          if [ $error_count -gt 0 ]; then
            exit 1
          fi

      - name: Final status check
        if: always()
        run: |
          if ${{ steps.linters.outputs.has_errors }}; then
            echo "::error::🔥 Lint errors found in $error_count directories. Check step 'Lint all directories with golangci-lint' for details."
            exit 1
          else
            echo "::notice::✅ All linters passed successfully in ${{ steps.linters.outputs.directory_count }} directories"
          fi

  lint_yaml:
    runs-on: ubuntu-latest
    name: Run yaml linter
    steps:
      - name: Install Task
        uses: arduino/setup-task@v2
        with:
          version: 3.37.2

      - uses: actions/checkout@v4
        with:
          ref: ${{ github.event.pull_request.head.sha || github.sha }}

      - name: Lint yaml with prettier
        run: task -p lint:prettier:yaml

  test:
    runs-on: ubuntu-22.04
    name: Run unit test
    steps:
      - name: Set up Go ${{ env.GO_VERSION }}
        uses: actions/setup-go@v5
        with:
          go-version: "${{ env.GO_VERSION }}"

      - name: Install Task
        uses: arduino/setup-task@v2
        with:
          version: 3.37.2

      - uses: actions/checkout@v4
        with:
          ref: ${{ github.event.pull_request.head.sha || github.sha }}

      - name: Run test hooks
        run: |
          task hooks:test

      - name: Run unit test virtualization-controller
        run: |
          task virtualization-controller:init
          task virtualization-controller:test:unit

  dev_setup_build:
    runs-on: ${{ fromJSON(needs.set_vars.outputs.runner_type)}}
    name: Build and Push images
    needs: set_vars
    env:
      MODULES_MODULE_TAG: ${{needs.set_vars.outputs.modules_module_tag}}
      MODULE_EDITION: ${{needs.set_vars.outputs.module_edition}}
      WERF_VIRTUAL_MERGE: 0
    steps:
      - name: Print vars
        run: |
          echo MODULES_REGISTRY=$MODULES_REGISTRY
          echo CI_COMMIT_REF_NAME=$CI_COMMIT_REF_NAME
          echo MODULES_MODULE_NAME=$MODULES_MODULE_NAME
          echo MODULES_MODULE_SOURCE=$MODULES_MODULE_SOURCE
          echo MODULES_MODULE_TAG=$MODULES_MODULE_TAG
          echo MODULE_EDITION=$MODULE_EDITION

      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: ${{ github.event.pull_request.head.sha || github.sha }}

      - name: Remove unwanted software
        if: ${{ !contains(needs.set_vars.outputs.runner_type, 'self-hosted') }}
        uses: ./.github/actions/remove-unwanted-software

      - uses: deckhouse/modules-actions/setup@v2
        with:
          registry: ${{ vars.DEV_REGISTRY }}
          registry_login: ${{ vars.DEV_MODULES_REGISTRY_LOGIN }}
          registry_password: ${{ secrets.DEV_MODULES_REGISTRY_PASSWORD }}

      - uses: deckhouse/modules-actions/build@v2
        with:
          module_source: ${{ vars.DEV_MODULE_SOURCE}}
          module_name: ${{ vars.MODULE_NAME }}
          module_tag: "$MODULES_MODULE_TAG"

  pull_request_info:
    name: Get PR info
    runs-on: ubuntu-latest
    outputs:
      labels: ${{ steps.pr_labels.outputs.labels }}
    steps:
      - name: Get PR labels
        id: pr_labels
        uses: actions/github-script@v6.4.1
        with:
          script: |
            const prNumber = context.payload.pull_request.number;
            const { data: labels } = await github.rest.issues.listLabelsOnIssue({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: prNumber
            });
            core.setOutput('labels', JSON.stringify(labels));

  set_e2e_requirement_status:
    name: Set 'waiting for e2e' commit status
    needs:
      - pull_request_info
    runs-on: ubuntu-latest
    steps:
      - name: Checkout sources
        uses: actions/checkout@v3.5.2
      - name: Set commit status after e2e run
        id: set_e2e_requirement_status
        uses: actions/github-script@v6.4.1
        env:
          STATUS_TARGET_COMMIT: ${{ github.event.pull_request.head.sha }}
          PR_LABELS: ${{ needs.pull_request_info.outputs.labels }}
        with:
          github-token: ${{secrets.RELEASE_PLEASE_TOKEN}}
          script: |
            const e2eStatus = require('./.github/scripts/js/e2e-commit-status');
            await e2eStatus.setInitialStatus({github, context, core});

  cve_scan_on_pr:
    name: Trivy images check
    runs-on: ${{ fromJSON(needs.set_vars.outputs.runner_type)}}
    needs:
      - set_vars
      - dev_setup_build
    steps:
      - uses: actions/checkout@v4
      - uses: deckhouse/modules-actions/cve_scan@v2
        with:
          image: ${{ vars.DEV_MODULE_SOURCE }}/${{ vars.MODULE_NAME }}
          tag: ${{needs.set_vars.outputs.modules_module_tag}}
          module_name: ${{ vars.MODULE_NAME }}
          dd_url: ${{vars.DEFECTDOJO_HOST}}
          dd_token: ${{secrets.DEFECTDOJO_API_TOKEN}}
          trivy_registry: ${{ vars.TRIVY_REGISTRY }}
          trivy_registry_user: ${{ vars.PROD_MODULES_REGISTRY_LOGIN }}
          trivy_registry_password: ${{ secrets.PROD_MODULES_REGISTRY_PASSWORD }}
          deckhouse_private_repo: ${{vars.DECKHOUSE_PRIVATE_REPO}}

  skip_e2e:
    if: ${{ github.event.label.name == 'skip/e2e' }}
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Skip E2E tests
        id: skip_e2e
        uses: actions/github-script@v6
        with:
          script: |
            const e2eStatus = require('./.github/scripts/js/e2e-commit-status');
            e2eStatus.onLabeledForSkip({
              github,
              context,
              core,
              labeled: true,
              commitSha: context.payload.pull_request.head.sha
            })

  run_e2e:
    if: ${{ github.event.label.name == 'e2e/run' }}
    name: Run E2E tests
    runs-on: ubuntu-latest
    needs:
      - dev_setup_build
      - set_e2e_requirement_status
      - set_vars
    steps:
      - uses: actions/checkout@v4
      - name: Select user
        id: select_user
        uses: actions/github-script@v6
        env:
          KUBECONFIGS: ${{ secrets.K8S_CLUSTER_SECRET }}
        with:
          script: |
            const ci = require('./.github/scripts/js/ci');
            const userId = await ci.getClusterUser({context, core});
            const fs = require('fs');
            const path = require('path');
            // core.setOutput("user_id", user_id)
            // core.exportVariable("user_id", user_id);
            const kubeconfigs = JSON.parse(process.env.KUBECONFIGS);
            const kubeconfig = kubeconfigs.find(config => config.id === userId)?.kubeconfig;
            if (!kubeconfig) {
              core.setFailed(`No kubeconfig found for user with ID ${userId}.`);
            } else {
              core.info(`Found kubeconfig for user with ID ${userId}`);
              const runnerTempDir = process.env['RUNNER_TEMP'];
              const kubeconfigFile = path.join(runnerTempDir, `kubeconfig_${Date.now()}`);
              fs.writeFileSync(kubeconfigFile, kubeconfig);
              fs.chmodSync(kubeconfigFile, '600');
              core.exportVariable('KUBECONFIG', kubeconfigFile)

              // core.setSecret(kubeconfig);
              // core.setOutput('kubeconfig_data', kubeconfig);
            }

      - name: Install Deckhouse-cli
        run: |
          echo "Install d8"
          curl -fsSL -o d8-install.sh https://raw.githubusercontent.com/deckhouse/deckhouse-cli/main/d8-install.sh
          bash d8-install.sh

      - name: Set up Go ${{ env.GO_VERSION }}
        uses: actions/setup-go@v5
        with:
          go-version: "${{ env.GO_VERSION }}"

      - name: Install Task
        uses: arduino/setup-task@v2

      - name: Install ginkgo
        working-directory: ./tests/e2e/
        run: |
          echo "Install ginkgo"
          GINKGO_VERSION=$(go list -f '{{.Version}}' -m github.com/onsi/ginkgo/v2)
          go install "github.com/onsi/ginkgo/v2/ginkgo@${GINKGO_VERSION}"

      - uses: deckhouse/modules-actions/setup@v2
        with:
          registry: ${{ vars.DEV_REGISTRY }}
          registry_login: ${{ vars.DEV_MODULES_REGISTRY_LOGIN }}
          registry_password: ${{ secrets.DEV_MODULES_REGISTRY_PASSWORD }}

      - name: Checkout cluster to revision
        env:
          v12n_tag: pr${{ github.event.pull_request.number }}
        run: |
          d8 k patch mpo virtualization --type merge -p "{\"spec\":{\"imageTag\":\"$v12n_tag\"}}" 
          images_hash=$(crane export "dev-registry.deckhouse.io/sys/deckhouse-oss/modules/virtualization:$v12n_tag" - | tar -Oxf - images_digests.json)
          v12n_pods=$(kubectl -n d8-virtualization get pods -o json | jq -c)
          retry_count=0
          max_retries=120
          sleep_interval=5 

          while true; do
            all_hashes_found=true

            # Fetch current pods information
            v12n_pods=$(kubectl -n d8-virtualization get pods -o json | jq -c)

            # Process each image entry
            while IFS= read -r image_entry; do
              image=$(echo "$image_entry" | jq -r '.key')
              hash=$(echo "$image_entry" | jq -r '.value')

              if [[ "${image,,}" =~ (libguestfs|predeletehook) ]]; then
                continue
              fi

              if echo "$v12n_pods" | grep -q "$hash"; then
                echo "- ✅ $image $hash"
              else
                echo "- 🟥 $image $hash"
                all_hashes_found=false
              fi
            done < <(echo "$images_hash" | jq -c '. | to_entries | sort_by(.key)[]')

            # If all hashes are found, break the loop
            if [ "$all_hashes_found" = true ]; then
              echo "All image hashes found in pods."
              break
            fi 

            retry_count=$((retry_count + 1))
            echo "Some hashes are missing, rechecking... Attempt: $retry_count"

            # Check if the retry limit has been reached
            if [ "$retry_count" -ge "$max_retries" ]; then
              echo "Error: Timeout reached after $((retry_count * sleep_interval)) seconds. Some image hashes are still missing."
              exit 1
            fi
            # Wait for the specified interval before retrying
            sleep "$sleep_interval"
          done

      - name: Download dependencies
        working-directory: ./tests/e2e/
        run: |
          echo "Download dependencies"
          go mod download

      - name: Run E2E
        id: e2e-tests
        working-directory: ./tests/e2e/
        run: |
          task run -v

      - name: Cleanup E2E resources on cancel
        if: always() && (steps.e2e-tests.outcome == 'cancelled' || steps.e2e-tests.outcome == 'failure')
        id: e2e-tests-cleanup
        working-directory: ./tests/e2e/
        run: |
          task cleanup

  last_comment:
    name: Update comment on finish
    needs:
      - run_e2e
    runs-on: ubuntu-latest
    steps:
      - name: Checkout sources
        uses: actions/checkout@v3.5.2

      - name: Set commit status after e2e run
        id: set_e2e_requirement_status
        if: ${{ always() }}
        uses: actions/github-script@v6.4.1
        env:
          JOB_STATUS: ${{ job.status }}
          STATUS_TARGET_COMMIT: ${{ github.event.pull_request.head.sha }}
        with:
          github-token: ${{secrets.RELEASE_PLEASE_TOKEN}}
          script: |
            const e2eStatus = require('./.github/scripts/js/e2e-commit-status');

            await e2eStatus.setStatusAfterE2eRun({github, context, core});

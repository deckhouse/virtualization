<?xml version="1.0" encoding="UTF-8"?>
  <testsuites tests="215" disabled="191" errors="1" failures="10" time="7563.763960459">
      <testsuite name="Tests" package="/Users/antont/ansible_deckhouse/virtualization-full/tests/e2e" tests="215" disabled="0" skipped="191" errors="1" failures="10" time="7563.763960459" timestamp="2025-10-12T15:57:52">
          <properties>
              <property name="SuiteSucceeded" value="false"></property>
              <property name="SuiteHasProgrammaticFocus" value="false"></property>
              <property name="SpecialSuiteFailureReason" value="Interrupted by User"></property>
              <property name="SuiteLabels" value="[]"></property>
              <property name="RandomSeed" value="1760273858"></property>
              <property name="RandomizeAllSpecs" value="false"></property>
              <property name="LabelFilter" value=""></property>
              <property name="FocusStrings" value=""></property>
              <property name="SkipStrings" value=""></property>
              <property name="FocusFiles" value=""></property>
              <property name="SkipFiles" value=""></property>
              <property name="FailOnPending" value="false"></property>
              <property name="FailOnEmpty" value="false"></property>
              <property name="FailFast" value="false"></property>
              <property name="FlakeAttempts" value="0"></property>
              <property name="DryRun" value="false"></property>
              <property name="ParallelTotal" value="1"></property>
              <property name="OutputInterceptorMode" value=""></property>
          </properties>
          <testcase name="[SynchronizedBeforeSuite]" classname="Tests" status="passed" time="4.080972791">
              <system-err>&gt; Enter [SynchronizedBeforeSuite] TOP-LEVEL - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/e2e_test.go:137 @ 10/12/25 15:57:52.653&#xA;&lt; Exit [SynchronizedBeforeSuite] TOP-LEVEL - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/e2e_test.go:137 @ 10/12/25 15:57:56.734 (4.081s)&#xA;&gt; Enter [SynchronizedBeforeSuite] TOP-LEVEL - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/e2e_test.go:137 @ 10/12/25 15:57:56.734&#xA;&lt; Exit [SynchronizedBeforeSuite] TOP-LEVEL - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/e2e_test.go:137 @ 10/12/25 15:57:56.734 (0s)&#xA;</system-err>
          </testcase>
          <testcase name="[It] IPAM vmip with type Auto Creates vmip with type Auto" classname="Tests" status="passed" time="4.429212208">
              <system-err>&gt; Enter [BeforeAll] IPAM - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/ipam_test.go:50 @ 10/12/25 15:57:56.738&#xA;&lt; Exit [BeforeAll] IPAM - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/ipam_test.go:50 @ 10/12/25 15:58:00.466 (3.728s)&#xA;&gt; Enter [BeforeEach] IPAM - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/ipam_test.go:65 @ 10/12/25 15:58:00.466&#xA;&lt; Exit [BeforeEach] IPAM - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/ipam_test.go:65 @ 10/12/25 15:58:00.466 (0s)&#xA;&gt; Enter [It] Creates vmip with type Auto - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/ipam_test.go:80 @ 10/12/25 15:58:00.466&#xA;STEP: Create a vmip automatically and check its binding with a lease - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/ipam_test.go:81 @ 10/12/25 15:58:00.466&#xA;STEP: Remove label from the lease - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/ipam_test.go:87 @ 10/12/25 15:58:00.828&#xA;STEP: Wait for the label to be restored by the controller - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/ipam_test.go:96 @ 10/12/25 15:58:00.941&#xA;&lt; Exit [It] Creates vmip with type Auto - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/ipam_test.go:80 @ 10/12/25 15:58:01.167 (701ms)&#xA;&gt; Enter [AfterEach] IPAM - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/ipam_test.go:157 @ 10/12/25 15:58:01.167&#xA;&lt; Exit [AfterEach] IPAM - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/ipam_test.go:157 @ 10/12/25 15:58:01.167 (0s)&#xA;</system-err>
          </testcase>
          <testcase name="[It] IPAM vmip with type Static Creates vmip with type Static" classname="Tests" status="passed" time="2.284170417">
              <system-err>&gt; Enter [BeforeEach] IPAM - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/ipam_test.go:65 @ 10/12/25 15:58:01.168&#xA;&lt; Exit [BeforeEach] IPAM - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/ipam_test.go:65 @ 10/12/25 15:58:01.168 (0s)&#xA;&gt; Enter [It] Creates vmip with type Static - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/ipam_test.go:108 @ 10/12/25 15:58:01.168&#xA;STEP: Create an intermediate vmip automatically to allocate a new ip address - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/ipam_test.go:109 @ 10/12/25 15:58:01.168&#xA;STEP: Delete the intermediate vmip automatically and check that the lease is released - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/ipam_test.go:115 @ 10/12/25 15:58:02.153&#xA;STEP: Reuse the released lease with a static vmip - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/ipam_test.go:124 @ 10/12/25 15:58:02.439&#xA;STEP: Delete the static vmip and lease, then create another static vmip with this ip address - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/ipam_test.go:132 @ 10/12/25 15:58:02.807&#xA;&lt; Exit [It] Creates vmip with type Static - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/ipam_test.go:108 @ 10/12/25 15:58:03.452 (2.284s)&#xA;&gt; Enter [AfterEach] IPAM - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/ipam_test.go:157 @ 10/12/25 15:58:03.452&#xA;&lt; Exit [AfterEach] IPAM - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/ipam_test.go:157 @ 10/12/25 15:58:03.452 (0s)&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineAffinityAndToleration When the virtualization resources are applied: result should be succeeded" classname="Tests" status="passed" time="10.8212715">
              <system-err>&gt; Enter [BeforeAll] VirtualMachineAffinityAndToleration - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/affinity_toleration_test.go:59 @ 10/12/25 15:58:03.452&#xA;&lt; Exit [BeforeAll] VirtualMachineAffinityAndToleration - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/affinity_toleration_test.go:59 @ 10/12/25 15:58:04.978 (1.526s)&#xA;&gt; Enter [It] result should be succeeded - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/affinity_toleration_test.go:79 @ 10/12/25 15:58:04.978&#xA;&lt; Exit [It] result should be succeeded - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/affinity_toleration_test.go:79 @ 10/12/25 15:58:14.273 (9.295s)&#xA;&gt; Enter [AfterEach] VirtualMachineAffinityAndToleration - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/affinity_toleration_test.go:72 @ 10/12/25 15:58:14.273&#xA;&lt; Exit [AfterEach] VirtualMachineAffinityAndToleration - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/affinity_toleration_test.go:72 @ 10/12/25 15:58:14.273 (0s)&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineAffinityAndToleration When the virtualization resources are applied: checks the resources phase" classname="Tests" status="failed" time="1008.243455334">
              <failure message="should observe resources in &#39;&#39;jsonpath={.status.phase}=Ready&#39;&#39; state before 16m40s timeout&#xA;Expected&#xA;    &lt;[]string | len:1, cap:1&gt;: [&#xA;        &#34;cmd: kubectl wait virtualimages.virtualization.deckhouse.io head-5073ae15-vi-ubuntu-http --namespace head-5073ae15-end-to-end-affinity-toleration --for=&#39;jsonpath={.status.phase}=Ready&#39; --timeout=16m40s\nstderr: error: timed out waiting for the condition on virtualimages/head-5073ae15-vi-ubuntu-http\n\nwaited for: &#39;jsonpath={.status.phase}=Ready&#39;&#34;,&#xA;    ]&#xA;to be empty" type="failed">[FAILED] should observe resources in &#39;&#39;jsonpath={.status.phase}=Ready&#39;&#39; state before 16m40s timeout&#xA;Expected&#xA;    &lt;[]string | len:1, cap:1&gt;: [&#xA;        &#34;cmd: kubectl wait virtualimages.virtualization.deckhouse.io head-5073ae15-vi-ubuntu-http --namespace head-5073ae15-end-to-end-affinity-toleration --for=&#39;jsonpath={.status.phase}=Ready&#39; --timeout=16m40s\nstderr: error: timed out waiting for the condition on virtualimages/head-5073ae15-vi-ubuntu-http\n\nwaited for: &#39;jsonpath={.status.phase}=Ready&#39;&#34;,&#xA;    ]&#xA;to be empty&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/affinity_toleration_test.go:89 @ 10/12/25 16:14:56.36&#xA;</failure>
              <system-err>&gt; Enter [It] checks the resources phase - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/affinity_toleration_test.go:87 @ 10/12/25 15:58:14.273&#xA;STEP: `VirtualImages` should be in the &#34;Ready&#34; phase - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/affinity_toleration_test.go:88 @ 10/12/25 15:58:14.273&#xA;END STEP: `VirtualImages` should be in the &#34;Ready&#34; phase - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/affinity_toleration_test.go:88 @ 10/12/25 16:14:56.359 (16m42.098s)&#xA;[FAILED] should observe resources in &#39;&#39;jsonpath={.status.phase}=Ready&#39;&#39; state before 16m40s timeout&#xA;Expected&#xA;    &lt;[]string | len:1, cap:1&gt;: [&#xA;        &#34;cmd: kubectl wait virtualimages.virtualization.deckhouse.io head-5073ae15-vi-ubuntu-http --namespace head-5073ae15-end-to-end-affinity-toleration --for=&#39;jsonpath={.status.phase}=Ready&#39; --timeout=16m40s\nstderr: error: timed out waiting for the condition on virtualimages/head-5073ae15-vi-ubuntu-http\n\nwaited for: &#39;jsonpath={.status.phase}=Ready&#39;&#34;,&#xA;    ]&#xA;to be empty&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/affinity_toleration_test.go:89 @ 10/12/25 16:14:56.36&#xA;&lt; Exit [It] checks the resources phase - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/affinity_toleration_test.go:87 @ 10/12/25 16:14:56.36 (16m42.098s)&#xA;&gt; Enter [AfterEach] VirtualMachineAffinityAndToleration - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/affinity_toleration_test.go:72 @ 10/12/25 16:14:56.36&#xA;The list of pods is empty; nothing to dump.&#xA;&lt; Exit [AfterEach] VirtualMachineAffinityAndToleration - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/affinity_toleration_test.go:72 @ 10/12/25 16:15:02.505 (6.145s)&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineAffinityAndToleration When the virtual machines agents are ready checks the `status.nodeName` field of the `VirtualMachines`" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/affinity_toleration_test.go:120 @ 10/12/25 16:15:02.505&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineAffinityAndToleration When the virtual machine `node-selector` agent is ready sets the `spec.nodeSelector` field" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/affinity_toleration_test.go:283 @ 10/12/25 16:15:02.505&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineAffinityAndToleration When the virtual machine `node-affinity` agent is ready sets the `spec.affinity.nodeAffinity` field" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/affinity_toleration_test.go:372 @ 10/12/25 16:15:02.506&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineAffinityAndToleration When test is completed deletes test case resources" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/affinity_toleration_test.go:467 @ 10/12/25 16:15:02.506&#xA;</system-err>
          </testcase>
          <testcase name="[It] ImporterNetworkPolicy Project creates project" classname="Tests" status="passed" time="1.490021667">
              <system-err>&gt; Enter [BeforeAll] ImporterNetworkPolicy - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/importer_network_policy_test.go:36 @ 10/12/25 16:15:02.506&#xA;&lt; Exit [BeforeAll] ImporterNetworkPolicy - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/importer_network_policy_test.go:36 @ 10/12/25 16:15:02.507 (2ms)&#xA;&gt; Enter [BeforeEach] ImporterNetworkPolicy - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/importer_network_policy_test.go:43 @ 10/12/25 16:15:02.507&#xA;&lt; Exit [BeforeEach] ImporterNetworkPolicy - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/importer_network_policy_test.go:43 @ 10/12/25 16:15:02.507 (0s)&#xA;&gt; Enter [It] creates project - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/importer_network_policy_test.go:61 @ 10/12/25 16:15:02.507&#xA;&lt; Exit [It] creates project - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/importer_network_policy_test.go:61 @ 10/12/25 16:15:03.996 (1.488s)&#xA;&gt; Enter [AfterEach] ImporterNetworkPolicy - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/importer_network_policy_test.go:54 @ 10/12/25 16:15:03.996&#xA;&lt; Exit [AfterEach] ImporterNetworkPolicy - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/importer_network_policy_test.go:54 @ 10/12/25 16:15:03.996 (0s)&#xA;</system-err>
          </testcase>
          <testcase name="[It] ImporterNetworkPolicy Project checks project readiness" classname="Tests" status="passed" time="2.750370375">
              <system-err>&gt; Enter [BeforeEach] ImporterNetworkPolicy - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/importer_network_policy_test.go:43 @ 10/12/25 16:15:03.996&#xA;&lt; Exit [BeforeEach] ImporterNetworkPolicy - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/importer_network_policy_test.go:43 @ 10/12/25 16:15:03.996 (0s)&#xA;&gt; Enter [It] checks project readiness - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/importer_network_policy_test.go:72 @ 10/12/25 16:15:03.996&#xA;STEP: Project should be deployed - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/importer_network_policy_test.go:73 @ 10/12/25 16:15:03.996&#xA;&lt; Exit [It] checks project readiness - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/importer_network_policy_test.go:72 @ 10/12/25 16:15:06.746 (2.75s)&#xA;&gt; Enter [AfterEach] ImporterNetworkPolicy - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/importer_network_policy_test.go:54 @ 10/12/25 16:15:06.746&#xA;&lt; Exit [AfterEach] ImporterNetworkPolicy - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/importer_network_policy_test.go:54 @ 10/12/25 16:15:06.746 (0s)&#xA;</system-err>
          </testcase>
          <testcase name="[It] ImporterNetworkPolicy When resources are applied result should be succeeded" classname="Tests" status="passed" time="3.082429667">
              <system-err>&gt; Enter [BeforeEach] ImporterNetworkPolicy - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/importer_network_policy_test.go:43 @ 10/12/25 16:15:06.747&#xA;&lt; Exit [BeforeEach] ImporterNetworkPolicy - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/importer_network_policy_test.go:43 @ 10/12/25 16:15:06.747 (0s)&#xA;&gt; Enter [It] result should be succeeded - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/importer_network_policy_test.go:83 @ 10/12/25 16:15:06.747&#xA;&lt; Exit [It] result should be succeeded - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/importer_network_policy_test.go:83 @ 10/12/25 16:15:09.829 (3.082s)&#xA;&gt; Enter [AfterEach] ImporterNetworkPolicy - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/importer_network_policy_test.go:54 @ 10/12/25 16:15:09.829&#xA;&lt; Exit [AfterEach] ImporterNetworkPolicy - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/importer_network_policy_test.go:54 @ 10/12/25 16:15:09.829 (0s)&#xA;</system-err>
          </testcase>
          <testcase name="[It] ImporterNetworkPolicy When resources are applied When virtual images are applied" classname="Tests" status="failed" time="1011.689280084">
              <failure message="should observe resources in &#39;&#39;jsonpath={.status.phase}=Ready&#39;&#39; state before 16m40s timeout&#xA;Expected&#xA;    &lt;[]string | len:1, cap:1&gt;: [&#xA;        &#34;cmd: kubectl wait virtualimages.virtualization.deckhouse.io head-5073ae15-vi --namespace head-5073ae15-end-to-end-importer-network-policy --for=&#39;jsonpath={.status.phase}=Ready&#39; --timeout=16m40s\nstderr: error: timed out waiting for the condition on virtualimages/head-5073ae15-vi\n\nwaited for: &#39;jsonpath={.status.phase}=Ready&#39;&#34;,&#xA;    ]&#xA;to be empty" type="failed">[FAILED] should observe resources in &#39;&#39;jsonpath={.status.phase}=Ready&#39;&#39; state before 16m40s timeout&#xA;Expected&#xA;    &lt;[]string | len:1, cap:1&gt;: [&#xA;        &#34;cmd: kubectl wait virtualimages.virtualization.deckhouse.io head-5073ae15-vi --namespace head-5073ae15-end-to-end-importer-network-policy --for=&#39;jsonpath={.status.phase}=Ready&#39; --timeout=16m40s\nstderr: error: timed out waiting for the condition on virtualimages/head-5073ae15-vi\n\nwaited for: &#39;jsonpath={.status.phase}=Ready&#39;&#34;,&#xA;    ]&#xA;to be empty&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/importer_network_policy_test.go:95 @ 10/12/25 16:31:51.962&#xA;</failure>
              <system-err>&gt; Enter [BeforeEach] ImporterNetworkPolicy - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/importer_network_policy_test.go:43 @ 10/12/25 16:15:09.829&#xA;&lt; Exit [BeforeEach] ImporterNetworkPolicy - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/importer_network_policy_test.go:43 @ 10/12/25 16:15:09.829 (0s)&#xA;&gt; Enter [It] When virtual images are applied - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/importer_network_policy_test.go:101 @ 10/12/25 16:15:09.829&#xA;STEP: VIs should be in Ready phases - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/importer_network_policy_test.go:94 @ 10/12/25 16:15:09.829&#xA;[FAILED] should observe resources in &#39;&#39;jsonpath={.status.phase}=Ready&#39;&#39; state before 16m40s timeout&#xA;Expected&#xA;    &lt;[]string | len:1, cap:1&gt;: [&#xA;        &#34;cmd: kubectl wait virtualimages.virtualization.deckhouse.io head-5073ae15-vi --namespace head-5073ae15-end-to-end-importer-network-policy --for=&#39;jsonpath={.status.phase}=Ready&#39; --timeout=16m40s\nstderr: error: timed out waiting for the condition on virtualimages/head-5073ae15-vi\n\nwaited for: &#39;jsonpath={.status.phase}=Ready&#39;&#34;,&#xA;    ]&#xA;to be empty&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/importer_network_policy_test.go:95 @ 10/12/25 16:31:51.962&#xA;&lt; Exit [It] When virtual images are applied - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/importer_network_policy_test.go:101 @ 10/12/25 16:31:51.962 (16m42.131s)&#xA;&gt; Enter [AfterEach] ImporterNetworkPolicy - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/importer_network_policy_test.go:54 @ 10/12/25 16:31:51.962&#xA;The list of pods is empty; nothing to dump.&#xA;&lt; Exit [AfterEach] ImporterNetworkPolicy - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/importer_network_policy_test.go:54 @ 10/12/25 16:31:57.665 (5.703s)&#xA;&gt; Enter [AfterAll] ImporterNetworkPolicy - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/importer_network_policy_test.go:49 @ 10/12/25 16:31:57.665&#xA;STEP: Delete manifests - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/importer_network_policy_test.go:50 @ 10/12/25 16:31:57.665&#xA;STEP: Response on deletion request should be successful - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:604 @ 10/12/25 16:31:57.665&#xA;END STEP: Response on deletion request should be successful - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:604 @ 10/12/25 16:32:01.52 (3.854s)&#xA;&lt; Exit [AfterAll] ImporterNetworkPolicy - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/importer_network_policy_test.go:49 @ 10/12/25 16:32:01.52 (3.855s)&#xA;</system-err>
          </testcase>
          <testcase name="[It] ImporterNetworkPolicy When resources are applied When virtual disks are applied" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/importer_network_policy_test.go:102 @ 10/12/25 16:32:01.52&#xA;</system-err>
          </testcase>
          <testcase name="[It] ImporterNetworkPolicy When resources are applied When virtual machines are applied" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/importer_network_policy_test.go:103 @ 10/12/25 16:32:01.52&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineEvacuation Evacuation [SIG-Migration]" classname="Tests" status="failed" time="1019.680384167">
              <failure message="should observe resources in &#39;&#39;jsonpath={.status.phase}=Running&#39;&#39; state before 16m40s timeout&#xA;Expected&#xA;    &lt;[]string | len:2, cap:2&gt;: [&#xA;        &#34;cmd: kubectl wait virtualmachine.virtualization.deckhouse.io head-5073ae15-vm-migration-bios --namespace head-5073ae15-end-to-end-vm-evacuation --for=&#39;jsonpath={.status.phase}=Running&#39; --timeout=16m40s\nstderr: W1012 16:41:59.532409   80502 reflector.go:492] k8s.io/client-go/tools/watch/informerwatcher.go:146: watch of *unstructured.Unstructured ended with: an error on the server (\&#34;unable to decode an event from the watch stream: http2: client connection lost\&#34;) has prevented the request from succeeding\nerror: timed out waiting for the condition on virtualmachines/head-5073ae15-vm-migration-bios\n\nwaited for: &#39;jsonpath={.status.phase}=Running&#39;&#34;,&#xA;        &#34;cmd: kubectl wait virtualmachine.virtualization.deckhouse.io head-5073ae15-vm-migration-uefi --namespace head-5073ae15-end-to-end-vm-evacuation --for=&#39;jsonpath={.status.phase}=Running&#39; --timeout=16m40s\nstderr: W1012 16:42:00.178317   80503 reflector.go:492] k8s.io/client-go/tools/watch/informerwatcher.go:146: watch of *unstructured.Unstructured ended with: an error on the server (\&#34;unable to decode an event from the watch stream: http2: client connection lost\&#34;) has prevented the request from succeeding\nerror: timed out waiting for the condition on virtualmachines/head-5073ae15-vm-migration-uefi\n\nwaited for: &#39;jsonpath={.status.phase}=Running&#39;&#34;,&#xA;    ]&#xA;to be empty" type="failed">[FAILED] should observe resources in &#39;&#39;jsonpath={.status.phase}=Running&#39;&#39; state before 16m40s timeout&#xA;Expected&#xA;    &lt;[]string | len:2, cap:2&gt;: [&#xA;        &#34;cmd: kubectl wait virtualmachine.virtualization.deckhouse.io head-5073ae15-vm-migration-bios --namespace head-5073ae15-end-to-end-vm-evacuation --for=&#39;jsonpath={.status.phase}=Running&#39; --timeout=16m40s\nstderr: W1012 16:41:59.532409   80502 reflector.go:492] k8s.io/client-go/tools/watch/informerwatcher.go:146: watch of *unstructured.Unstructured ended with: an error on the server (\&#34;unable to decode an event from the watch stream: http2: client connection lost\&#34;) has prevented the request from succeeding\nerror: timed out waiting for the condition on virtualmachines/head-5073ae15-vm-migration-bios\n\nwaited for: &#39;jsonpath={.status.phase}=Running&#39;&#34;,&#xA;        &#34;cmd: kubectl wait virtualmachine.virtualization.deckhouse.io head-5073ae15-vm-migration-uefi --namespace head-5073ae15-end-to-end-vm-evacuation --for=&#39;jsonpath={.status.phase}=Running&#39; --timeout=16m40s\nstderr: W1012 16:42:00.178317   80503 reflector.go:492] k8s.io/client-go/tools/watch/informerwatcher.go:146: watch of *unstructured.Unstructured ended with: an error on the server (\&#34;unable to decode an event from the watch stream: http2: client connection lost\&#34;) has prevented the request from succeeding\nerror: timed out waiting for the condition on virtualmachines/head-5073ae15-vm-migration-uefi\n\nwaited for: &#39;jsonpath={.status.phase}=Running&#39;&#34;,&#xA;    ]&#xA;to be empty&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_evacuation_test.go:98 @ 10/12/25 16:50:51.352&#xA;</failure>
              <system-err>&gt; Enter [BeforeAll] VirtualMachineEvacuation - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_evacuation_test.go:42 @ 10/12/25 16:32:01.52&#xA;&lt; Exit [BeforeAll] VirtualMachineEvacuation - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_evacuation_test.go:42 @ 10/12/25 16:32:03.475 (1.955s)&#xA;&gt; Enter [BeforeEach] VirtualMachineEvacuation - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_evacuation_test.go:51 @ 10/12/25 16:32:03.475&#xA;&lt; Exit [BeforeEach] VirtualMachineEvacuation - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_evacuation_test.go:51 @ 10/12/25 16:32:08.95 (5.475s)&#xA;&gt; Enter [It] Evacuation - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_evacuation_test.go:96 @ 10/12/25 16:32:08.95&#xA;STEP: Virtual machine agents should be ready - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_evacuation_test.go:97 @ 10/12/25 16:32:08.95&#xA;[FAILED] should observe resources in &#39;&#39;jsonpath={.status.phase}=Running&#39;&#39; state before 16m40s timeout&#xA;Expected&#xA;    &lt;[]string | len:2, cap:2&gt;: [&#xA;        &#34;cmd: kubectl wait virtualmachine.virtualization.deckhouse.io head-5073ae15-vm-migration-bios --namespace head-5073ae15-end-to-end-vm-evacuation --for=&#39;jsonpath={.status.phase}=Running&#39; --timeout=16m40s\nstderr: W1012 16:41:59.532409   80502 reflector.go:492] k8s.io/client-go/tools/watch/informerwatcher.go:146: watch of *unstructured.Unstructured ended with: an error on the server (\&#34;unable to decode an event from the watch stream: http2: client connection lost\&#34;) has prevented the request from succeeding\nerror: timed out waiting for the condition on virtualmachines/head-5073ae15-vm-migration-bios\n\nwaited for: &#39;jsonpath={.status.phase}=Running&#39;&#34;,&#xA;        &#34;cmd: kubectl wait virtualmachine.virtualization.deckhouse.io head-5073ae15-vm-migration-uefi --namespace head-5073ae15-end-to-end-vm-evacuation --for=&#39;jsonpath={.status.phase}=Running&#39; --timeout=16m40s\nstderr: W1012 16:42:00.178317   80503 reflector.go:492] k8s.io/client-go/tools/watch/informerwatcher.go:146: watch of *unstructured.Unstructured ended with: an error on the server (\&#34;unable to decode an event from the watch stream: http2: client connection lost\&#34;) has prevented the request from succeeding\nerror: timed out waiting for the condition on virtualmachines/head-5073ae15-vm-migration-uefi\n\nwaited for: &#39;jsonpath={.status.phase}=Running&#39;&#34;,&#xA;    ]&#xA;to be empty&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_evacuation_test.go:98 @ 10/12/25 16:50:51.352&#xA;&lt; Exit [It] Evacuation - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_evacuation_test.go:96 @ 10/12/25 16:50:51.352 (16m41.669s)&#xA;&gt; Enter [AfterEach] VirtualMachineEvacuation - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_evacuation_test.go:59 @ 10/12/25 16:50:51.352&#xA;The list of pods is empty; nothing to dump.&#xA;STEP: Response on deletion request should be successful - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:604 @ 10/12/25 16:50:57.141&#xA;END STEP: Response on deletion request should be successful - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:604 @ 10/12/25 16:51:01.934 (4.792s)&#xA;&lt; Exit [AfterEach] VirtualMachineEvacuation - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_evacuation_test.go:59 @ 10/12/25 16:51:01.934 (10.582s)&#xA;</system-err>
          </testcase>
          <testcase name="[It] ComplexTest When virtualization resources are applied result should be succeeded [Serial]" classname="Tests" status="passed" time="29.14222775">
              <system-err>&gt; Enter [BeforeAll] ComplexTest - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:52 @ 10/12/25 16:51:01.934&#xA;&lt; Exit [BeforeAll] ComplexTest - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:52 @ 10/12/25 16:51:03.888 (1.953s)&#xA;&gt; Enter [It] result should be succeeded - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:62 @ 10/12/25 16:51:03.888&#xA;&lt; Exit [It] result should be succeeded - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:62 @ 10/12/25 16:51:31.076 (27.189s)&#xA;&gt; Enter [AfterEach] ComplexTest - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:46 @ 10/12/25 16:51:31.076&#xA;&lt; Exit [AfterEach] ComplexTest - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:46 @ 10/12/25 16:51:31.077 (0s)&#xA;</system-err>
          </testcase>
          <testcase name="[It] ComplexTest When virtualization resources are applied should fill empty virtualMachineClassName with the default class name [Serial]" classname="Tests" status="passed" time="1.075506375">
              <system-err>&gt; Enter [It] should fill empty virtualMachineClassName with the default class name - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:83 @ 10/12/25 16:51:31.077&#xA;&lt; Exit [It] should fill empty virtualMachineClassName with the default class name - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:83 @ 10/12/25 16:51:32.152 (1.075s)&#xA;&gt; Enter [AfterEach] ComplexTest - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:46 @ 10/12/25 16:51:32.152&#xA;&lt; Exit [AfterEach] ComplexTest - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:46 @ 10/12/25 16:51:32.152 (0s)&#xA;</system-err>
          </testcase>
          <testcase name="[It] ComplexTest When virtual images are applied checks VIs phases [Serial]" classname="Tests" status="failed" time="1008.16969725">
              <failure message="should observe resources in &#39;&#39;jsonpath={.status.phase}=Ready&#39;&#39; state before 16m40s timeout&#xA;Expected&#xA;    &lt;[]string | len:4, cap:4&gt;: [&#xA;        &#34;cmd: kubectl wait virtualimages.virtualization.deckhouse.io head-5073ae15-vi-from-vi-ubuntu-http --namespace head-5073ae15-end-to-end-complex-test --for=&#39;jsonpath={.status.phase}=Ready&#39; --timeout=16m40s\nstderr: W1012 17:14:19.951967   81706 reflector.go:492] k8s.io/client-go/tools/watch/informerwatcher.go:146: watch of *unstructured.Unstructured ended with: an error on the server (\&#34;unable to decode an event from the watch stream: http2: client connection lost\&#34;) has prevented the request from succeeding\nerror: timed out waiting for the condition on virtualimages/head-5073ae15-vi-from-vi-ubuntu-http\n\nwaited for: &#39;jsonpath={.status.phase}=Ready&#39;&#34;,&#xA;        &#34;cmd: kubectl wait virtualimages.virtualization.deckhouse.io head-5073ae15-vi-ubuntu-http --namespace head-5073ae15-end-to-end-complex-test --for=&#39;jsonpath={.status.phase}=Ready&#39; --timeout=16m40s\nstderr: W1012 17:14:19.953166   81704 reflector.go:492] k8s.io/client-go/tools/watch/informerwatcher.go:146: watch of *unstructured.Unstructured ended with: an error on the server (\&#34;unable to decode an event from the watch stream: http2: client connection lost\&#34;) has prevented the request from succeeding\nerror: timed out waiting for the condition on virtualimages/head-5073ae15-vi-ubuntu-http\n\nwaited for: &#39;jsonpath={.status.phase}=Ready&#39;&#34;,&#xA;        &#34;cmd: kubectl wait virtualimages.virtualization.deckhouse.io head-5073ae15-vi-alpine-registry --namespace head-5073ae15-end-to-end-complex-test --for=&#39;jsonpath={.status.phase}=Ready&#39; --timeout=16m40s\nstderr: W1012 17:14:19.940197   81705 reflector.go:492] k8s.io/client-go/tools/watch/informerwatcher.go:146: watch of *unstructured.Unstructured ended with: an error on the server (\&#34;unable to decode an event from the watch stream: http2: client connection lost\&#34;) has prevented the request from succeeding\nerror: timed out waiting for the condition on virtualimages/head-5073ae15-vi-alpine-registry\n\nwaited for: &#39;jsonpath={.status.phase}=Ready&#39;&#34;,&#xA;        &#34;cmd: kubectl wait virtualimages.virtualization.deckhouse.io head-5073ae15-vi-from-cvi-ubuntu-http --namespace head-5073ae15-end-to-end-complex-test --for=&#39;jsonpath={.status.phase}=Ready&#39; --timeout=16m40s\nstderr: W1012 17:14:19.952170   81703 reflector.go:492] k8s.io/client-go/tools/watch/informerwatcher.go:146: watch of *unstructured.Unstructured ended with: an error on the server (\&#34;unable to decode an event from the watch stream: http2: client connection lost\&#34;) has prevented the request from succeeding\nerror: timed out waiting for the condition on virtualimages/head-5073ae15-vi-from-cvi-ubuntu-http\n\nwaited for: &#39;jsonpath={.status.phase}=Ready&#39;&#34;,&#xA;    ]&#xA;to be empty" type="failed">[FAILED] should observe resources in &#39;&#39;jsonpath={.status.phase}=Ready&#39;&#39; state before 16m40s timeout&#xA;Expected&#xA;    &lt;[]string | len:4, cap:4&gt;: [&#xA;        &#34;cmd: kubectl wait virtualimages.virtualization.deckhouse.io head-5073ae15-vi-from-vi-ubuntu-http --namespace head-5073ae15-end-to-end-complex-test --for=&#39;jsonpath={.status.phase}=Ready&#39; --timeout=16m40s\nstderr: W1012 17:14:19.951967   81706 reflector.go:492] k8s.io/client-go/tools/watch/informerwatcher.go:146: watch of *unstructured.Unstructured ended with: an error on the server (\&#34;unable to decode an event from the watch stream: http2: client connection lost\&#34;) has prevented the request from succeeding\nerror: timed out waiting for the condition on virtualimages/head-5073ae15-vi-from-vi-ubuntu-http\n\nwaited for: &#39;jsonpath={.status.phase}=Ready&#39;&#34;,&#xA;        &#34;cmd: kubectl wait virtualimages.virtualization.deckhouse.io head-5073ae15-vi-ubuntu-http --namespace head-5073ae15-end-to-end-complex-test --for=&#39;jsonpath={.status.phase}=Ready&#39; --timeout=16m40s\nstderr: W1012 17:14:19.953166   81704 reflector.go:492] k8s.io/client-go/tools/watch/informerwatcher.go:146: watch of *unstructured.Unstructured ended with: an error on the server (\&#34;unable to decode an event from the watch stream: http2: client connection lost\&#34;) has prevented the request from succeeding\nerror: timed out waiting for the condition on virtualimages/head-5073ae15-vi-ubuntu-http\n\nwaited for: &#39;jsonpath={.status.phase}=Ready&#39;&#34;,&#xA;        &#34;cmd: kubectl wait virtualimages.virtualization.deckhouse.io head-5073ae15-vi-alpine-registry --namespace head-5073ae15-end-to-end-complex-test --for=&#39;jsonpath={.status.phase}=Ready&#39; --timeout=16m40s\nstderr: W1012 17:14:19.940197   81705 reflector.go:492] k8s.io/client-go/tools/watch/informerwatcher.go:146: watch of *unstructured.Unstructured ended with: an error on the server (\&#34;unable to decode an event from the watch stream: http2: client connection lost\&#34;) has prevented the request from succeeding\nerror: timed out waiting for the condition on virtualimages/head-5073ae15-vi-alpine-registry\n\nwaited for: &#39;jsonpath={.status.phase}=Ready&#39;&#34;,&#xA;        &#34;cmd: kubectl wait virtualimages.virtualization.deckhouse.io head-5073ae15-vi-from-cvi-ubuntu-http --namespace head-5073ae15-end-to-end-complex-test --for=&#39;jsonpath={.status.phase}=Ready&#39; --timeout=16m40s\nstderr: W1012 17:14:19.952170   81703 reflector.go:492] k8s.io/client-go/tools/watch/informerwatcher.go:146: watch of *unstructured.Unstructured ended with: an error on the server (\&#34;unable to decode an event from the watch stream: http2: client connection lost\&#34;) has prevented the request from succeeding\nerror: timed out waiting for the condition on virtualimages/head-5073ae15-vi-from-cvi-ubuntu-http\n\nwaited for: &#39;jsonpath={.status.phase}=Ready&#39;&#34;,&#xA;    ]&#xA;to be empty&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:103 @ 10/12/25 17:29:44.18&#xA;</failure>
              <system-err>&gt; Enter [It] checks VIs phases - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:101 @ 10/12/25 16:51:32.153&#xA;STEP: VIs should be in Ready phases - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:102 @ 10/12/25 16:51:32.153&#xA;[FAILED] should observe resources in &#39;&#39;jsonpath={.status.phase}=Ready&#39;&#39; state before 16m40s timeout&#xA;Expected&#xA;    &lt;[]string | len:4, cap:4&gt;: [&#xA;        &#34;cmd: kubectl wait virtualimages.virtualization.deckhouse.io head-5073ae15-vi-from-vi-ubuntu-http --namespace head-5073ae15-end-to-end-complex-test --for=&#39;jsonpath={.status.phase}=Ready&#39; --timeout=16m40s\nstderr: W1012 17:14:19.951967   81706 reflector.go:492] k8s.io/client-go/tools/watch/informerwatcher.go:146: watch of *unstructured.Unstructured ended with: an error on the server (\&#34;unable to decode an event from the watch stream: http2: client connection lost\&#34;) has prevented the request from succeeding\nerror: timed out waiting for the condition on virtualimages/head-5073ae15-vi-from-vi-ubuntu-http\n\nwaited for: &#39;jsonpath={.status.phase}=Ready&#39;&#34;,&#xA;        &#34;cmd: kubectl wait virtualimages.virtualization.deckhouse.io head-5073ae15-vi-ubuntu-http --namespace head-5073ae15-end-to-end-complex-test --for=&#39;jsonpath={.status.phase}=Ready&#39; --timeout=16m40s\nstderr: W1012 17:14:19.953166   81704 reflector.go:492] k8s.io/client-go/tools/watch/informerwatcher.go:146: watch of *unstructured.Unstructured ended with: an error on the server (\&#34;unable to decode an event from the watch stream: http2: client connection lost\&#34;) has prevented the request from succeeding\nerror: timed out waiting for the condition on virtualimages/head-5073ae15-vi-ubuntu-http\n\nwaited for: &#39;jsonpath={.status.phase}=Ready&#39;&#34;,&#xA;        &#34;cmd: kubectl wait virtualimages.virtualization.deckhouse.io head-5073ae15-vi-alpine-registry --namespace head-5073ae15-end-to-end-complex-test --for=&#39;jsonpath={.status.phase}=Ready&#39; --timeout=16m40s\nstderr: W1012 17:14:19.940197   81705 reflector.go:492] k8s.io/client-go/tools/watch/informerwatcher.go:146: watch of *unstructured.Unstructured ended with: an error on the server (\&#34;unable to decode an event from the watch stream: http2: client connection lost\&#34;) has prevented the request from succeeding\nerror: timed out waiting for the condition on virtualimages/head-5073ae15-vi-alpine-registry\n\nwaited for: &#39;jsonpath={.status.phase}=Ready&#39;&#34;,&#xA;        &#34;cmd: kubectl wait virtualimages.virtualization.deckhouse.io head-5073ae15-vi-from-cvi-ubuntu-http --namespace head-5073ae15-end-to-end-complex-test --for=&#39;jsonpath={.status.phase}=Ready&#39; --timeout=16m40s\nstderr: W1012 17:14:19.952170   81703 reflector.go:492] k8s.io/client-go/tools/watch/informerwatcher.go:146: watch of *unstructured.Unstructured ended with: an error on the server (\&#34;unable to decode an event from the watch stream: http2: client connection lost\&#34;) has prevented the request from succeeding\nerror: timed out waiting for the condition on virtualimages/head-5073ae15-vi-from-cvi-ubuntu-http\n\nwaited for: &#39;jsonpath={.status.phase}=Ready&#39;&#34;,&#xA;    ]&#xA;to be empty&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:103 @ 10/12/25 17:29:44.18&#xA;&lt; Exit [It] checks VIs phases - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:101 @ 10/12/25 17:29:44.181 (16m42.113s)&#xA;&gt; Enter [AfterEach] ComplexTest - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:46 @ 10/12/25 17:29:44.181&#xA;The list of pods is empty; nothing to dump.&#xA;&lt; Exit [AfterEach] ComplexTest - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:46 @ 10/12/25 17:29:50.238 (6.057s)&#xA;</system-err>
          </testcase>
          <testcase name="[It] ComplexTest When cluster virtual images are applied checks CVIs phases [Serial]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:112 @ 10/12/25 17:29:50.238&#xA;</system-err>
          </testcase>
          <testcase name="[It] ComplexTest When virtual machine classes are applied checks VMClasses phases [Serial]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:123 @ 10/12/25 17:29:50.238&#xA;</system-err>
          </testcase>
          <testcase name="[It] ComplexTest When virtual machines IP addresses are applied patches custom VMIP with unassigned address [Serial]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:134 @ 10/12/25 17:29:50.238&#xA;</system-err>
          </testcase>
          <testcase name="[It] ComplexTest When virtual machines IP addresses are applied checks VMIPs phases [Serial]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:141 @ 10/12/25 17:29:50.238&#xA;</system-err>
          </testcase>
          <testcase name="[It] ComplexTest When virtual disks are applied checks VDs phases with consumers [Serial]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:152 @ 10/12/25 17:29:50.238&#xA;</system-err>
          </testcase>
          <testcase name="[It] ComplexTest When virtual disks are applied checks VDs phases with no consumers [Serial]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:162 @ 10/12/25 17:29:50.239&#xA;</system-err>
          </testcase>
          <testcase name="[It] ComplexTest When virtual machines are applied checks VMs phases [Serial]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:173 @ 10/12/25 17:29:50.239&#xA;</system-err>
          </testcase>
          <testcase name="[It] ComplexTest When virtual machine block device attachments are applied checks VMBDAs phases [Serial]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:184 @ 10/12/25 17:29:50.239&#xA;</system-err>
          </testcase>
          <testcase name="[It] ComplexTest External connection When Virtual machine agents are ready checks VMs external connectivity [Serial]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:196 @ 10/12/25 17:29:50.239&#xA;</system-err>
          </testcase>
          <testcase name="[It] ComplexTest Power state checks Verify that the virtual machines are stopping by VMOPs stops VMs by VMOPs [Serial]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:220 @ 10/12/25 17:29:50.239&#xA;</system-err>
          </testcase>
          <testcase name="[It] ComplexTest Power state checks Verify that the virtual machines are stopping by VMOPs checks VMOPs and VMs phases [Serial]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:245 @ 10/12/25 17:29:50.239&#xA;</system-err>
          </testcase>
          <testcase name="[It] ComplexTest Power state checks Verify that the virtual machines are stopping by VMOPs cleanup AlwaysOn VM VMOPs [Serial]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:268 @ 10/12/25 17:29:50.239&#xA;</system-err>
          </testcase>
          <testcase name="[It] ComplexTest Power state checks Verify that the virtual machines are starting starts VMs by VMOP [Serial]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:280 @ 10/12/25 17:29:50.239&#xA;</system-err>
          </testcase>
          <testcase name="[It] ComplexTest Power state checks Verify that the virtual machines are starting checks VMs and VMOPs phases [Serial]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:299 @ 10/12/25 17:29:50.239&#xA;</system-err>
          </testcase>
          <testcase name="[It] ComplexTest Power state checks Verify that the virtual machines are stopping by ssh stops VMs by ssh [Serial]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:316 @ 10/12/25 17:29:50.239&#xA;</system-err>
          </testcase>
          <testcase name="[It] ComplexTest Power state checks Verify that the virtual machines are stopping by ssh checks VMs phases [Serial]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:341 @ 10/12/25 17:29:50.239&#xA;</system-err>
          </testcase>
          <testcase name="[It] ComplexTest Power state checks Verify that the virtual machines are stopping by ssh start not AlwaysOn VMs [Serial]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:354 @ 10/12/25 17:29:50.24&#xA;</system-err>
          </testcase>
          <testcase name="[It] ComplexTest Power state checks Verify that the virtual machines are stopping by ssh checks VMs and VMOPs phases [Serial]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:358 @ 10/12/25 17:29:50.24&#xA;</system-err>
          </testcase>
          <testcase name="[It] ComplexTest Power state checks Verify that the virtual machines are restarting by VMOP reboot VMs by VMOP [Serial]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:375 @ 10/12/25 17:29:50.24&#xA;</system-err>
          </testcase>
          <testcase name="[It] ComplexTest Power state checks Verify that the virtual machines are restarting by VMOP checks VMs and VMOPs phases [Serial]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:388 @ 10/12/25 17:29:50.24&#xA;</system-err>
          </testcase>
          <testcase name="[It] ComplexTest Power state checks Verify that the virtual machines are restarting by ssh reboot VMs by ssh [Serial]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:405 @ 10/12/25 17:29:50.24&#xA;</system-err>
          </testcase>
          <testcase name="[It] ComplexTest Power state checks Verify that the virtual machines are restarting after deleting their pods reboots the VMs by deleting their pods [Serial]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:444 @ 10/12/25 17:29:50.24&#xA;</system-err>
          </testcase>
          <testcase name="[It] ComplexTest Power state checks Verify that the virtual machines are restarting after deleting their pods checks VMs external connection after reboot [Serial]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:479 @ 10/12/25 17:29:50.24&#xA;</system-err>
          </testcase>
          <testcase name="[It] ComplexTest Migrations When Virtual machine agents are ready starts migrations [Serial]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:497 @ 10/12/25 17:29:50.24&#xA;</system-err>
          </testcase>
          <testcase name="[It] ComplexTest Migrations When VMs migrations are applied checks VMs and VMOPs phases [Serial]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:512 @ 10/12/25 17:29:50.24&#xA;</system-err>
          </testcase>
          <testcase name="[It] ComplexTest Migrations When VMs migrations are applied checks VMs external connection after migrations [Serial]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:528 @ 10/12/25 17:29:50.24&#xA;</system-err>
          </testcase>
          <testcase name="[It] ComplexTest When test is completed deletes test case resources [Serial]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/complex_test.go:545 @ 10/12/25 17:29:50.24&#xA;</system-err>
          </testcase>
          <testcase name="[It] [sig-storage] StorageClassMigration should be successful when only root disk changed storage class [SIG-Storage]" classname="Tests" status="skipped" time="0.000560625">
              <skipped message="skipped - This test case is not working everytime. Should be fixed."></skipped>
              <system-err>&gt; Enter [BeforeEach] [sig-storage] StorageClassMigration - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/storage/volume_migration_storage_class_changed.go:48 @ 10/12/25 17:29:50.241&#xA;[SKIPPED] This test case is not working everytime. Should be fixed.&#xA;In [BeforeEach] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/storage/volume_migration_storage_class_changed.go:50 @ 10/12/25 17:29:50.241&#xA;&lt; Exit [BeforeEach] [sig-storage] StorageClassMigration - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/storage/volume_migration_storage_class_changed.go:48 @ 10/12/25 17:29:50.241 (1ms)&#xA;</system-err>
          </testcase>
          <testcase name="[It] [sig-storage] StorageClassMigration should be successful when root disk changed storage class and one local additional disk [SIG-Storage]" classname="Tests" status="skipped" time="0.000189625">
              <skipped message="skipped - This test case is not working everytime. Should be fixed."></skipped>
              <system-err>&gt; Enter [BeforeEach] [sig-storage] StorageClassMigration - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/storage/volume_migration_storage_class_changed.go:48 @ 10/12/25 17:29:50.241&#xA;[SKIPPED] This test case is not working everytime. Should be fixed.&#xA;In [BeforeEach] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/storage/volume_migration_storage_class_changed.go:50 @ 10/12/25 17:29:50.242&#xA;&lt; Exit [BeforeEach] [sig-storage] StorageClassMigration - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/storage/volume_migration_storage_class_changed.go:48 @ 10/12/25 17:29:50.242 (0s)&#xA;</system-err>
          </testcase>
          <testcase name="[It] [sig-storage] StorageClassMigration should be successful when root disk changed storage class and one additional disk [SIG-Storage]" classname="Tests" status="skipped" time="0.000124708">
              <skipped message="skipped - This test case is not working everytime. Should be fixed."></skipped>
              <system-err>&gt; Enter [BeforeEach] [sig-storage] StorageClassMigration - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/storage/volume_migration_storage_class_changed.go:48 @ 10/12/25 17:29:50.242&#xA;[SKIPPED] This test case is not working everytime. Should be fixed.&#xA;In [BeforeEach] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/storage/volume_migration_storage_class_changed.go:50 @ 10/12/25 17:29:50.242&#xA;&lt; Exit [BeforeEach] [sig-storage] StorageClassMigration - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/storage/volume_migration_storage_class_changed.go:48 @ 10/12/25 17:29:50.242 (0s)&#xA;</system-err>
          </testcase>
          <testcase name="[It] [sig-storage] StorageClassMigration should be successful when only additional disk changed storage class [SIG-Storage]" classname="Tests" status="skipped" time="0.000140083">
              <skipped message="skipped - This test case is not working everytime. Should be fixed."></skipped>
              <system-err>&gt; Enter [BeforeEach] [sig-storage] StorageClassMigration - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/storage/volume_migration_storage_class_changed.go:48 @ 10/12/25 17:29:50.242&#xA;[SKIPPED] This test case is not working everytime. Should be fixed.&#xA;In [BeforeEach] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/storage/volume_migration_storage_class_changed.go:50 @ 10/12/25 17:29:50.242&#xA;&lt; Exit [BeforeEach] [sig-storage] StorageClassMigration - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/storage/volume_migration_storage_class_changed.go:48 @ 10/12/25 17:29:50.242 (0s)&#xA;</system-err>
          </testcase>
          <testcase name="[It] [sig-storage] StorageClassMigration should be reverted when only root disk changed storage class [SIG-Storage]" classname="Tests" status="skipped" time="0.000122417">
              <skipped message="skipped - This test case is not working everytime. Should be fixed."></skipped>
              <system-err>&gt; Enter [BeforeEach] [sig-storage] StorageClassMigration - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/storage/volume_migration_storage_class_changed.go:48 @ 10/12/25 17:29:50.242&#xA;[SKIPPED] This test case is not working everytime. Should be fixed.&#xA;In [BeforeEach] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/storage/volume_migration_storage_class_changed.go:50 @ 10/12/25 17:29:50.242&#xA;&lt; Exit [BeforeEach] [sig-storage] StorageClassMigration - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/storage/volume_migration_storage_class_changed.go:48 @ 10/12/25 17:29:50.242 (0s)&#xA;</system-err>
          </testcase>
          <testcase name="[It] [sig-storage] StorageClassMigration should be reverted when root disk changed storage class and one local additional disk [SIG-Storage]" classname="Tests" status="skipped" time="0.000113333">
              <skipped message="skipped - This test case is not working everytime. Should be fixed."></skipped>
              <system-err>&gt; Enter [BeforeEach] [sig-storage] StorageClassMigration - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/storage/volume_migration_storage_class_changed.go:48 @ 10/12/25 17:29:50.242&#xA;[SKIPPED] This test case is not working everytime. Should be fixed.&#xA;In [BeforeEach] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/storage/volume_migration_storage_class_changed.go:50 @ 10/12/25 17:29:50.242&#xA;&lt; Exit [BeforeEach] [sig-storage] StorageClassMigration - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/storage/volume_migration_storage_class_changed.go:48 @ 10/12/25 17:29:50.242 (0s)&#xA;</system-err>
          </testcase>
          <testcase name="[It] [sig-storage] StorageClassMigration should be reverted when root disk changed storage class and one additional disk [SIG-Storage]" classname="Tests" status="skipped" time="0.000110291">
              <skipped message="skipped - This test case is not working everytime. Should be fixed."></skipped>
              <system-err>&gt; Enter [BeforeEach] [sig-storage] StorageClassMigration - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/storage/volume_migration_storage_class_changed.go:48 @ 10/12/25 17:29:50.243&#xA;[SKIPPED] This test case is not working everytime. Should be fixed.&#xA;In [BeforeEach] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/storage/volume_migration_storage_class_changed.go:50 @ 10/12/25 17:29:50.243&#xA;&lt; Exit [BeforeEach] [sig-storage] StorageClassMigration - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/storage/volume_migration_storage_class_changed.go:48 @ 10/12/25 17:29:50.243 (0s)&#xA;</system-err>
          </testcase>
          <testcase name="[It] [sig-storage] StorageClassMigration should be reverted when only additional disk changed storage class [SIG-Storage]" classname="Tests" status="skipped" time="0.000153125">
              <skipped message="skipped - This test case is not working everytime. Should be fixed."></skipped>
              <system-err>&gt; Enter [BeforeEach] [sig-storage] StorageClassMigration - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/storage/volume_migration_storage_class_changed.go:48 @ 10/12/25 17:29:50.243&#xA;[SKIPPED] This test case is not working everytime. Should be fixed.&#xA;In [BeforeEach] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/storage/volume_migration_storage_class_changed.go:50 @ 10/12/25 17:29:50.243&#xA;&lt; Exit [BeforeEach] [sig-storage] StorageClassMigration - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/storage/volume_migration_storage_class_changed.go:48 @ 10/12/25 17:29:50.243 (0s)&#xA;</system-err>
          </testcase>
          <testcase name="[It] [sig-storage] StorageClassMigration should be successful two migrations in a row [SIG-Storage]" classname="Tests" status="skipped" time="0.000108417">
              <skipped message="skipped - This test case is not working everytime. Should be fixed."></skipped>
              <system-err>&gt; Enter [BeforeEach] [sig-storage] StorageClassMigration - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/storage/volume_migration_storage_class_changed.go:48 @ 10/12/25 17:29:50.243&#xA;[SKIPPED] This test case is not working everytime. Should be fixed.&#xA;In [BeforeEach] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/storage/volume_migration_storage_class_changed.go:50 @ 10/12/25 17:29:50.243&#xA;&lt; Exit [BeforeEach] [sig-storage] StorageClassMigration - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/storage/volume_migration_storage_class_changed.go:48 @ 10/12/25 17:29:50.243 (0s)&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineRestoreSafe When the virtualization resources are applied result should be succeeded [SIG-Restoration]" classname="Tests" status="passed" time="6.011336916">
              <system-err>&gt; Enter [BeforeAll] VirtualMachineRestoreSafe - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_safe_test.go:52 @ 10/12/25 17:29:50.243&#xA;&lt; Exit [BeforeAll] VirtualMachineRestoreSafe - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_safe_test.go:52 @ 10/12/25 17:29:52.19 (1.947s)&#xA;&gt; Enter [BeforeEach] VirtualMachineRestoreSafe - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_safe_test.go:61 @ 10/12/25 17:29:52.19&#xA;&lt; Exit [BeforeEach] VirtualMachineRestoreSafe - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_safe_test.go:61 @ 10/12/25 17:29:52.19 (0s)&#xA;&gt; Enter [It] result should be succeeded - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_safe_test.go:74 @ 10/12/25 17:29:52.19&#xA;&lt; Exit [It] result should be succeeded - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_safe_test.go:74 @ 10/12/25 17:29:56.254 (4.065s)&#xA;&gt; Enter [AfterEach] VirtualMachineRestoreSafe - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_safe_test.go:65 @ 10/12/25 17:29:56.254&#xA;&lt; Exit [AfterEach] VirtualMachineRestoreSafe - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_safe_test.go:65 @ 10/12/25 17:29:56.254 (0s)&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineRestoreSafe When the virtualization resources are applied checks the resources phase [SIG-Restoration]" classname="Tests" status="failed" time="1007.904067458">
              <failure message="should observe resources in &#39;&#39;jsonpath={.status.phase}=Running&#39;&#39; state before 16m40s timeout&#xA;Expected&#xA;    &lt;[]string | len:1, cap:1&gt;: [&#xA;        &#34;cmd: kubectl wait virtualmachine.virtualization.deckhouse.io head-5073ae15-vm-restore-safe --namespace head-5073ae15-end-to-end-vm-restore-safe --for=&#39;jsonpath={.status.phase}=Running&#39; --timeout=16m40s\nstderr: error: timed out waiting for the condition on virtualmachines/head-5073ae15-vm-restore-safe\n\nwaited for: &#39;jsonpath={.status.phase}=Running&#39;&#34;,&#xA;    ]&#xA;to be empty" type="failed">[FAILED] should observe resources in &#39;&#39;jsonpath={.status.phase}=Running&#39;&#39; state before 16m40s timeout&#xA;Expected&#xA;    &lt;[]string | len:1, cap:1&gt;: [&#xA;        &#34;cmd: kubectl wait virtualmachine.virtualization.deckhouse.io head-5073ae15-vm-restore-safe --namespace head-5073ae15-end-to-end-vm-restore-safe --for=&#39;jsonpath={.status.phase}=Running&#39; --timeout=16m40s\nstderr: error: timed out waiting for the condition on virtualmachines/head-5073ae15-vm-restore-safe\n\nwaited for: &#39;jsonpath={.status.phase}=Running&#39;&#34;,&#xA;    ]&#xA;to be empty&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_safe_test.go:107 @ 10/12/25 17:46:37.96&#xA;</failure>
              <system-err>&gt; Enter [BeforeEach] VirtualMachineRestoreSafe - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_safe_test.go:61 @ 10/12/25 17:29:56.255&#xA;&lt; Exit [BeforeEach] VirtualMachineRestoreSafe - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_safe_test.go:61 @ 10/12/25 17:29:56.255 (0s)&#xA;&gt; Enter [It] checks the resources phase - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_safe_test.go:105 @ 10/12/25 17:29:56.255&#xA;STEP: `VirtualMachine` agent should be ready - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_safe_test.go:106 @ 10/12/25 17:29:56.255&#xA;END STEP: `VirtualMachine` agent should be ready - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_safe_test.go:106 @ 10/12/25 17:46:37.96 (16m41.657s)&#xA;[FAILED] should observe resources in &#39;&#39;jsonpath={.status.phase}=Running&#39;&#39; state before 16m40s timeout&#xA;Expected&#xA;    &lt;[]string | len:1, cap:1&gt;: [&#xA;        &#34;cmd: kubectl wait virtualmachine.virtualization.deckhouse.io head-5073ae15-vm-restore-safe --namespace head-5073ae15-end-to-end-vm-restore-safe --for=&#39;jsonpath={.status.phase}=Running&#39; --timeout=16m40s\nstderr: error: timed out waiting for the condition on virtualmachines/head-5073ae15-vm-restore-safe\n\nwaited for: &#39;jsonpath={.status.phase}=Running&#39;&#34;,&#xA;    ]&#xA;to be empty&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_safe_test.go:107 @ 10/12/25 17:46:37.96&#xA;&lt; Exit [It] checks the resources phase - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_safe_test.go:105 @ 10/12/25 17:46:37.96 (16m41.657s)&#xA;&gt; Enter [AfterEach] VirtualMachineRestoreSafe - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_safe_test.go:65 @ 10/12/25 17:46:37.96&#xA;The list of pods is empty; nothing to dump.&#xA;&lt; Exit [AfterEach] VirtualMachineRestoreSafe - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_safe_test.go:65 @ 10/12/25 17:46:44.207 (6.247s)&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineRestoreSafe When the virtualization resources are applied add additional interface to virtual machines [SIG-Restoration]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_safe_test.go:115 @ 10/12/25 17:46:44.207&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineRestoreSafe When the resources are ready to use restore the `VirtualMachines` with `Safe` mode [SIG-Restoration]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_safe_test.go:158 @ 10/12/25 17:46:44.208&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineRestoreSafe When the resources are ready to use check the .status.networks of each VM after restore [SIG-Restoration]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_safe_test.go:348 @ 10/12/25 17:46:44.208&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineRestoreSafe When test is completed deletes test case resources [SIG-Restoration]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_safe_test.go:374 @ 10/12/25 17:46:44.208&#xA;</system-err>
          </testcase>
          <testcase name="[It] ImageHotplug When the virtualization resources are applied result should be succeeded" classname="Tests" status="failed" time="12.751419375">
              <failure message="Warning: resource namespaces/head-5073ae15-end-to-end-image-hotplug is missing the kubectl.kubernetes.io/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create --save-config or kubectl apply. The missing annotation will be patched automatically.&#xA;Error from server (Forbidden): error when creating &#34;/tmp/testdata/image-hotplug&#34;: admission webhook &#34;vi.virtualization-controller.validate.d8-virtualization&#34; denied the request: the storage class &#34;ceph-pool-r2-csi-rbd&#34; lacks of capabilities to support &#39;Virtual Images on PVC&#39; function; use StorageClass that supports volume mode &#39;Block&#39; and access mode &#39;ReadWriteMany&#39;&#xA;&#xA;Unexpected error:&#xA;    &lt;*exec.ExitError | 0x1400075e340&gt;: &#xA;    exit status 1&#xA;    {&#xA;        ProcessState: {&#xA;            pid: 84693,&#xA;            status: 256,&#xA;            rusage: {&#xA;                Utime: {&#xA;                    Sec: 0,&#xA;                    Usec: 294652,&#xA;                    Pad_cgo_0: [0, 0, 0, 0],&#xA;                },&#xA;                Stime: {&#xA;                    Sec: 0,&#xA;                    Usec: 60432,&#xA;                    Pad_cgo_0: [0, 0, 0, 0],&#xA;                },&#xA;                Maxrss: 70877184,&#xA;                Ixrss: 0,&#xA;                Idrss: 0,&#xA;                Isrss: 0,&#xA;                Minflt: 5139,&#xA;                Majflt: 3,&#xA;                Nswap: 0,&#xA;                Inblock: 0,&#xA;                Oublock: 0,&#xA;                Msgsnd: 49,&#xA;                Msgrcv: 54,&#xA;                Nsignals: 338,&#xA;                Nvcsw: 303,&#xA;                Nivcsw: 2716,&#xA;            },&#xA;        },&#xA;        Stderr: nil,&#xA;    }&#xA;occurred" type="failed">[FAILED] Warning: resource namespaces/head-5073ae15-end-to-end-image-hotplug is missing the kubectl.kubernetes.io/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create --save-config or kubectl apply. The missing annotation will be patched automatically.&#xA;Error from server (Forbidden): error when creating &#34;/tmp/testdata/image-hotplug&#34;: admission webhook &#34;vi.virtualization-controller.validate.d8-virtualization&#34; denied the request: the storage class &#34;ceph-pool-r2-csi-rbd&#34; lacks of capabilities to support &#39;Virtual Images on PVC&#39; function; use StorageClass that supports volume mode &#39;Block&#39; and access mode &#39;ReadWriteMany&#39;&#xA;&#xA;Unexpected error:&#xA;    &lt;*exec.ExitError | 0x1400075e340&gt;: &#xA;    exit status 1&#xA;    {&#xA;        ProcessState: {&#xA;            pid: 84693,&#xA;            status: 256,&#xA;            rusage: {&#xA;                Utime: {&#xA;                    Sec: 0,&#xA;                    Usec: 294652,&#xA;                    Pad_cgo_0: [0, 0, 0, 0],&#xA;                },&#xA;                Stime: {&#xA;                    Sec: 0,&#xA;                    Usec: 60432,&#xA;                    Pad_cgo_0: [0, 0, 0, 0],&#xA;                },&#xA;                Maxrss: 70877184,&#xA;                Ixrss: 0,&#xA;                Idrss: 0,&#xA;                Isrss: 0,&#xA;                Minflt: 5139,&#xA;                Majflt: 3,&#xA;                Nswap: 0,&#xA;                Inblock: 0,&#xA;                Oublock: 0,&#xA;                Msgsnd: 49,&#xA;                Msgrcv: 54,&#xA;                Nsignals: 338,&#xA;                Nvcsw: 303,&#xA;                Nivcsw: 2716,&#xA;            },&#xA;        },&#xA;        Stderr: nil,&#xA;    }&#xA;occurred&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/image_hotplug_test.go:109 @ 10/12/25 17:46:51.291&#xA;</failure>
              <system-err>&gt; Enter [BeforeAll] ImageHotplug - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/image_hotplug_test.go:54 @ 10/12/25 17:46:44.208&#xA;&lt; Exit [BeforeAll] ImageHotplug - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/image_hotplug_test.go:54 @ 10/12/25 17:46:47.332 (3.124s)&#xA;&gt; Enter [It] result should be succeeded - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/image_hotplug_test.go:77 @ 10/12/25 17:46:47.332&#xA;[FAILED] Warning: resource namespaces/head-5073ae15-end-to-end-image-hotplug is missing the kubectl.kubernetes.io/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create --save-config or kubectl apply. The missing annotation will be patched automatically.&#xA;Error from server (Forbidden): error when creating &#34;/tmp/testdata/image-hotplug&#34;: admission webhook &#34;vi.virtualization-controller.validate.d8-virtualization&#34; denied the request: the storage class &#34;ceph-pool-r2-csi-rbd&#34; lacks of capabilities to support &#39;Virtual Images on PVC&#39; function; use StorageClass that supports volume mode &#39;Block&#39; and access mode &#39;ReadWriteMany&#39;&#xA;&#xA;Unexpected error:&#xA;    &lt;*exec.ExitError | 0x1400075e340&gt;: &#xA;    exit status 1&#xA;    {&#xA;        ProcessState: {&#xA;            pid: 84693,&#xA;            status: 256,&#xA;            rusage: {&#xA;                Utime: {&#xA;                    Sec: 0,&#xA;                    Usec: 294652,&#xA;                    Pad_cgo_0: [0, 0, 0, 0],&#xA;                },&#xA;                Stime: {&#xA;                    Sec: 0,&#xA;                    Usec: 60432,&#xA;                    Pad_cgo_0: [0, 0, 0, 0],&#xA;                },&#xA;                Maxrss: 70877184,&#xA;                Ixrss: 0,&#xA;                Idrss: 0,&#xA;                Isrss: 0,&#xA;                Minflt: 5139,&#xA;                Majflt: 3,&#xA;                Nswap: 0,&#xA;                Inblock: 0,&#xA;                Oublock: 0,&#xA;                Msgsnd: 49,&#xA;                Msgrcv: 54,&#xA;                Nsignals: 338,&#xA;                Nvcsw: 303,&#xA;                Nivcsw: 2716,&#xA;            },&#xA;        },&#xA;        Stderr: nil,&#xA;    }&#xA;occurred&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/image_hotplug_test.go:109 @ 10/12/25 17:46:51.291&#xA;&lt; Exit [It] result should be succeeded - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/image_hotplug_test.go:77 @ 10/12/25 17:46:51.292 (3.96s)&#xA;&gt; Enter [AfterEach] ImageHotplug - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/image_hotplug_test.go:70 @ 10/12/25 17:46:51.292&#xA;The list of pods is empty; nothing to dump.&#xA;&lt; Exit [AfterEach] ImageHotplug - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/image_hotplug_test.go:70 @ 10/12/25 17:46:56.959 (5.668s)&#xA;</system-err>
          </testcase>
          <testcase name="[It] ImageHotplug When the virtualization resources are applied checks the resources phase" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/image_hotplug_test.go:112 @ 10/12/25 17:46:56.961&#xA;</system-err>
          </testcase>
          <testcase name="[It] ImageHotplug When the resources are ready to use retrieves the test objects" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/image_hotplug_test.go:147 @ 10/12/25 17:46:56.961&#xA;</system-err>
          </testcase>
          <testcase name="[It] ImageHotplug When the resources are ready to use retrieves the disk count before the images attachment" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/image_hotplug_test.go:190 @ 10/12/25 17:46:56.961&#xA;</system-err>
          </testcase>
          <testcase name="[It] ImageHotplug When the resources are ready to use attaches the images into the `VirtualMachine`" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/image_hotplug_test.go:196 @ 10/12/25 17:46:56.961&#xA;</system-err>
          </testcase>
          <testcase name="[It] ImageHotplug When the resources are ready to use checks the `VirtualMachine` and the `VirtualMachineBlockDeviceAttachments` phases" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/image_hotplug_test.go:204 @ 10/12/25 17:46:56.961&#xA;</system-err>
          </testcase>
          <testcase name="[It] ImageHotplug When the resources are ready to use compares the disk count before and after attachment" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/image_hotplug_test.go:224 @ 10/12/25 17:46:56.961&#xA;</system-err>
          </testcase>
          <testcase name="[It] ImageHotplug When the resources are ready to use checks that the `ISO` image is attached as `CD-ROM`" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/image_hotplug_test.go:236 @ 10/12/25 17:46:56.961&#xA;</system-err>
          </testcase>
          <testcase name="[It] ImageHotplug When the resources are ready to use check that the images are attached as the `ReadOnly` devices" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/image_hotplug_test.go:258 @ 10/12/25 17:46:56.961&#xA;</system-err>
          </testcase>
          <testcase name="[It] ImageHotplug When the resources are ready to use detaches the images" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/image_hotplug_test.go:284 @ 10/12/25 17:46:56.961&#xA;</system-err>
          </testcase>
          <testcase name="[It] ImageHotplug When the resources are ready to use compares the disk count after detachment" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/image_hotplug_test.go:294 @ 10/12/25 17:46:56.961&#xA;</system-err>
          </testcase>
          <testcase name="[It] ImageHotplug When test is completed deletes test case resources" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/image_hotplug_test.go:309 @ 10/12/25 17:46:56.961&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineLabelAndAnnotation When resources are applied result should be succeeded" classname="Tests" status="passed" time="5.000326916">
              <system-err>&gt; Enter [BeforeAll] VirtualMachineLabelAndAnnotation - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_label_annotation_test.go:42 @ 10/12/25 17:46:56.962&#xA;&lt; Exit [BeforeAll] VirtualMachineLabelAndAnnotation - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_label_annotation_test.go:42 @ 10/12/25 17:46:58.943 (1.981s)&#xA;&gt; Enter [BeforeEach] VirtualMachineLabelAndAnnotation - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_label_annotation_test.go:51 @ 10/12/25 17:46:58.943&#xA;&lt; Exit [BeforeEach] VirtualMachineLabelAndAnnotation - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_label_annotation_test.go:51 @ 10/12/25 17:46:58.943 (0s)&#xA;&gt; Enter [It] result should be succeeded - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_label_annotation_test.go:64 @ 10/12/25 17:46:58.943&#xA;&lt; Exit [It] result should be succeeded - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_label_annotation_test.go:64 @ 10/12/25 17:47:01.962 (3.019s)&#xA;&gt; Enter [AfterEach] VirtualMachineLabelAndAnnotation - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_label_annotation_test.go:57 @ 10/12/25 17:47:01.962&#xA;&lt; Exit [AfterEach] VirtualMachineLabelAndAnnotation - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_label_annotation_test.go:57 @ 10/12/25 17:47:01.962 (0s)&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineLabelAndAnnotation When virtual images are applied checks VIs phases" classname="Tests" status="failed" time="1008.391982916">
              <failure message="should observe resources in &#39;&#39;jsonpath={.status.phase}=Ready&#39;&#39; state before 16m40s timeout&#xA;Expected&#xA;    &lt;[]string | len:1, cap:1&gt;: [&#xA;        &#34;cmd: kubectl wait virtualimages.virtualization.deckhouse.io head-5073ae15-vi-alpine-http --namespace head-5073ae15-end-to-end-vm-label-annotation --for=&#39;jsonpath={.status.phase}=Ready&#39; --timeout=16m40s\nstderr: W1012 18:10:38.250308   84712 reflector.go:492] k8s.io/client-go/tools/watch/informerwatcher.go:146: watch of *unstructured.Unstructured ended with: an error on the server (\&#34;unable to decode an event from the watch stream: http2: client connection lost\&#34;) has prevented the request from succeeding\nW1012 18:43:39.991900   84712 reflector.go:492] k8s.io/client-go/tools/watch/informerwatcher.go:146: watch of *unstructured.Unstructured ended with: an error on the server (\&#34;unable to decode an event from the watch stream: http2: client connection lost\&#34;) has prevented the request from succeeding\nW1012 19:46:10.004982   84712 reflector.go:492] k8s.io/client-go/tools/watch/informerwatcher.go:146: watch of *unstructured.Unstructured ended with: an error on the server (\&#34;unable to decode an event from the watch stream: http2: client connection lost\&#34;) has prevented the request from succeeding\nerror: timed out waiting for the condition on virtualimages/head-5073ae15-vi-alpine-http\n\nwaited for: &#39;jsonpath={.status.phase}=Ready&#39;&#34;,&#xA;    ]&#xA;to be empty" type="failed">[FAILED] should observe resources in &#39;&#39;jsonpath={.status.phase}=Ready&#39;&#39; state before 16m40s timeout&#xA;Expected&#xA;    &lt;[]string | len:1, cap:1&gt;: [&#xA;        &#34;cmd: kubectl wait virtualimages.virtualization.deckhouse.io head-5073ae15-vi-alpine-http --namespace head-5073ae15-end-to-end-vm-label-annotation --for=&#39;jsonpath={.status.phase}=Ready&#39; --timeout=16m40s\nstderr: W1012 18:10:38.250308   84712 reflector.go:492] k8s.io/client-go/tools/watch/informerwatcher.go:146: watch of *unstructured.Unstructured ended with: an error on the server (\&#34;unable to decode an event from the watch stream: http2: client connection lost\&#34;) has prevented the request from succeeding\nW1012 18:43:39.991900   84712 reflector.go:492] k8s.io/client-go/tools/watch/informerwatcher.go:146: watch of *unstructured.Unstructured ended with: an error on the server (\&#34;unable to decode an event from the watch stream: http2: client connection lost\&#34;) has prevented the request from succeeding\nW1012 19:46:10.004982   84712 reflector.go:492] k8s.io/client-go/tools/watch/informerwatcher.go:146: watch of *unstructured.Unstructured ended with: an error on the server (\&#34;unable to decode an event from the watch stream: http2: client connection lost\&#34;) has prevented the request from succeeding\nerror: timed out waiting for the condition on virtualimages/head-5073ae15-vi-alpine-http\n\nwaited for: &#39;jsonpath={.status.phase}=Ready&#39;&#34;,&#xA;    ]&#xA;to be empty&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_label_annotation_test.go:76 @ 10/12/25 19:53:44.073&#xA;</failure>
              <system-err>&gt; Enter [BeforeEach] VirtualMachineLabelAndAnnotation - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_label_annotation_test.go:51 @ 10/12/25 17:47:01.962&#xA;&lt; Exit [BeforeEach] VirtualMachineLabelAndAnnotation - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_label_annotation_test.go:51 @ 10/12/25 17:47:01.962 (0s)&#xA;&gt; Enter [It] checks VIs phases - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_label_annotation_test.go:74 @ 10/12/25 17:47:01.962&#xA;STEP: VIs should be in Ready phases - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_label_annotation_test.go:75 @ 10/12/25 17:47:01.962&#xA;[FAILED] should observe resources in &#39;&#39;jsonpath={.status.phase}=Ready&#39;&#39; state before 16m40s timeout&#xA;Expected&#xA;    &lt;[]string | len:1, cap:1&gt;: [&#xA;        &#34;cmd: kubectl wait virtualimages.virtualization.deckhouse.io head-5073ae15-vi-alpine-http --namespace head-5073ae15-end-to-end-vm-label-annotation --for=&#39;jsonpath={.status.phase}=Ready&#39; --timeout=16m40s\nstderr: W1012 18:10:38.250308   84712 reflector.go:492] k8s.io/client-go/tools/watch/informerwatcher.go:146: watch of *unstructured.Unstructured ended with: an error on the server (\&#34;unable to decode an event from the watch stream: http2: client connection lost\&#34;) has prevented the request from succeeding\nW1012 18:43:39.991900   84712 reflector.go:492] k8s.io/client-go/tools/watch/informerwatcher.go:146: watch of *unstructured.Unstructured ended with: an error on the server (\&#34;unable to decode an event from the watch stream: http2: client connection lost\&#34;) has prevented the request from succeeding\nW1012 19:46:10.004982   84712 reflector.go:492] k8s.io/client-go/tools/watch/informerwatcher.go:146: watch of *unstructured.Unstructured ended with: an error on the server (\&#34;unable to decode an event from the watch stream: http2: client connection lost\&#34;) has prevented the request from succeeding\nerror: timed out waiting for the condition on virtualimages/head-5073ae15-vi-alpine-http\n\nwaited for: &#39;jsonpath={.status.phase}=Ready&#39;&#34;,&#xA;    ]&#xA;to be empty&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_label_annotation_test.go:76 @ 10/12/25 19:53:44.073&#xA;&lt; Exit [It] checks VIs phases - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_label_annotation_test.go:74 @ 10/12/25 19:53:44.073 (16m42.119s)&#xA;&gt; Enter [AfterEach] VirtualMachineLabelAndAnnotation - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_label_annotation_test.go:57 @ 10/12/25 19:53:44.073&#xA;The list of pods is empty; nothing to dump.&#xA;&lt; Exit [AfterEach] VirtualMachineLabelAndAnnotation - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_label_annotation_test.go:57 @ 10/12/25 19:53:50.346 (6.273s)&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineLabelAndAnnotation When virtual disks are applied checks VDs phases" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_label_annotation_test.go:85 @ 10/12/25 19:53:50.347&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineLabelAndAnnotation When virtual machines are applied checks VMs phases" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_label_annotation_test.go:96 @ 10/12/25 19:53:50.347&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineLabelAndAnnotation When virtual machine is running marks VMs with label map[&#34;specialKey&#34;:&#34;specialValue&#34;]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_label_annotation_test.go:107 @ 10/12/25 19:53:50.347&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineLabelAndAnnotation When virtual machine is running checks VMs and pods labels after VMs labeling" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_label_annotation_test.go:120 @ 10/12/25 19:53:50.348&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineLabelAndAnnotation When virtual machine is running removes label map[specialKey:specialValue] from VMs" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_label_annotation_test.go:152 @ 10/12/25 19:53:50.348&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineLabelAndAnnotation When virtual machine is running checks VMs and pods labels after VMs unlabeling" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_label_annotation_test.go:165 @ 10/12/25 19:53:50.348&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineLabelAndAnnotation Annotate `VirtualMachines` in Running phase marks VMs with annotation map[&#34;specialKey&#34;:&#34;specialValue&#34;]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_label_annotation_test.go:199 @ 10/12/25 19:53:50.348&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineLabelAndAnnotation Annotate `VirtualMachines` in Running phase checks VMs and pods annotations after VMs annotating" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_label_annotation_test.go:212 @ 10/12/25 19:53:50.348&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineLabelAndAnnotation Annotate `VirtualMachines` in Running phase removes annotation map[specialKey:specialValue] from VMs" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_label_annotation_test.go:244 @ 10/12/25 19:53:50.348&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineLabelAndAnnotation Annotate `VirtualMachines` in Running phase checks VMs and pods annotations after VMs unannotating" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_label_annotation_test.go:257 @ 10/12/25 19:53:50.348&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineLabelAndAnnotation When test is completed deletes test case resources" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_label_annotation_test.go:291 @ 10/12/25 19:53:50.348&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineConfiguration 1 When resources are applied result should be succeeded" classname="Tests" status="passed" time="6.801763167">
              <system-err>&gt; Enter [BeforeAll] VirtualMachineConfiguration 1 - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_configuration_test.go:49 @ 10/12/25 19:53:50.348&#xA;&lt; Exit [BeforeAll] VirtualMachineConfiguration 1 - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_configuration_test.go:49 @ 10/12/25 19:53:52.334 (1.986s)&#xA;&gt; Enter [It] result should be succeeded - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_configuration_test.go:65 @ 10/12/25 19:53:52.334&#xA;&lt; Exit [It] result should be succeeded - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_configuration_test.go:65 @ 10/12/25 19:53:57.15 (4.816s)&#xA;&gt; Enter [AfterEach] VirtualMachineConfiguration 1 - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_configuration_test.go:58 @ 10/12/25 19:53:57.15&#xA;&lt; Exit [AfterEach] VirtualMachineConfiguration 1 - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_configuration_test.go:58 @ 10/12/25 19:53:57.15 (0s)&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineConfiguration 1 When virtual images are applied checks VIs phases" classname="Tests" status="failed" time="1008.148127125">
              <failure message="should observe resources in &#39;&#39;jsonpath={.status.phase}=Ready&#39;&#39; state before 16m40s timeout&#xA;Expected&#xA;    &lt;[]string | len:1, cap:1&gt;: [&#xA;        &#34;cmd: kubectl wait virtualimages.virtualization.deckhouse.io head-5073ae15-vi-alpine-http --namespace head-5073ae15-end-to-end-vm-configuration --for=&#39;jsonpath={.status.phase}=Ready&#39; --timeout=16m40s\nstderr: error: timed out waiting for the condition on virtualimages/head-5073ae15-vi-alpine-http\n\nwaited for: &#39;jsonpath={.status.phase}=Ready&#39;&#34;,&#xA;    ]&#xA;to be empty" type="failed">[FAILED] should observe resources in &#39;&#39;jsonpath={.status.phase}=Ready&#39;&#39; state before 16m40s timeout&#xA;Expected&#xA;    &lt;[]string | len:1, cap:1&gt;: [&#xA;        &#34;cmd: kubectl wait virtualimages.virtualization.deckhouse.io head-5073ae15-vi-alpine-http --namespace head-5073ae15-end-to-end-vm-configuration --for=&#39;jsonpath={.status.phase}=Ready&#39; --timeout=16m40s\nstderr: error: timed out waiting for the condition on virtualimages/head-5073ae15-vi-alpine-http\n\nwaited for: &#39;jsonpath={.status.phase}=Ready&#39;&#34;,&#xA;    ]&#xA;to be empty&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_configuration_test.go:90 @ 10/12/25 20:10:39.292&#xA;</failure>
              <system-err>&gt; Enter [It] checks VIs phases - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_configuration_test.go:88 @ 10/12/25 19:53:57.15&#xA;STEP: VIs should be in Ready phases - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_configuration_test.go:89 @ 10/12/25 19:53:57.15&#xA;[FAILED] should observe resources in &#39;&#39;jsonpath={.status.phase}=Ready&#39;&#39; state before 16m40s timeout&#xA;Expected&#xA;    &lt;[]string | len:1, cap:1&gt;: [&#xA;        &#34;cmd: kubectl wait virtualimages.virtualization.deckhouse.io head-5073ae15-vi-alpine-http --namespace head-5073ae15-end-to-end-vm-configuration --for=&#39;jsonpath={.status.phase}=Ready&#39; --timeout=16m40s\nstderr: error: timed out waiting for the condition on virtualimages/head-5073ae15-vi-alpine-http\n\nwaited for: &#39;jsonpath={.status.phase}=Ready&#39;&#34;,&#xA;    ]&#xA;to be empty&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_configuration_test.go:90 @ 10/12/25 20:10:39.292&#xA;&lt; Exit [It] checks VIs phases - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_configuration_test.go:88 @ 10/12/25 20:10:39.292 (16m42.141s)&#xA;&gt; Enter [AfterEach] VirtualMachineConfiguration 1 - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_configuration_test.go:58 @ 10/12/25 20:10:39.292&#xA;The list of pods is empty; nothing to dump.&#xA;&lt; Exit [AfterEach] VirtualMachineConfiguration 1 - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_configuration_test.go:58 @ 10/12/25 20:10:45.299 (6.007s)&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineConfiguration 1 When virtual disks are applied should be in Ready phase" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_configuration_test.go:99 @ 10/12/25 20:10:45.3&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineConfiguration 1 When virtual machines are applied should be ready" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_configuration_test.go:109 @ 10/12/25 20:10:45.3&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineConfiguration 1 Manual restart approval mode 1 When virtual machine agents are ready changes the number of processor cores" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_configuration_test.go:123 @ 10/12/25 20:10:45.3&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineConfiguration 1 Manual restart approval mode 1 When virtual machine is patched checks the number of processor cores in specification" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_configuration_test.go:147 @ 10/12/25 20:10:45.3&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineConfiguration 1 Manual restart approval mode 1 When virtual machine is restarted should be ready" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_configuration_test.go:161 @ 10/12/25 20:10:45.3&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineConfiguration 1 Manual restart approval mode 1 When virtual machine agents are ready checks that the number of processor cores was changed" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_configuration_test.go:183 @ 10/12/25 20:10:45.3&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineConfiguration 1 Automatic restart approval mode 1 When virtual machine is in Running phase changes the number of processor cores" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_configuration_test.go:202 @ 10/12/25 20:10:45.3&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineConfiguration 1 Automatic restart approval mode 1 When virtual machine is patched checks the number of processor cores in specification" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_configuration_test.go:226 @ 10/12/25 20:10:45.3&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineConfiguration 1 Automatic restart approval mode 1 When virtual machine is restarted should be ready" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_configuration_test.go:240 @ 10/12/25 20:10:45.3&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineConfiguration 1 Automatic restart approval mode 1 When virtual machine agents are ready checks that the number of processor cores was changed" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_configuration_test.go:250 @ 10/12/25 20:10:45.3&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineConfiguration 1 When test is completed deletes test case resources" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_configuration_test.go:265 @ 10/12/25 20:10:45.3&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualDiskSnapshots When virtualization resources are applied: result should be succeeded" classname="Tests" status="failed" time="8.39020925">
              <failure message="immediate storage class cannot be nil; please set up the immediate storage class in the cluster&#xA;Expected&#xA;    &lt;*v1.StorageClass | 0x0&gt;: nil&#xA;not to be nil" type="failed">[FAILED] immediate storage class cannot be nil; please set up the immediate storage class in the cluster&#xA;Expected&#xA;    &lt;*v1.StorageClass | 0x0&gt;: nil&#xA;not to be nil&#xA;In [BeforeAll] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vd_snapshots_test.go:71 @ 10/12/25 20:10:47.275&#xA;</failure>
              <system-err>&gt; Enter [BeforeAll] VirtualDiskSnapshots - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vd_snapshots_test.go:55 @ 10/12/25 20:10:45.301&#xA;[FAILED] immediate storage class cannot be nil; please set up the immediate storage class in the cluster&#xA;Expected&#xA;    &lt;*v1.StorageClass | 0x0&gt;: nil&#xA;not to be nil&#xA;In [BeforeAll] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vd_snapshots_test.go:71 @ 10/12/25 20:10:47.275&#xA;&lt; Exit [BeforeAll] VirtualDiskSnapshots - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vd_snapshots_test.go:55 @ 10/12/25 20:10:47.275 (1.975s)&#xA;&gt; Enter [AfterEach] VirtualDiskSnapshots - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vd_snapshots_test.go:83 @ 10/12/25 20:10:47.275&#xA;The list of pods is empty; nothing to dump.&#xA;&lt; Exit [AfterEach] VirtualDiskSnapshots - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vd_snapshots_test.go:83 @ 10/12/25 20:10:53.691 (6.416s)&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualDiskSnapshots When virtual images are applied: checks VIs phases" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vd_snapshots_test.go:100 @ 10/12/25 20:10:53.691&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualDiskSnapshots When virtual disks are applied: checks VDs phases" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vd_snapshots_test.go:111 @ 10/12/25 20:10:53.691&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualDiskSnapshots When virtual machines are applied: checks VMs phases" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vd_snapshots_test.go:122 @ 10/12/25 20:10:53.692&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualDiskSnapshots When virtual machine block device attachments are applied: checks VMBDAs phases" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vd_snapshots_test.go:133 @ 10/12/25 20:10:53.692&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualDiskSnapshots When unattached VDs in phase Ready: creates VDs snapshots with `requiredConsistency`" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vd_snapshots_test.go:144 @ 10/12/25 20:10:53.692&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualDiskSnapshots When unattached VDs in phase Ready: checks snapshots of unattached VDs" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vd_snapshots_test.go:164 @ 10/12/25 20:10:53.692&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualDiskSnapshots When virtual machines in Running phase creates snapshots with `requiredConsistency` of attached VDs" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vd_snapshots_test.go:185 @ 10/12/25 20:10:53.692&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualDiskSnapshots When virtual machines in Running phase creates `vdSnapshots` concurrently" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vd_snapshots_test.go:229 @ 10/12/25 20:10:53.692&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualDiskSnapshots When virtual machines in Running phase checks snapshots" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vd_snapshots_test.go:290 @ 10/12/25 20:10:53.692&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualDiskSnapshots When virtual machines in Running phase checks `FileSystemFrozen` status of VMs" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vd_snapshots_test.go:341 @ 10/12/25 20:10:53.692&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualDiskSnapshots When test is completed deletes test case resources" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vd_snapshots_test.go:367 @ 10/12/25 20:10:53.693&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualImageCreation When resources are applied result should be succeeded" classname="Tests" status="failed" time="7.604343458">
              <failure message="immediate storage class cannot be nil; please set up the immediate storage class in the cluster&#xA;Expected&#xA;    &lt;*v1.StorageClass | 0x0&gt;: nil&#xA;not to be nil" type="failed">[FAILED] immediate storage class cannot be nil; please set up the immediate storage class in the cluster&#xA;Expected&#xA;    &lt;*v1.StorageClass | 0x0&gt;: nil&#xA;not to be nil&#xA;In [BeforeAll] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/images_creation_test.go:51 @ 10/12/25 20:10:55.673&#xA;</failure>
              <system-err>&gt; Enter [BeforeAll] VirtualImageCreation - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/images_creation_test.go:39 @ 10/12/25 20:10:53.693&#xA;[FAILED] immediate storage class cannot be nil; please set up the immediate storage class in the cluster&#xA;Expected&#xA;    &lt;*v1.StorageClass | 0x0&gt;: nil&#xA;not to be nil&#xA;In [BeforeAll] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/images_creation_test.go:51 @ 10/12/25 20:10:55.673&#xA;&lt; Exit [BeforeAll] VirtualImageCreation - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/images_creation_test.go:39 @ 10/12/25 20:10:55.673 (1.981s)&#xA;&gt; Enter [AfterEach] VirtualImageCreation - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/images_creation_test.go:71 @ 10/12/25 20:10:55.673&#xA;The list of pods is empty; nothing to dump.&#xA;&lt; Exit [AfterEach] VirtualImageCreation - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/images_creation_test.go:71 @ 10/12/25 20:11:01.297 (5.624s)&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualImageCreation When base virtual resources are ready checks VD phase" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/images_creation_test.go:94 @ 10/12/25 20:11:01.297&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualImageCreation When base virtual resources are ready checks VDSnapshot phase" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/images_creation_test.go:103 @ 10/12/25 20:11:01.298&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualImageCreation When virtual images are applied checks VIs phases" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/images_creation_test.go:114 @ 10/12/25 20:11:01.298&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualImageCreation When virtual images are applied checks CVIs phases" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/images_creation_test.go:128 @ 10/12/25 20:11:01.298&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualImageCreation When test is completed deletes test case resources" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because an earlier spec in an ordered container failed"></skipped>
              <system-err>[SKIPPED] Spec skipped because an earlier spec in an ordered container failed&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/images_creation_test.go:139 @ 10/12/25 20:11:01.298&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineAdditionalNetworkInterfaces When resources are applied result should be succeeded [SIG-Migration]" classname="Tests" status="skipped" time="0.503348292">
              <skipped message="skipped - Module SDN is disabled. Skipping all tests for module SDN."></skipped>
              <system-err>&gt; Enter [BeforeAll] VirtualMachineAdditionalNetworkInterfaces - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_vpc_test.go:47 @ 10/12/25 20:11:01.298&#xA;[SKIPPED] Module SDN is disabled. Skipping all tests for module SDN.&#xA;In [BeforeAll] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_vpc_test.go:50 @ 10/12/25 20:11:01.8&#xA;&lt; Exit [BeforeAll] VirtualMachineAdditionalNetworkInterfaces - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_vpc_test.go:47 @ 10/12/25 20:11:01.801 (503ms)&#xA;&gt; Enter [AfterAll] VirtualMachineAdditionalNetworkInterfaces - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_vpc_test.go:60 @ 10/12/25 20:11:01.801&#xA;&lt; Exit [AfterAll] VirtualMachineAdditionalNetworkInterfaces - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_vpc_test.go:60 @ 10/12/25 20:11:01.801 (0s)&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineAdditionalNetworkInterfaces When virtual machines are applied checks VMs phases [SIG-Migration]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because Skip() was called in BeforeAll"></skipped>
              <system-err>[SKIPPED] Spec skipped because Skip() was called in BeforeAll&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_vpc_test.go:90 @ 10/12/25 20:11:01.802&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineAdditionalNetworkInterfaces When virtual machines are applied checks network availability [SIG-Migration]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because Skip() was called in BeforeAll"></skipped>
              <system-err>[SKIPPED] Spec skipped because Skip() was called in BeforeAll&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_vpc_test.go:98 @ 10/12/25 20:11:01.802&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineAdditionalNetworkInterfaces When virtual machine agents and network are ready starts migrations [SIG-Migration]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because Skip() was called in BeforeAll"></skipped>
              <system-err>[SKIPPED] Spec skipped because Skip() was called in BeforeAll&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_vpc_test.go:111 @ 10/12/25 20:11:01.802&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineAdditionalNetworkInterfaces When VMs migrations are applied checks VMs and VMOPs phases [SIG-Migration]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because Skip() was called in BeforeAll"></skipped>
              <system-err>[SKIPPED] Spec skipped because Skip() was called in BeforeAll&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_vpc_test.go:125 @ 10/12/25 20:11:01.802&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineAdditionalNetworkInterfaces When VMs migrations are applied checks VMs external connection after migrations [SIG-Migration]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because Skip() was called in BeforeAll"></skipped>
              <system-err>[SKIPPED] Spec skipped because Skip() was called in BeforeAll&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_vpc_test.go:141 @ 10/12/25 20:11:01.802&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineAdditionalNetworkInterfaces When VMs migrations are applied checks network availability after migrations [SIG-Migration]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because Skip() was called in BeforeAll"></skipped>
              <system-err>[SKIPPED] Spec skipped because Skip() was called in BeforeAll&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_vpc_test.go:156 @ 10/12/25 20:11:01.802&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineAdditionalNetworkInterfaces When test is completed deletes test case resources [SIG-Migration]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped - Spec skipped because Skip() was called in BeforeAll"></skipped>
              <system-err>[SKIPPED] Spec skipped because Skip() was called in BeforeAll&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_vpc_test.go:169 @ 10/12/25 20:11:01.802&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineRestoreForce When the virtualization resources are applied result should be succeeded [SIG-Restoration]" classname="Tests" status="passed" time="7.939463292">
              <system-err>&gt; Enter [BeforeAll] VirtualMachineRestoreForce - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:55 @ 10/12/25 20:11:01.803&#xA;&lt; Exit [BeforeAll] VirtualMachineRestoreForce - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:55 @ 10/12/25 20:11:03.781 (1.978s)&#xA;&gt; Enter [BeforeEach] VirtualMachineRestoreForce - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:64 @ 10/12/25 20:11:03.781&#xA;&lt; Exit [BeforeEach] VirtualMachineRestoreForce - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:64 @ 10/12/25 20:11:03.781 (0s)&#xA;&gt; Enter [It] result should be succeeded - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:80 @ 10/12/25 20:11:03.781&#xA;&lt; Exit [It] result should be succeeded - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:80 @ 10/12/25 20:11:09.742 (5.961s)&#xA;&gt; Enter [AfterEach] VirtualMachineRestoreForce - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:71 @ 10/12/25 20:11:09.742&#xA;&lt; Exit [AfterEach] VirtualMachineRestoreForce - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:71 @ 10/12/25 20:11:09.742 (0s)&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineRestoreForce When the virtualization resources are applied checks the resources phase [SIG-Restoration]" classname="Tests" status="interrupted" time="377.350922792">
              <error message="Interrupted by User" type="interrupted">[INTERRUPTED] Interrupted by User&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:111 @ 10/12/25 20:17:24.214&#xA;&#xA;This is the Progress Report generated when the interrupt was received:&#xA;  VirtualMachineRestoreForce When the virtualization resources are applied checks the resources phase (Spec Runtime: 6m14.471s)&#xA;    /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:111&#xA;    In [It] (Node Runtime: 6m14.471s)&#xA;      /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:111&#xA;      At [By Step] `VirtualMachine` agent should be ready (Step Runtime: 6m14.471s)&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:112&#xA;&#xA;      Spec Goroutine&#xA;      goroutine 508 [sync.WaitGroup.Wait, 6 minutes]&#xA;        sync.runtime_SemacquireWaitGroup(0x100ee0b30?, 0x80?)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/runtime/sema.go:114&#xA;        sync.(*WaitGroup).Wait(0x14000b871d0)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/sync/waitgroup.go:206&#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e.WaitResources({0x14000956de0, 0x2, 0x102959e58?}, {0x102676a2d, 0x2a}, {{0x0, 0x0, 0x0}, 0x1400070b350, {0x14000bebd70, ...}, ...})&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:349&#xA;            | &#x9;&#x9;}()&#xA;            | &#x9;}&#xA;            &gt; &#x9;wg.Wait()&#xA;            | &#x9;Expect(waitErr).To(BeEmpty(), &#34;should observe resources in &#39;%s&#39; state before %s timeout&#34;, opts.For, opts.Timeout.String())&#xA;            | }&#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e.WaitByLabel({0x102676a2d, 0x2a}, {{0x0, 0x0, 0x0}, 0x1400070b350, {0x14000bebd70, 0x29}, {0x140007f1320, 0x22}, ...})&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:308&#xA;            | &#x9;&#x9;resources = strings.Split(res.StdOut(), &#34; &#34;)&#xA;            | &#x9;}&#xA;            &gt; &#x9;WaitResources(resources, resource, opts)&#xA;            | }&#xA;            | &#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e.WaitPhaseByLabel({0x102676a2d, 0x2a}, {0x102633a0a, 0x7}, {{0x0, 0x0, 0x0}, 0x1400070b350, {0x14000bebd70, 0x29}, ...})&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:290&#xA;            | &#x9;GinkgoHelper()&#xA;            | &#x9;opts.For = fmt.Sprintf(&#34;&#39;jsonpath={.status.phase}=%s&#39;&#34;, phase)&#xA;            &gt; &#x9;WaitByLabel(resource, opts)&#xA;            | }&#xA;            | &#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e.WaitVMAgentReady({{0x0, 0x0, 0x0}, 0x1400070b350, {0x14000bebd70, 0x29}, {0x0, 0x0}, 0xe8d4a51000})&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:274&#xA;            | func WaitVMAgentReady(opts kc.WaitOptions) {&#xA;            | &#x9;GinkgoHelper()&#xA;            &gt; &#x9;WaitPhaseByLabel(kc.ResourceVM, PhaseRunning, opts)&#xA;            | &#x9;WaitConditionIsTrueByLabel(kc.ResourceVM, vmcondition.TypeAgentReady.String(), opts)&#xA;            | }&#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e.init.func22.4.2.1()&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:113&#xA;            | It(&#34;checks the resources phase&#34;, func() {&#xA;            | &#x9;By(&#34;`VirtualMachine` agent should be ready&#34;, func() {&#xA;            &gt; &#x9;&#x9;WaitVMAgentReady(kc.WaitOptions{&#xA;            | &#x9;&#x9;&#x9;Labels:    testCaseLabel,&#xA;            | &#x9;&#x9;&#x9;Namespace: namespace,&#xA;        github.com/onsi/ginkgo/v2/internal.(*Suite).By(0x140000fd508, {0x10266ddb1, 0x26}, {0x14000b79f48, 0x1, 0x1025c3614?})&#xA;          /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/suite.go:323&#xA;        github.com/onsi/ginkgo/v2.By({0x10266ddb1?, 0x102ff5eb0?}, {0x14000918748?, 0x1400049a410?, 0x14000918758?})&#xA;          /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/core_dsl.go:600&#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e.init.func22.4.2()&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:112&#xA;            | &#xA;            | It(&#34;checks the resources phase&#34;, func() {&#xA;            &gt; &#x9;By(&#34;`VirtualMachine` agent should be ready&#34;, func() {&#xA;            | &#x9;&#x9;WaitVMAgentReady(kc.WaitOptions{&#xA;            | &#x9;&#x9;&#x9;Labels:    testCaseLabel,&#xA;        github.com/onsi/ginkgo/v2/internal.extractBodyFunction.func3({0x0?, 0x0?})&#xA;          /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/node.go:475&#xA;        github.com/onsi/ginkgo/v2/internal.(*Suite).runNode.func3()&#xA;          /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/suite.go:894&#xA;        github.com/onsi/ginkgo/v2/internal.(*Suite).runNode in goroutine 5&#xA;          /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/suite.go:881&#xA;&#xA;      Goroutines of Interest&#xA;      goroutine 512 [syscall, 6 minutes]&#xA;        syscall.syscall6(0x90010100954030?, 0x110a7faa0?, 0x105250f30?, 0x90?, 0x14000580008?, 0x14000968000?, 0x1400071fa58?)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/runtime/sys_darwin.go:60&#xA;        syscall.wait4(0x1400071fa88?, 0x100f626fc?, 0x90?, 0x102f5e120?)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/syscall/zsyscall_darwin_arm64.go:44&#xA;        syscall.Wait4(0x14000270380?, 0x1400071fac4, 0x14000954030?, 0x140002702a0?)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/syscall/syscall_bsd.go:144&#xA;        os.(*Process).pidWait.func1(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec_unix.go:64&#xA;        os.ignoringEINTR2[...](...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file_posix.go:266&#xA;        os.(*Process).pidWait(0x14000434900)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec_unix.go:63&#xA;        os.(*Process).wait(0x1400090a408?)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec_unix.go:28&#xA;        os.(*Process).Wait(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec.go:340&#xA;        os/exec.(*Cmd).Wait(0x14000908000)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:922&#xA;        os/exec.(*Cmd).Run(0x14000908000)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:626&#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e/executor.CMDExecutor.ExecuteContext({{0x140002a34f0?, 0x102ff5e88?, 0x14000270000?}}, {0x103016488?, 0x14000270000?}, {0x14000e3a0d0?, 0xc233172ab5e082d0?}, {0x102feed80, 0x14000434800}, {0x102feed80, ...})&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/executor/executor.go:76&#xA;            | &#x9;cmd.Stderr = stderr&#xA;            | &#x9;cmd.Stdout = stdout&#xA;            &gt; &#x9;return cmd.Run()&#xA;            | }&#xA;            | &#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e/executor.CMDExecutor.ExecContext({{0x140002a34f0?, 0x104503728?, 0x1044d9fa0?}}, {0x103016488, 0x14000270000}, {0x14000e3a0d0, 0xd0})&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/executor/executor.go:49&#xA;            | stdout := new(Buffer)&#xA;            | stderr := new(Buffer)&#xA;            &gt; err := e.ExecuteContext(ctx, command, stdout, stderr)&#xA;            | cmdResult := &amp;CMDResult{&#xA;            | &#x9;stdOut:  stdout,&#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e/kubectl.KubectlCMD.WaitResource({{0x10301aa38?, 0x1400000fde8?}, {0x102633fba?, 0x1400071fe88?}}, {0x102676a2d, 0x2a}, {0x14000b56a00, 0x28}, {{0x0, 0x0, ...}, ...})&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/kubectl/kubectl.go:260&#xA;            | &#x9;ctx, cancel := context.WithTimeout(context.Background(), timeout)&#xA;            | &#x9;defer cancel()&#xA;            &gt; &#x9;return k.ExecContext(ctx, cmd)&#xA;            | }&#xA;            | &#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e.WaitResources.func1()&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:341&#xA;            | go func() {&#xA;            | &#x9;defer wg.Done()&#xA;            &gt; &#x9;res := kubectl.WaitResource(resource, name, waitOpts)&#xA;            | &#x9;if res.Error() != nil {&#xA;            | &#x9;&#x9;mu.Lock()&#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e.WaitResources in goroutine 508&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:339&#xA;            | for _, name := range resources {&#xA;            | &#x9;wg.Add(1)&#xA;            &gt; &#x9;go func() {&#xA;            | &#x9;&#x9;defer wg.Done()&#xA;            | &#x9;&#x9;res := kubectl.WaitResource(resource, name, waitOpts)&#xA;&#xA;      goroutine 513 [syscall, 6 minutes]&#xA;        syscall.syscall6(0x10067a840?, 0x110a8eaf0?, 0x105250a78?, 0x90?, 0x140000a5008?, 0x14000882090?, 0x1400097ba58?)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/runtime/sys_darwin.go:60&#xA;        syscall.wait4(0x1400097ba88?, 0x100f626fc?, 0x90?, 0x102f5e120?)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/syscall/zsyscall_darwin_arm64.go:44&#xA;        syscall.Wait4(0x14000490380?, 0x1400097bac4, 0x1400067a840?, 0x140004902a0?)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/syscall/syscall_bsd.go:144&#xA;        os.(*Process).pidWait.func1(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec_unix.go:64&#xA;        os.ignoringEINTR2[...](...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file_posix.go:266&#xA;        os.(*Process).pidWait(0x14000596600)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec_unix.go:63&#xA;        os.(*Process).wait(0x140008c4408?)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec_unix.go:28&#xA;        os.(*Process).Wait(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec.go:340&#xA;        os/exec.(*Cmd).Wait(0x140008c0000)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:922&#xA;        os/exec.(*Cmd).Run(0x140008c0000)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:626&#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e/executor.CMDExecutor.ExecuteContext({{0x140002a34f0?, 0x102ff5e88?, 0x140004900e0?}}, {0x103016488?, 0x140004900e0?}, {0x140008b6000?, 0xc233172ab5e0ec48?}, {0x102feed80, 0x14000596000}, {0x102feed80, ...})&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/executor/executor.go:76&#xA;            | &#x9;cmd.Stderr = stderr&#xA;            | &#x9;cmd.Stdout = stdout&#xA;            &gt; &#x9;return cmd.Run()&#xA;            | }&#xA;            | &#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e/executor.CMDExecutor.ExecContext({{0x140002a34f0?, 0x104503728?, 0x1044d9fa0?}}, {0x103016488, 0x140004900e0}, {0x140008b6000, 0xc6})&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/executor/executor.go:49&#xA;            | stdout := new(Buffer)&#xA;            | stderr := new(Buffer)&#xA;            &gt; err := e.ExecuteContext(ctx, command, stdout, stderr)&#xA;            | cmdResult := &amp;CMDResult{&#xA;            | &#x9;stdOut:  stdout,&#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e/kubectl.KubectlCMD.WaitResource({{0x10301aa38?, 0x1400000fde8?}, {0x102633fba?, 0x14000a20f40?}}, {0x102676a2d, 0x2a}, {0x14000b56a29, 0x1e}, {{0x0, 0x0, ...}, ...})&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/kubectl/kubectl.go:260&#xA;            | &#x9;ctx, cancel := context.WithTimeout(context.Background(), timeout)&#xA;            | &#x9;defer cancel()&#xA;            &gt; &#x9;return k.ExecContext(ctx, cmd)&#xA;            | }&#xA;            | &#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e.WaitResources.func1()&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:341&#xA;            | go func() {&#xA;            | &#x9;defer wg.Done()&#xA;            &gt; &#x9;res := kubectl.WaitResource(resource, name, waitOpts)&#xA;            | &#x9;if res.Error() != nil {&#xA;            | &#x9;&#x9;mu.Lock()&#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e.WaitResources in goroutine 508&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:339&#xA;            | for _, name := range resources {&#xA;            | &#x9;wg.Add(1)&#xA;            &gt; &#x9;go func() {&#xA;            | &#x9;&#x9;defer wg.Done()&#xA;            | &#x9;&#x9;res := kubectl.WaitResource(resource, name, waitOpts)&#xA;&#xA;      Other Goroutines&#xA;      goroutine 5 [running]&#xA;        github.com/onsi/ginkgo/v2/internal.extractRunningGoroutines()&#xA;          /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/progress_report.go:181&#xA;        github.com/onsi/ginkgo/v2/internal.NewProgressReport(_, {{0x14000956c00, 0x2, 0x2}, {0x14000255340, 0x2, 0x2}, {0x1400028de30, 0x2, 0x2}, ...}, ...)&#xA;          /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/progress_report.go:75&#xA;        github.com/onsi/ginkgo/v2/internal.(*Suite).generateProgressReport(_, _)&#xA;          /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/suite.go:381&#xA;        github.com/onsi/ginkgo/v2/internal.(*Suite).runNode(_, {0x17a, 0x4, {0x102655aa3, 0x1a}, 0x140000a2290, {{0x10371dce5, 0x56}, 0x6f, {0x0, ...}, ...}, ...}, ...)&#xA;          /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/suite.go:980&#xA;        github.com/onsi/ginkgo/v2/internal.(*group).attemptSpec(0x140007537f0, 0x1, {{0x140006ef508?, 0x14000255340?, 0x2?}, 0x0?})&#xA;          /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/group.go:199&#xA;        github.com/onsi/ginkgo/v2/internal.(*group).run(0x140007537f0, {0x14000b58000?, 0x0?, 0x0?})&#xA;          /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/group.go:349&#xA;        github.com/onsi/ginkgo/v2/internal.(*Suite).runSpecs(0x140000fd508, {0x102630f2b, 0x5}, {0x104503728, 0x0, 0x0}, {0x1400005a0f4, 0x3d}, 0x0, {0x14000092c08, ...})&#xA;          /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/suite.go:489&#xA;        github.com/onsi/ginkgo/v2/internal.(*Suite).Run(_, {_, _}, {_, _, _}, {_, _}, _, {_, ...}, ...)&#xA;          /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/suite.go:130&#xA;        github.com/onsi/ginkgo/v2.RunSpecs({0x102fee0a0, 0x14000602c40}, {0x102630f2b, 0x5}, {0x0, 0x0, 0x0})&#xA;          /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/core_dsl.go:300&#xA;        github.com/deckhouse/virtualization/tests/e2e.TestE2E(0x14000602c40)&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/e2e_test.go:76&#xA;        testing.tRunner(0x14000602c40, 0x102fddc50)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/testing/testing.go:1934&#xA;        testing.(*T).Run in goroutine 1&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/testing/testing.go:1997&#xA;&#xA;      goroutine 1 [chan receive, 126 minutes]&#xA;        testing.(*T).Run(0x14000602a80, {0x10263399a?, 0x140005a1b38?}, 0x102fddc50)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/testing/testing.go:2005&#xA;        testing.runTests.func1(0x14000602a80)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/testing/testing.go:2477&#xA;        testing.tRunner(0x14000602a80, 0x140005a1c68)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/testing/testing.go:1934&#xA;        testing.runTests(0x1400000ed50, {0x104488fd0, 0x1, 0x1}, {0x14000708f20?, 0xf?, 0x0?})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/testing/testing.go:2475&#xA;        testing.(*M).Run(0x140004d6460)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/testing/testing.go:2337&#xA;        main.main()&#xA;          _testmain.go:45&#xA;&#xA;      goroutine 41 [syscall]&#xA;        os/signal.signal_recv()&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/runtime/sigqueue.go:149&#xA;        os/signal.loop()&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/signal/signal_unix.go:23&#xA;        os/signal.Notify.func1.1 in goroutine 5&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/signal/signal.go:152&#xA;&#xA;      goroutine 31 [select, 126 minutes]&#xA;        github.com/onsi/ginkgo/v2/internal.RegisterForProgressSignal.func1()&#xA;          /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/progress_report.go:32&#xA;        github.com/onsi/ginkgo/v2/internal.RegisterForProgressSignal in goroutine 5&#xA;          /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/progress_report.go:30&#xA;&#xA;      goroutine 66 [select]&#xA;        github.com/onsi/ginkgo/v2/internal/interrupt_handler.(*InterruptHandler).registerForInterrupts.func2(0x0?)&#xA;          /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/interrupt_handler/interrupt_handler.go:131&#xA;        github.com/onsi/ginkgo/v2/internal/interrupt_handler.(*InterruptHandler).registerForInterrupts in goroutine 5&#xA;          /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/interrupt_handler/interrupt_handler.go:128&#xA;&#xA;      goroutine 396 [IO wait, 6 minutes]&#xA;        internal/poll.runtime_pollWait(0x110980400, 0x72)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/runtime/netpoll.go:351&#xA;        internal/poll.(*pollDesc).wait(0x1400078a2a0?, 0x14000a4c000?, 0x1)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_poll_runtime.go:84&#xA;        internal/poll.(*pollDesc).waitRead(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_poll_runtime.go:89&#xA;        internal/poll.(*FD).Read(0x1400078a2a0, {0x14000a4c000, 0x8000, 0x8000})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_unix.go:165&#xA;        os.(*File).read(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file_posix.go:29&#xA;        os.(*File).Read(0x140004280c8, {0x14000a4c000?, 0x14000978da8?, 0x100ea3a18?})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:144&#xA;        io.copyBuffer({0x102feed80, 0x14000434880}, {0x102fedec8, 0x140008b4210}, {0x0, 0x0, 0x0})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:429&#xA;        io.Copy(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:388&#xA;        os.genericWriteTo(0x1?, {0x102feed80, 0x14000434880})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:295&#xA;        os.(*File).WriteTo(0x104489230?, {0x102feed80?, 0x14000434880?})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:273&#xA;        io.copyBuffer({0x102feed80, 0x14000434880}, {0x102fedfc0, 0x140004280c8}, {0x0, 0x0, 0x0})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:411&#xA;        io.Copy(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:388&#xA;        os/exec.(*Cmd).writerDescriptor.func1()&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:596&#xA;        os/exec.(*Cmd).Start.func2(0x0?)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:749&#xA;        os/exec.(*Cmd).Start in goroutine 512&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:748&#xA;&#xA;      goroutine 442 [select, 6 minutes]&#xA;        os/exec.(*Cmd).watchCtx(0x140008c0000, 0x1400098c070)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:789&#xA;        os/exec.(*Cmd).Start in goroutine 513&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:775&#xA;&#xA;      goroutine 397 [select, 6 minutes]&#xA;        os/exec.(*Cmd).watchCtx(0x14000908000, 0x1400011a620)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:789&#xA;        os/exec.(*Cmd).Start in goroutine 512&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:775&#xA;&#xA;      goroutine 441 [IO wait, 6 minutes]&#xA;        internal/poll.runtime_pollWait(0x11075d600, 0x72)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/runtime/netpoll.go:351&#xA;        internal/poll.(*pollDesc).wait(0x14000074240?, 0x14000a34000?, 0x1)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_poll_runtime.go:84&#xA;        internal/poll.(*pollDesc).waitRead(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_poll_runtime.go:89&#xA;        internal/poll.(*FD).Read(0x14000074240, {0x14000a34000, 0x8000, 0x8000})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_unix.go:165&#xA;        os.(*File).read(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file_posix.go:29&#xA;        os.(*File).Read(0x140001261e8, {0x14000a34000?, 0x14000512da8?, 0x100ea3a18?})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:144&#xA;        io.copyBuffer({0x102feed80, 0x14000596580}, {0x102fedec8, 0x140008b4208}, {0x0, 0x0, 0x0})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:429&#xA;        io.Copy(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:388&#xA;        os.genericWriteTo(0x14000512e01?, {0x102feed80, 0x14000596580})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:295&#xA;        os.(*File).WriteTo(0x104489230?, {0x102feed80?, 0x14000596580?})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:273&#xA;        io.copyBuffer({0x102feed80, 0x14000596580}, {0x102fedfc0, 0x140001261e8}, {0x0, 0x0, 0x0})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:411&#xA;        io.Copy(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:388&#xA;        os/exec.(*Cmd).writerDescriptor.func1()&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:596&#xA;        os/exec.(*Cmd).Start.func2(0x1400023e070?)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:749&#xA;        os/exec.(*Cmd).Start in goroutine 513&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:748&#xA;&#xA;      goroutine 395 [IO wait, 6 minutes]&#xA;        internal/poll.runtime_pollWait(0x11075e000, 0x72)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/runtime/netpoll.go:351&#xA;        internal/poll.(*pollDesc).wait(0x1400078a1e0?, 0x14000a3c000?, 0x1)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_poll_runtime.go:84&#xA;        internal/poll.(*pollDesc).waitRead(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_poll_runtime.go:89&#xA;        internal/poll.(*FD).Read(0x1400078a1e0, {0x14000a3c000, 0x8000, 0x8000})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_unix.go:165&#xA;        os.(*File).read(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file_posix.go:29&#xA;        os.(*File).Read(0x14000428068, {0x14000a3c000?, 0x14000977da8?, 0x100ea3a18?})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:144&#xA;        io.copyBuffer({0x102feed80, 0x14000434800}, {0x102fedec8, 0x1400049e6e0}, {0x0, 0x0, 0x0})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:429&#xA;        io.Copy(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:388&#xA;        os.genericWriteTo(0x1?, {0x102feed80, 0x14000434800})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:295&#xA;        os.(*File).WriteTo(0x104489230?, {0x102feed80?, 0x14000434800?})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:273&#xA;        io.copyBuffer({0x102feed80, 0x14000434800}, {0x102fedfc0, 0x14000428068}, {0x0, 0x0, 0x0})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:411&#xA;        io.Copy(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:388&#xA;        os/exec.(*Cmd).writerDescriptor.func1()&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:596&#xA;        os/exec.(*Cmd).Start.func2(0x0?)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:749&#xA;        os/exec.(*Cmd).Start in goroutine 512&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:748&#xA;&#xA;      goroutine 440 [IO wait, 6 minutes]&#xA;        internal/poll.runtime_pollWait(0x11097fc00, 0x72)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/runtime/netpoll.go:351&#xA;        internal/poll.(*pollDesc).wait(0x14000074060?, 0x14000a22000?, 0x1)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_poll_runtime.go:84&#xA;        internal/poll.(*pollDesc).waitRead(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_poll_runtime.go:89&#xA;        internal/poll.(*FD).Read(0x14000074060, {0x14000a22000, 0x8000, 0x8000})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_unix.go:165&#xA;        os.(*File).read(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file_posix.go:29&#xA;        os.(*File).Read(0x140001260d0, {0x14000a22000?, 0x14000515da8?, 0x100ea3a18?})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:144&#xA;        io.copyBuffer({0x102feed80, 0x14000596000}, {0x102fedec8, 0x1400049e6d8}, {0x0, 0x0, 0x0})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:429&#xA;        io.Copy(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:388&#xA;        os.genericWriteTo(0x14000515e01?, {0x102feed80, 0x14000596000})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:295&#xA;        os.(*File).WriteTo(0x104489230?, {0x102feed80?, 0x14000596000?})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:273&#xA;        io.copyBuffer({0x102feed80, 0x14000596000}, {0x102fedfc0, 0x140001260d0}, {0x0, 0x0, 0x0})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:411&#xA;        io.Copy(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:388&#xA;        os/exec.(*Cmd).writerDescriptor.func1()&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:596&#xA;        os/exec.(*Cmd).Start.func2(0x14000a05be0?)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:749&#xA;        os/exec.(*Cmd).Start in goroutine 513&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:748&#xA;&#xA;There were additional failures detected after the initial failure. These are visible in the timeline&#xA;</error>
              <system-err>&gt; Enter [BeforeEach] VirtualMachineRestoreForce - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:64 @ 10/12/25 20:11:09.742&#xA;&lt; Exit [BeforeEach] VirtualMachineRestoreForce - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:64 @ 10/12/25 20:11:09.742 (0s)&#xA;&gt; Enter [It] checks the resources phase - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:111 @ 10/12/25 20:11:09.742&#xA;STEP: `VirtualMachine` agent should be ready - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:112 @ 10/12/25 20:11:09.742&#xA;[INTERRUPTED] Interrupted by User&#xA;In [It] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:111 @ 10/12/25 20:17:24.214&#xA;&#xA;This is the Progress Report generated when the interrupt was received:&#xA;  VirtualMachineRestoreForce When the virtualization resources are applied checks the resources phase (Spec Runtime: 6m14.471s)&#xA;    /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:111&#xA;    In [It] (Node Runtime: 6m14.471s)&#xA;      /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:111&#xA;      At [By Step] `VirtualMachine` agent should be ready (Step Runtime: 6m14.471s)&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:112&#xA;&#xA;      Spec Goroutine&#xA;      goroutine 508 [sync.WaitGroup.Wait, 6 minutes]&#xA;        sync.runtime_SemacquireWaitGroup(0x100ee0b30?, 0x80?)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/runtime/sema.go:114&#xA;        sync.(*WaitGroup).Wait(0x14000b871d0)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/sync/waitgroup.go:206&#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e.WaitResources({0x14000956de0, 0x2, 0x102959e58?}, {0x102676a2d, 0x2a}, {{0x0, 0x0, 0x0}, 0x1400070b350, {0x14000bebd70, ...}, ...})&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:349&#xA;            | &#x9;&#x9;}()&#xA;            | &#x9;}&#xA;            &gt; &#x9;wg.Wait()&#xA;            | &#x9;Expect(waitErr).To(BeEmpty(), &#34;should observe resources in &#39;%s&#39; state before %s timeout&#34;, opts.For, opts.Timeout.String())&#xA;            | }&#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e.WaitByLabel({0x102676a2d, 0x2a}, {{0x0, 0x0, 0x0}, 0x1400070b350, {0x14000bebd70, 0x29}, {0x140007f1320, 0x22}, ...})&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:308&#xA;            | &#x9;&#x9;resources = strings.Split(res.StdOut(), &#34; &#34;)&#xA;            | &#x9;}&#xA;            &gt; &#x9;WaitResources(resources, resource, opts)&#xA;            | }&#xA;            | &#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e.WaitPhaseByLabel({0x102676a2d, 0x2a}, {0x102633a0a, 0x7}, {{0x0, 0x0, 0x0}, 0x1400070b350, {0x14000bebd70, 0x29}, ...})&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:290&#xA;            | &#x9;GinkgoHelper()&#xA;            | &#x9;opts.For = fmt.Sprintf(&#34;&#39;jsonpath={.status.phase}=%s&#39;&#34;, phase)&#xA;            &gt; &#x9;WaitByLabel(resource, opts)&#xA;            | }&#xA;            | &#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e.WaitVMAgentReady({{0x0, 0x0, 0x0}, 0x1400070b350, {0x14000bebd70, 0x29}, {0x0, 0x0}, 0xe8d4a51000})&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:274&#xA;            | func WaitVMAgentReady(opts kc.WaitOptions) {&#xA;            | &#x9;GinkgoHelper()&#xA;            &gt; &#x9;WaitPhaseByLabel(kc.ResourceVM, PhaseRunning, opts)&#xA;            | &#x9;WaitConditionIsTrueByLabel(kc.ResourceVM, vmcondition.TypeAgentReady.String(), opts)&#xA;            | }&#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e.init.func22.4.2.1()&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:113&#xA;            | It(&#34;checks the resources phase&#34;, func() {&#xA;            | &#x9;By(&#34;`VirtualMachine` agent should be ready&#34;, func() {&#xA;            &gt; &#x9;&#x9;WaitVMAgentReady(kc.WaitOptions{&#xA;            | &#x9;&#x9;&#x9;Labels:    testCaseLabel,&#xA;            | &#x9;&#x9;&#x9;Namespace: namespace,&#xA;        github.com/onsi/ginkgo/v2/internal.(*Suite).By(0x140000fd508, {0x10266ddb1, 0x26}, {0x14000b79f48, 0x1, 0x1025c3614?})&#xA;          /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/suite.go:323&#xA;        github.com/onsi/ginkgo/v2.By({0x10266ddb1?, 0x102ff5eb0?}, {0x14000918748?, 0x1400049a410?, 0x14000918758?})&#xA;          /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/core_dsl.go:600&#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e.init.func22.4.2()&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:112&#xA;            | &#xA;            | It(&#34;checks the resources phase&#34;, func() {&#xA;            &gt; &#x9;By(&#34;`VirtualMachine` agent should be ready&#34;, func() {&#xA;            | &#x9;&#x9;WaitVMAgentReady(kc.WaitOptions{&#xA;            | &#x9;&#x9;&#x9;Labels:    testCaseLabel,&#xA;        github.com/onsi/ginkgo/v2/internal.extractBodyFunction.func3({0x0?, 0x0?})&#xA;          /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/node.go:475&#xA;        github.com/onsi/ginkgo/v2/internal.(*Suite).runNode.func3()&#xA;          /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/suite.go:894&#xA;        github.com/onsi/ginkgo/v2/internal.(*Suite).runNode in goroutine 5&#xA;          /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/suite.go:881&#xA;&#xA;      Goroutines of Interest&#xA;      goroutine 512 [syscall, 6 minutes]&#xA;        syscall.syscall6(0x90010100954030?, 0x110a7faa0?, 0x105250f30?, 0x90?, 0x14000580008?, 0x14000968000?, 0x1400071fa58?)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/runtime/sys_darwin.go:60&#xA;        syscall.wait4(0x1400071fa88?, 0x100f626fc?, 0x90?, 0x102f5e120?)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/syscall/zsyscall_darwin_arm64.go:44&#xA;        syscall.Wait4(0x14000270380?, 0x1400071fac4, 0x14000954030?, 0x140002702a0?)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/syscall/syscall_bsd.go:144&#xA;        os.(*Process).pidWait.func1(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec_unix.go:64&#xA;        os.ignoringEINTR2[...](...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file_posix.go:266&#xA;        os.(*Process).pidWait(0x14000434900)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec_unix.go:63&#xA;        os.(*Process).wait(0x1400090a408?)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec_unix.go:28&#xA;        os.(*Process).Wait(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec.go:340&#xA;        os/exec.(*Cmd).Wait(0x14000908000)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:922&#xA;        os/exec.(*Cmd).Run(0x14000908000)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:626&#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e/executor.CMDExecutor.ExecuteContext({{0x140002a34f0?, 0x102ff5e88?, 0x14000270000?}}, {0x103016488?, 0x14000270000?}, {0x14000e3a0d0?, 0xc233172ab5e082d0?}, {0x102feed80, 0x14000434800}, {0x102feed80, ...})&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/executor/executor.go:76&#xA;            | &#x9;cmd.Stderr = stderr&#xA;            | &#x9;cmd.Stdout = stdout&#xA;            &gt; &#x9;return cmd.Run()&#xA;            | }&#xA;            | &#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e/executor.CMDExecutor.ExecContext({{0x140002a34f0?, 0x104503728?, 0x1044d9fa0?}}, {0x103016488, 0x14000270000}, {0x14000e3a0d0, 0xd0})&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/executor/executor.go:49&#xA;            | stdout := new(Buffer)&#xA;            | stderr := new(Buffer)&#xA;            &gt; err := e.ExecuteContext(ctx, command, stdout, stderr)&#xA;            | cmdResult := &amp;CMDResult{&#xA;            | &#x9;stdOut:  stdout,&#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e/kubectl.KubectlCMD.WaitResource({{0x10301aa38?, 0x1400000fde8?}, {0x102633fba?, 0x1400071fe88?}}, {0x102676a2d, 0x2a}, {0x14000b56a00, 0x28}, {{0x0, 0x0, ...}, ...})&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/kubectl/kubectl.go:260&#xA;            | &#x9;ctx, cancel := context.WithTimeout(context.Background(), timeout)&#xA;            | &#x9;defer cancel()&#xA;            &gt; &#x9;return k.ExecContext(ctx, cmd)&#xA;            | }&#xA;            | &#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e.WaitResources.func1()&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:341&#xA;            | go func() {&#xA;            | &#x9;defer wg.Done()&#xA;            &gt; &#x9;res := kubectl.WaitResource(resource, name, waitOpts)&#xA;            | &#x9;if res.Error() != nil {&#xA;            | &#x9;&#x9;mu.Lock()&#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e.WaitResources in goroutine 508&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:339&#xA;            | for _, name := range resources {&#xA;            | &#x9;wg.Add(1)&#xA;            &gt; &#x9;go func() {&#xA;            | &#x9;&#x9;defer wg.Done()&#xA;            | &#x9;&#x9;res := kubectl.WaitResource(resource, name, waitOpts)&#xA;&#xA;      goroutine 513 [syscall, 6 minutes]&#xA;        syscall.syscall6(0x10067a840?, 0x110a8eaf0?, 0x105250a78?, 0x90?, 0x140000a5008?, 0x14000882090?, 0x1400097ba58?)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/runtime/sys_darwin.go:60&#xA;        syscall.wait4(0x1400097ba88?, 0x100f626fc?, 0x90?, 0x102f5e120?)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/syscall/zsyscall_darwin_arm64.go:44&#xA;        syscall.Wait4(0x14000490380?, 0x1400097bac4, 0x1400067a840?, 0x140004902a0?)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/syscall/syscall_bsd.go:144&#xA;        os.(*Process).pidWait.func1(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec_unix.go:64&#xA;        os.ignoringEINTR2[...](...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file_posix.go:266&#xA;        os.(*Process).pidWait(0x14000596600)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec_unix.go:63&#xA;        os.(*Process).wait(0x140008c4408?)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec_unix.go:28&#xA;        os.(*Process).Wait(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec.go:340&#xA;        os/exec.(*Cmd).Wait(0x140008c0000)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:922&#xA;        os/exec.(*Cmd).Run(0x140008c0000)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:626&#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e/executor.CMDExecutor.ExecuteContext({{0x140002a34f0?, 0x102ff5e88?, 0x140004900e0?}}, {0x103016488?, 0x140004900e0?}, {0x140008b6000?, 0xc233172ab5e0ec48?}, {0x102feed80, 0x14000596000}, {0x102feed80, ...})&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/executor/executor.go:76&#xA;            | &#x9;cmd.Stderr = stderr&#xA;            | &#x9;cmd.Stdout = stdout&#xA;            &gt; &#x9;return cmd.Run()&#xA;            | }&#xA;            | &#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e/executor.CMDExecutor.ExecContext({{0x140002a34f0?, 0x104503728?, 0x1044d9fa0?}}, {0x103016488, 0x140004900e0}, {0x140008b6000, 0xc6})&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/executor/executor.go:49&#xA;            | stdout := new(Buffer)&#xA;            | stderr := new(Buffer)&#xA;            &gt; err := e.ExecuteContext(ctx, command, stdout, stderr)&#xA;            | cmdResult := &amp;CMDResult{&#xA;            | &#x9;stdOut:  stdout,&#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e/kubectl.KubectlCMD.WaitResource({{0x10301aa38?, 0x1400000fde8?}, {0x102633fba?, 0x14000a20f40?}}, {0x102676a2d, 0x2a}, {0x14000b56a29, 0x1e}, {{0x0, 0x0, ...}, ...})&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/kubectl/kubectl.go:260&#xA;            | &#x9;ctx, cancel := context.WithTimeout(context.Background(), timeout)&#xA;            | &#x9;defer cancel()&#xA;            &gt; &#x9;return k.ExecContext(ctx, cmd)&#xA;            | }&#xA;            | &#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e.WaitResources.func1()&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:341&#xA;            | go func() {&#xA;            | &#x9;defer wg.Done()&#xA;            &gt; &#x9;res := kubectl.WaitResource(resource, name, waitOpts)&#xA;            | &#x9;if res.Error() != nil {&#xA;            | &#x9;&#x9;mu.Lock()&#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e.WaitResources in goroutine 508&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:339&#xA;            | for _, name := range resources {&#xA;            | &#x9;wg.Add(1)&#xA;            &gt; &#x9;go func() {&#xA;            | &#x9;&#x9;defer wg.Done()&#xA;            | &#x9;&#x9;res := kubectl.WaitResource(resource, name, waitOpts)&#xA;&#xA;      Other Goroutines&#xA;      goroutine 5 [running]&#xA;        github.com/onsi/ginkgo/v2/internal.extractRunningGoroutines()&#xA;          /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/progress_report.go:181&#xA;        github.com/onsi/ginkgo/v2/internal.NewProgressReport(_, {{0x14000956c00, 0x2, 0x2}, {0x14000255340, 0x2, 0x2}, {0x1400028de30, 0x2, 0x2}, ...}, ...)&#xA;          /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/progress_report.go:75&#xA;        github.com/onsi/ginkgo/v2/internal.(*Suite).generateProgressReport(_, _)&#xA;          /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/suite.go:381&#xA;        github.com/onsi/ginkgo/v2/internal.(*Suite).runNode(_, {0x17a, 0x4, {0x102655aa3, 0x1a}, 0x140000a2290, {{0x10371dce5, 0x56}, 0x6f, {0x0, ...}, ...}, ...}, ...)&#xA;          /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/suite.go:980&#xA;        github.com/onsi/ginkgo/v2/internal.(*group).attemptSpec(0x140007537f0, 0x1, {{0x140006ef508?, 0x14000255340?, 0x2?}, 0x0?})&#xA;          /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/group.go:199&#xA;        github.com/onsi/ginkgo/v2/internal.(*group).run(0x140007537f0, {0x14000b58000?, 0x0?, 0x0?})&#xA;          /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/group.go:349&#xA;        github.com/onsi/ginkgo/v2/internal.(*Suite).runSpecs(0x140000fd508, {0x102630f2b, 0x5}, {0x104503728, 0x0, 0x0}, {0x1400005a0f4, 0x3d}, 0x0, {0x14000092c08, ...})&#xA;          /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/suite.go:489&#xA;        github.com/onsi/ginkgo/v2/internal.(*Suite).Run(_, {_, _}, {_, _, _}, {_, _}, _, {_, ...}, ...)&#xA;          /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/suite.go:130&#xA;        github.com/onsi/ginkgo/v2.RunSpecs({0x102fee0a0, 0x14000602c40}, {0x102630f2b, 0x5}, {0x0, 0x0, 0x0})&#xA;          /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/core_dsl.go:300&#xA;        github.com/deckhouse/virtualization/tests/e2e.TestE2E(0x14000602c40)&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/e2e_test.go:76&#xA;        testing.tRunner(0x14000602c40, 0x102fddc50)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/testing/testing.go:1934&#xA;        testing.(*T).Run in goroutine 1&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/testing/testing.go:1997&#xA;&#xA;      goroutine 1 [chan receive, 126 minutes]&#xA;        testing.(*T).Run(0x14000602a80, {0x10263399a?, 0x140005a1b38?}, 0x102fddc50)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/testing/testing.go:2005&#xA;        testing.runTests.func1(0x14000602a80)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/testing/testing.go:2477&#xA;        testing.tRunner(0x14000602a80, 0x140005a1c68)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/testing/testing.go:1934&#xA;        testing.runTests(0x1400000ed50, {0x104488fd0, 0x1, 0x1}, {0x14000708f20?, 0xf?, 0x0?})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/testing/testing.go:2475&#xA;        testing.(*M).Run(0x140004d6460)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/testing/testing.go:2337&#xA;        main.main()&#xA;          _testmain.go:45&#xA;&#xA;      goroutine 41 [syscall]&#xA;        os/signal.signal_recv()&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/runtime/sigqueue.go:149&#xA;        os/signal.loop()&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/signal/signal_unix.go:23&#xA;        os/signal.Notify.func1.1 in goroutine 5&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/signal/signal.go:152&#xA;&#xA;      goroutine 31 [select, 126 minutes]&#xA;        github.com/onsi/ginkgo/v2/internal.RegisterForProgressSignal.func1()&#xA;          /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/progress_report.go:32&#xA;        github.com/onsi/ginkgo/v2/internal.RegisterForProgressSignal in goroutine 5&#xA;          /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/progress_report.go:30&#xA;&#xA;      goroutine 66 [select]&#xA;        github.com/onsi/ginkgo/v2/internal/interrupt_handler.(*InterruptHandler).registerForInterrupts.func2(0x0?)&#xA;          /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/interrupt_handler/interrupt_handler.go:131&#xA;        github.com/onsi/ginkgo/v2/internal/interrupt_handler.(*InterruptHandler).registerForInterrupts in goroutine 5&#xA;          /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/interrupt_handler/interrupt_handler.go:128&#xA;&#xA;      goroutine 396 [IO wait, 6 minutes]&#xA;        internal/poll.runtime_pollWait(0x110980400, 0x72)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/runtime/netpoll.go:351&#xA;        internal/poll.(*pollDesc).wait(0x1400078a2a0?, 0x14000a4c000?, 0x1)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_poll_runtime.go:84&#xA;        internal/poll.(*pollDesc).waitRead(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_poll_runtime.go:89&#xA;        internal/poll.(*FD).Read(0x1400078a2a0, {0x14000a4c000, 0x8000, 0x8000})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_unix.go:165&#xA;        os.(*File).read(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file_posix.go:29&#xA;        os.(*File).Read(0x140004280c8, {0x14000a4c000?, 0x14000978da8?, 0x100ea3a18?})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:144&#xA;        io.copyBuffer({0x102feed80, 0x14000434880}, {0x102fedec8, 0x140008b4210}, {0x0, 0x0, 0x0})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:429&#xA;        io.Copy(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:388&#xA;        os.genericWriteTo(0x1?, {0x102feed80, 0x14000434880})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:295&#xA;        os.(*File).WriteTo(0x104489230?, {0x102feed80?, 0x14000434880?})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:273&#xA;        io.copyBuffer({0x102feed80, 0x14000434880}, {0x102fedfc0, 0x140004280c8}, {0x0, 0x0, 0x0})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:411&#xA;        io.Copy(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:388&#xA;        os/exec.(*Cmd).writerDescriptor.func1()&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:596&#xA;        os/exec.(*Cmd).Start.func2(0x0?)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:749&#xA;        os/exec.(*Cmd).Start in goroutine 512&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:748&#xA;&#xA;      goroutine 442 [select, 6 minutes]&#xA;        os/exec.(*Cmd).watchCtx(0x140008c0000, 0x1400098c070)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:789&#xA;        os/exec.(*Cmd).Start in goroutine 513&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:775&#xA;&#xA;      goroutine 397 [select, 6 minutes]&#xA;        os/exec.(*Cmd).watchCtx(0x14000908000, 0x1400011a620)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:789&#xA;        os/exec.(*Cmd).Start in goroutine 512&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:775&#xA;&#xA;      goroutine 441 [IO wait, 6 minutes]&#xA;        internal/poll.runtime_pollWait(0x11075d600, 0x72)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/runtime/netpoll.go:351&#xA;        internal/poll.(*pollDesc).wait(0x14000074240?, 0x14000a34000?, 0x1)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_poll_runtime.go:84&#xA;        internal/poll.(*pollDesc).waitRead(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_poll_runtime.go:89&#xA;        internal/poll.(*FD).Read(0x14000074240, {0x14000a34000, 0x8000, 0x8000})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_unix.go:165&#xA;        os.(*File).read(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file_posix.go:29&#xA;        os.(*File).Read(0x140001261e8, {0x14000a34000?, 0x14000512da8?, 0x100ea3a18?})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:144&#xA;        io.copyBuffer({0x102feed80, 0x14000596580}, {0x102fedec8, 0x140008b4208}, {0x0, 0x0, 0x0})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:429&#xA;        io.Copy(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:388&#xA;        os.genericWriteTo(0x14000512e01?, {0x102feed80, 0x14000596580})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:295&#xA;        os.(*File).WriteTo(0x104489230?, {0x102feed80?, 0x14000596580?})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:273&#xA;        io.copyBuffer({0x102feed80, 0x14000596580}, {0x102fedfc0, 0x140001261e8}, {0x0, 0x0, 0x0})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:411&#xA;        io.Copy(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:388&#xA;        os/exec.(*Cmd).writerDescriptor.func1()&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:596&#xA;        os/exec.(*Cmd).Start.func2(0x1400023e070?)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:749&#xA;        os/exec.(*Cmd).Start in goroutine 513&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:748&#xA;&#xA;      goroutine 395 [IO wait, 6 minutes]&#xA;        internal/poll.runtime_pollWait(0x11075e000, 0x72)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/runtime/netpoll.go:351&#xA;        internal/poll.(*pollDesc).wait(0x1400078a1e0?, 0x14000a3c000?, 0x1)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_poll_runtime.go:84&#xA;        internal/poll.(*pollDesc).waitRead(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_poll_runtime.go:89&#xA;        internal/poll.(*FD).Read(0x1400078a1e0, {0x14000a3c000, 0x8000, 0x8000})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_unix.go:165&#xA;        os.(*File).read(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file_posix.go:29&#xA;        os.(*File).Read(0x14000428068, {0x14000a3c000?, 0x14000977da8?, 0x100ea3a18?})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:144&#xA;        io.copyBuffer({0x102feed80, 0x14000434800}, {0x102fedec8, 0x1400049e6e0}, {0x0, 0x0, 0x0})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:429&#xA;        io.Copy(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:388&#xA;        os.genericWriteTo(0x1?, {0x102feed80, 0x14000434800})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:295&#xA;        os.(*File).WriteTo(0x104489230?, {0x102feed80?, 0x14000434800?})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:273&#xA;        io.copyBuffer({0x102feed80, 0x14000434800}, {0x102fedfc0, 0x14000428068}, {0x0, 0x0, 0x0})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:411&#xA;        io.Copy(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:388&#xA;        os/exec.(*Cmd).writerDescriptor.func1()&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:596&#xA;        os/exec.(*Cmd).Start.func2(0x0?)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:749&#xA;        os/exec.(*Cmd).Start in goroutine 512&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:748&#xA;&#xA;      goroutine 440 [IO wait, 6 minutes]&#xA;        internal/poll.runtime_pollWait(0x11097fc00, 0x72)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/runtime/netpoll.go:351&#xA;        internal/poll.(*pollDesc).wait(0x14000074060?, 0x14000a22000?, 0x1)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_poll_runtime.go:84&#xA;        internal/poll.(*pollDesc).waitRead(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_poll_runtime.go:89&#xA;        internal/poll.(*FD).Read(0x14000074060, {0x14000a22000, 0x8000, 0x8000})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_unix.go:165&#xA;        os.(*File).read(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file_posix.go:29&#xA;        os.(*File).Read(0x140001260d0, {0x14000a22000?, 0x14000515da8?, 0x100ea3a18?})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:144&#xA;        io.copyBuffer({0x102feed80, 0x14000596000}, {0x102fedec8, 0x1400049e6d8}, {0x0, 0x0, 0x0})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:429&#xA;        io.Copy(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:388&#xA;        os.genericWriteTo(0x14000515e01?, {0x102feed80, 0x14000596000})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:295&#xA;        os.(*File).WriteTo(0x104489230?, {0x102feed80?, 0x14000596000?})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:273&#xA;        io.copyBuffer({0x102feed80, 0x14000596000}, {0x102fedfc0, 0x140001260d0}, {0x0, 0x0, 0x0})&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:411&#xA;        io.Copy(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:388&#xA;        os/exec.(*Cmd).writerDescriptor.func1()&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:596&#xA;        os/exec.(*Cmd).Start.func2(0x14000a05be0?)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:749&#xA;        os/exec.(*Cmd).Start in goroutine 513&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:748&#xA;Interrupted by User&#xA;First interrupt received; Ginkgo will run any cleanup and reporting nodes but will skip all remaining specs.  Interrupt again to skip cleanup.&#xA;Here&#39;s a current progress report:&#xA;  VirtualMachineRestoreForce When the virtualization resources are applied checks the resources phase (Spec Runtime: 6m14.471s)&#xA;    /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:111&#xA;    In [It] (Node Runtime: 6m14.471s)&#xA;      /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:111&#xA;      At [By Step] `VirtualMachine` agent should be ready (Step Runtime: 6m14.471s)&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:112&#xA;&#xA;      Spec Goroutine&#xA;      goroutine 508 [sync.WaitGroup.Wait, 6 minutes]&#xA;        sync.runtime_SemacquireWaitGroup(0x100ee0b30?, 0x80?)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/runtime/sema.go:114&#xA;        sync.(*WaitGroup).Wait(0x14000b871d0)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/sync/waitgroup.go:206&#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e.WaitResources({0x14000956de0, 0x2, 0x102959e58?}, {0x102676a2d, 0x2a}, {{0x0, 0x0, 0x0}, 0x1400070b350, {0x14000bebd70, ...}, ...})&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:349&#xA;            | &#x9;&#x9;}()&#xA;            | &#x9;}&#xA;            &gt; &#x9;wg.Wait()&#xA;            | &#x9;Expect(waitErr).To(BeEmpty(), &#34;should observe resources in &#39;%s&#39; state before %s timeout&#34;, opts.For, opts.Timeout.String())&#xA;            | }&#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e.WaitByLabel({0x102676a2d, 0x2a}, {{0x0, 0x0, 0x0}, 0x1400070b350, {0x14000bebd70, 0x29}, {0x140007f1320, 0x22}, ...})&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:308&#xA;            | &#x9;&#x9;resources = strings.Split(res.StdOut(), &#34; &#34;)&#xA;            | &#x9;}&#xA;            &gt; &#x9;WaitResources(resources, resource, opts)&#xA;            | }&#xA;            | &#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e.WaitPhaseByLabel({0x102676a2d, 0x2a}, {0x102633a0a, 0x7}, {{0x0, 0x0, 0x0}, 0x1400070b350, {0x14000bebd70, 0x29}, ...})&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:290&#xA;            | &#x9;GinkgoHelper()&#xA;            | &#x9;opts.For = fmt.Sprintf(&#34;&#39;jsonpath={.status.phase}=%s&#39;&#34;, phase)&#xA;            &gt; &#x9;WaitByLabel(resource, opts)&#xA;            | }&#xA;            | &#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e.WaitVMAgentReady({{0x0, 0x0, 0x0}, 0x1400070b350, {0x14000bebd70, 0x29}, {0x0, 0x0}, 0xe8d4a51000})&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:274&#xA;            | func WaitVMAgentReady(opts kc.WaitOptions) {&#xA;            | &#x9;GinkgoHelper()&#xA;            &gt; &#x9;WaitPhaseByLabel(kc.ResourceVM, PhaseRunning, opts)&#xA;            | &#x9;WaitConditionIsTrueByLabel(kc.ResourceVM, vmcondition.TypeAgentReady.String(), opts)&#xA;            | }&#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e.init.func22.4.2.1()&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:113&#xA;            | It(&#34;checks the resources phase&#34;, func() {&#xA;            | &#x9;By(&#34;`VirtualMachine` agent should be ready&#34;, func() {&#xA;            &gt; &#x9;&#x9;WaitVMAgentReady(kc.WaitOptions{&#xA;            | &#x9;&#x9;&#x9;Labels:    testCaseLabel,&#xA;            | &#x9;&#x9;&#x9;Namespace: namespace,&#xA;        github.com/onsi/ginkgo/v2/internal.(*Suite).By(0x140000fd508, {0x10266ddb1, 0x26}, {0x14000b79f48, 0x1, 0x1025c3614?})&#xA;          /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/suite.go:323&#xA;        github.com/onsi/ginkgo/v2.By({0x10266ddb1?, 0x102ff5eb0?}, {0x14000918748?, 0x1400049a410?, 0x14000918758?})&#xA;          /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/core_dsl.go:600&#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e.init.func22.4.2()&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:112&#xA;            | &#xA;            | It(&#34;checks the resources phase&#34;, func() {&#xA;            &gt; &#x9;By(&#34;`VirtualMachine` agent should be ready&#34;, func() {&#xA;            | &#x9;&#x9;WaitVMAgentReady(kc.WaitOptions{&#xA;            | &#x9;&#x9;&#x9;Labels:    testCaseLabel,&#xA;        github.com/onsi/ginkgo/v2/internal.extractBodyFunction.func3({0x0?, 0x0?})&#xA;          /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/node.go:475&#xA;        github.com/onsi/ginkgo/v2/internal.(*Suite).runNode.func3()&#xA;          /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/suite.go:894&#xA;        github.com/onsi/ginkgo/v2/internal.(*Suite).runNode in goroutine 5&#xA;          /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/suite.go:881&#xA;&#xA;      Goroutines of Interest&#xA;      goroutine 512 [syscall, 6 minutes]&#xA;        syscall.syscall6(0x90010100954030?, 0x110a7faa0?, 0x105250f30?, 0x90?, 0x14000580008?, 0x14000968000?, 0x1400071fa58?)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/runtime/sys_darwin.go:60&#xA;        syscall.wait4(0x1400071fa88?, 0x100f626fc?, 0x90?, 0x102f5e120?)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/syscall/zsyscall_darwin_arm64.go:44&#xA;        syscall.Wait4(0x14000270380?, 0x1400071fac4, 0x14000954030?, 0x140002702a0?)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/syscall/syscall_bsd.go:144&#xA;        os.(*Process).pidWait.func1(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec_unix.go:64&#xA;        os.ignoringEINTR2[...](...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file_posix.go:266&#xA;        os.(*Process).pidWait(0x14000434900)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec_unix.go:63&#xA;        os.(*Process).wait(0x1400090a408?)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec_unix.go:28&#xA;        os.(*Process).Wait(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec.go:340&#xA;        os/exec.(*Cmd).Wait(0x14000908000)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:922&#xA;        os/exec.(*Cmd).Run(0x14000908000)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:626&#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e/executor.CMDExecutor.ExecuteContext({{0x140002a34f0?, 0x102ff5e88?, 0x14000270000?}}, {0x103016488?, 0x14000270000?}, {0x14000e3a0d0?, 0xc233172ab5e082d0?}, {0x102feed80, 0x14000434800}, {0x102feed80, ...})&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/executor/executor.go:76&#xA;            | &#x9;cmd.Stderr = stderr&#xA;            | &#x9;cmd.Stdout = stdout&#xA;            &gt; &#x9;return cmd.Run()&#xA;            | }&#xA;            | &#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e/executor.CMDExecutor.ExecContext({{0x140002a34f0?, 0x104503728?, 0x1044d9fa0?}}, {0x103016488, 0x14000270000}, {0x14000e3a0d0, 0xd0})&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/executor/executor.go:49&#xA;            | stdout := new(Buffer)&#xA;            | stderr := new(Buffer)&#xA;            &gt; err := e.ExecuteContext(ctx, command, stdout, stderr)&#xA;            | cmdResult := &amp;CMDResult{&#xA;            | &#x9;stdOut:  stdout,&#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e/kubectl.KubectlCMD.WaitResource({{0x10301aa38?, 0x1400000fde8?}, {0x102633fba?, 0x1400071fe88?}}, {0x102676a2d, 0x2a}, {0x14000b56a00, 0x28}, {{0x0, 0x0, ...}, ...})&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/kubectl/kubectl.go:260&#xA;            | &#x9;ctx, cancel := context.WithTimeout(context.Background(), timeout)&#xA;            | &#x9;defer cancel()&#xA;            &gt; &#x9;return k.ExecContext(ctx, cmd)&#xA;            | }&#xA;            | &#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e.WaitResources.func1()&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:341&#xA;            | go func() {&#xA;            | &#x9;defer wg.Done()&#xA;            &gt; &#x9;res := kubectl.WaitResource(resource, name, waitOpts)&#xA;            | &#x9;if res.Error() != nil {&#xA;            | &#x9;&#x9;mu.Lock()&#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e.WaitResources in goroutine 508&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:339&#xA;            | for _, name := range resources {&#xA;            | &#x9;wg.Add(1)&#xA;            &gt; &#x9;go func() {&#xA;            | &#x9;&#x9;defer wg.Done()&#xA;            | &#x9;&#x9;res := kubectl.WaitResource(resource, name, waitOpts)&#xA;&#xA;      goroutine 513 [syscall, 6 minutes]&#xA;        syscall.syscall6(0x10067a840?, 0x110a8eaf0?, 0x105250a78?, 0x90?, 0x140000a5008?, 0x14000882090?, 0x1400097ba58?)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/runtime/sys_darwin.go:60&#xA;        syscall.wait4(0x1400097ba88?, 0x100f626fc?, 0x90?, 0x102f5e120?)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/syscall/zsyscall_darwin_arm64.go:44&#xA;        syscall.Wait4(0x14000490380?, 0x1400097bac4, 0x1400067a840?, 0x140004902a0?)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/syscall/syscall_bsd.go:144&#xA;        os.(*Process).pidWait.func1(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec_unix.go:64&#xA;        os.ignoringEINTR2[...](...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file_posix.go:266&#xA;        os.(*Process).pidWait(0x14000596600)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec_unix.go:63&#xA;        os.(*Process).wait(0x140008c4408?)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec_unix.go:28&#xA;        os.(*Process).Wait(...)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec.go:340&#xA;        os/exec.(*Cmd).Wait(0x140008c0000)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:922&#xA;        os/exec.(*Cmd).Run(0x140008c0000)&#xA;          /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:626&#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e/executor.CMDExecutor.ExecuteContext({{0x140002a34f0?, 0x102ff5e88?, 0x140004900e0?}}, {0x103016488?, 0x140004900e0?}, {0x140008b6000?, 0xc233172ab5e0ec48?}, {0x102feed80, 0x14000596000}, {0x102feed80, ...})&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/executor/executor.go:76&#xA;            | &#x9;cmd.Stderr = stderr&#xA;            | &#x9;cmd.Stdout = stdout&#xA;            &gt; &#x9;return cmd.Run()&#xA;            | }&#xA;            | &#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e/executor.CMDExecutor.ExecContext({{0x140002a34f0?, 0x104503728?, 0x1044d9fa0?}}, {0x103016488, 0x140004900e0}, {0x140008b6000, 0xc6})&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/executor/executor.go:49&#xA;            | stdout := new(Buffer)&#xA;            | stderr := new(Buffer)&#xA;            &gt; err := e.ExecuteContext(ctx, command, stdout, stderr)&#xA;            | cmdResult := &amp;CMDResult{&#xA;            | &#x9;stdOut:  stdout,&#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e/kubectl.KubectlCMD.WaitResource({{0x10301aa38?, 0x1400000fde8?}, {0x102633fba?, 0x14000a20f40?}}, {0x102676a2d, 0x2a}, {0x14000b56a29, 0x1e}, {{0x0, 0x0, ...}, ...})&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/kubectl/kubectl.go:260&#xA;            | &#x9;ctx, cancel := context.WithTimeout(context.Background(), timeout)&#xA;            | &#x9;defer cancel()&#xA;            &gt; &#x9;return k.ExecContext(ctx, cmd)&#xA;            | }&#xA;            | &#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e.WaitResources.func1()&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:341&#xA;            | go func() {&#xA;            | &#x9;defer wg.Done()&#xA;            &gt; &#x9;res := kubectl.WaitResource(resource, name, waitOpts)&#xA;            | &#x9;if res.Error() != nil {&#xA;            | &#x9;&#x9;mu.Lock()&#xA;      &gt; github.com/deckhouse/virtualization/tests/e2e.WaitResources in goroutine 508&#xA;          /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:339&#xA;            | for _, name := range resources {&#xA;            | &#x9;wg.Add(1)&#xA;            &gt; &#x9;go func() {&#xA;            | &#x9;&#x9;defer wg.Done()&#xA;            | &#x9;&#x9;res := kubectl.WaitResource(resource, name, waitOpts)&#xA;&lt; Exit [It] checks the resources phase - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:111 @ 10/12/25 20:17:24.216 (6m14.473s)&#xA;&gt; Enter [AfterEach] VirtualMachineRestoreForce - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:71 @ 10/12/25 20:17:24.216&#xA;[INTERRUPTED] Interrupted by User&#xA;In [AfterEach] at: /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:71 @ 10/12/25 20:17:27.092&#xA;&#xA;This is the Progress Report generated when the interrupt was received:&#xA;  VirtualMachineRestoreForce When the virtualization resources are applied checks the resources phase (Spec Runtime: 6m17.35s)&#xA;    /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:111&#xA;    In [AfterEach] (Node Runtime: 2.876s)&#xA;      /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:71&#xA;&#xA;    Spec Goroutine&#xA;    goroutine 456 [syscall]&#xA;      syscall.syscall6(0x10090dc70?, 0x110a8eaf0?, 0x1052505c0?, 0x90?, 0x14000500808?, 0x14000882b40?, 0x1400002eb08?)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/runtime/sys_darwin.go:60&#xA;      syscall.wait4(0x1400002eb38?, 0x100f626fc?, 0x90?, 0x102f5e120?)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/syscall/zsyscall_darwin_arm64.go:44&#xA;      syscall.Wait4(0x14000490b60?, 0x1400002eb74, 0x1400090dc70?, 0x14000490a10?)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/syscall/syscall_bsd.go:144&#xA;      os.(*Process).pidWait.func1(...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec_unix.go:64&#xA;      os.ignoringEINTR2[...](...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file_posix.go:266&#xA;      os.(*Process).pidWait(0x14000597200)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec_unix.go:63&#xA;      os.(*Process).wait(0x140008c4c08?)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec_unix.go:28&#xA;      os.(*Process).Wait(...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec.go:340&#xA;      os/exec.(*Cmd).Wait(0x140008c0180)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:922&#xA;      os/exec.(*Cmd).Run(0x140008c0180)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:626&#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e/executor.CMDExecutor.ExecuteContext({{0x140002a34f0?, 0x102ff5e88?, 0x14000490850?}}, {0x103016488?, 0x14000490850?}, {0x14000884540?, 0xc23316908cec3270?}, {0x102feed80, 0x14000597080}, {0x102feed80, ...})&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/executor/executor.go:76&#xA;          | &#x9;cmd.Stderr = stderr&#xA;          | &#x9;cmd.Stdout = stdout&#xA;          &gt; &#x9;return cmd.Run()&#xA;          | }&#xA;          | &#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e/executor.CMDExecutor.ExecContext({{0x140002a34f0?, 0x104503728?, 0x1044d9fa0?}}, {0x103016488, 0x14000490850}, {0x14000884540, 0xb5})&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/executor/executor.go:49&#xA;          | stdout := new(Buffer)&#xA;          | stderr := new(Buffer)&#xA;          &gt; err := e.ExecuteContext(ctx, command, stdout, stderr)&#xA;          | cmdResult := &amp;CMDResult{&#xA;          | &#x9;stdOut:  stdout,&#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e/kubectl.KubectlCMD.Get({{0x10301aa38?, 0x1400000fde8?}, {0x102633fba?, 0x140004373b0?}}, {0x10268b2e2, 0x31}, {{0x0, 0x0, 0x0}, 0x0, ...})&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/kubectl/kubectl.go:208&#xA;          | &#x9;ctx, cancel := context.WithTimeout(context.Background(), MediumTimeout)&#xA;          | &#x9;defer cancel()&#xA;          &gt; &#x9;return k.ExecContext(ctx, cmd)&#xA;          | }&#xA;          | &#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e.SaveTestCaseResources(0x1400070b350, {0x14000a15c40, 0x1a}, {0x14000bebd70, 0x29}, {0x102630370, 0x4})&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:765&#xA;          | errorFileName := fmt.Sprintf(&#34;%s/e2e_failed__%s__%s_error.txt&#34;, dumpPath, labels[&#34;testcase&#34;], additional)&#xA;          | &#xA;          &gt; cmdr := kubectl.Get(&#xA;          | &#x9;&#34;virtualization,cvi,vmc,intvirt,pod,volumesnapshot&#34;,&#xA;          | &#x9;kc.GetOptions{&#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e.SaveTestCaseDump(0x1400070b350, {0x102655aa3, 0x1a}, {0x14000bebd70, 0x29})&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:757&#xA;          | &#x9;}&#xA;          | &#xA;          &gt; &#x9;SaveTestCaseResources(labels, additional, namespace, tmpDir)&#xA;          | &#x9;SavePodLogsAndDescriptions(labels, additional, namespace, tmpDir)&#xA;          | }&#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e.init.func22.3()&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:73&#xA;          | AfterEach(func() {&#xA;          | &#x9;if CurrentSpecReport().Failed() {&#xA;          &gt; &#x9;&#x9;SaveTestCaseDump(testCaseLabel, CurrentSpecReport().LeafNodeText, namespace)&#xA;          | &#x9;}&#xA;          | &#xA;      github.com/onsi/ginkgo/v2/internal.extractBodyFunction.func3({0x0?, 0x0?})&#xA;        /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/node.go:475&#xA;      github.com/onsi/ginkgo/v2/internal.(*Suite).runNode.func3()&#xA;        /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/suite.go:894&#xA;      github.com/onsi/ginkgo/v2/internal.(*Suite).runNode in goroutine 5&#xA;        /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/suite.go:881&#xA;&#xA;    Goroutines of Interest&#xA;    goroutine 508 [sync.WaitGroup.Wait, 6 minutes]&#xA;      sync.runtime_SemacquireWaitGroup(0x100ee0b30?, 0x80?)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/runtime/sema.go:114&#xA;      sync.(*WaitGroup).Wait(0x14000b871d0)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/sync/waitgroup.go:206&#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e.WaitResources({0x14000956de0, 0x2, 0x102959e58?}, {0x102676a2d, 0x2a}, {{0x0, 0x0, 0x0}, 0x1400070b350, {0x14000bebd70, ...}, ...})&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:349&#xA;          | &#x9;&#x9;}()&#xA;          | &#x9;}&#xA;          &gt; &#x9;wg.Wait()&#xA;          | &#x9;Expect(waitErr).To(BeEmpty(), &#34;should observe resources in &#39;%s&#39; state before %s timeout&#34;, opts.For, opts.Timeout.String())&#xA;          | }&#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e.WaitByLabel({0x102676a2d, 0x2a}, {{0x0, 0x0, 0x0}, 0x1400070b350, {0x14000bebd70, 0x29}, {0x140007f1320, 0x22}, ...})&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:308&#xA;          | &#x9;&#x9;resources = strings.Split(res.StdOut(), &#34; &#34;)&#xA;          | &#x9;}&#xA;          &gt; &#x9;WaitResources(resources, resource, opts)&#xA;          | }&#xA;          | &#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e.WaitPhaseByLabel({0x102676a2d, 0x2a}, {0x102633a0a, 0x7}, {{0x0, 0x0, 0x0}, 0x1400070b350, {0x14000bebd70, 0x29}, ...})&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:290&#xA;          | &#x9;GinkgoHelper()&#xA;          | &#x9;opts.For = fmt.Sprintf(&#34;&#39;jsonpath={.status.phase}=%s&#39;&#34;, phase)&#xA;          &gt; &#x9;WaitByLabel(resource, opts)&#xA;          | }&#xA;          | &#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e.WaitVMAgentReady({{0x0, 0x0, 0x0}, 0x1400070b350, {0x14000bebd70, 0x29}, {0x0, 0x0}, 0xe8d4a51000})&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:274&#xA;          | func WaitVMAgentReady(opts kc.WaitOptions) {&#xA;          | &#x9;GinkgoHelper()&#xA;          &gt; &#x9;WaitPhaseByLabel(kc.ResourceVM, PhaseRunning, opts)&#xA;          | &#x9;WaitConditionIsTrueByLabel(kc.ResourceVM, vmcondition.TypeAgentReady.String(), opts)&#xA;          | }&#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e.init.func22.4.2.1()&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:113&#xA;          | It(&#34;checks the resources phase&#34;, func() {&#xA;          | &#x9;By(&#34;`VirtualMachine` agent should be ready&#34;, func() {&#xA;          &gt; &#x9;&#x9;WaitVMAgentReady(kc.WaitOptions{&#xA;          | &#x9;&#x9;&#x9;Labels:    testCaseLabel,&#xA;          | &#x9;&#x9;&#x9;Namespace: namespace,&#xA;      github.com/onsi/ginkgo/v2/internal.(*Suite).By(0x140000fd508, {0x10266ddb1, 0x26}, {0x14000b79f48, 0x1, 0x1025c3614?})&#xA;        /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/suite.go:323&#xA;      github.com/onsi/ginkgo/v2.By({0x10266ddb1?, 0x102ff5eb0?}, {0x14000918748?, 0x1400049a410?, 0x14000918758?})&#xA;        /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/core_dsl.go:600&#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e.init.func22.4.2()&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:112&#xA;          | &#xA;          | It(&#34;checks the resources phase&#34;, func() {&#xA;          &gt; &#x9;By(&#34;`VirtualMachine` agent should be ready&#34;, func() {&#xA;          | &#x9;&#x9;WaitVMAgentReady(kc.WaitOptions{&#xA;          | &#x9;&#x9;&#x9;Labels:    testCaseLabel,&#xA;      github.com/onsi/ginkgo/v2/internal.extractBodyFunction.func3({0x0?, 0x0?})&#xA;        /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/node.go:475&#xA;      github.com/onsi/ginkgo/v2/internal.(*Suite).runNode.func3()&#xA;        /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/suite.go:894&#xA;      github.com/onsi/ginkgo/v2/internal.(*Suite).runNode in goroutine 5&#xA;        /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/suite.go:881&#xA;&#xA;    goroutine 512 [syscall, 6 minutes]&#xA;      syscall.syscall6(0x90010100954030?, 0x110a7faa0?, 0x105250f30?, 0x90?, 0x14000580008?, 0x14000968000?, 0x1400071fa58?)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/runtime/sys_darwin.go:60&#xA;      syscall.wait4(0x1400071fa88?, 0x100f626fc?, 0x90?, 0x102f5e120?)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/syscall/zsyscall_darwin_arm64.go:44&#xA;      syscall.Wait4(0x14000270380?, 0x1400071fac4, 0x14000954030?, 0x140002702a0?)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/syscall/syscall_bsd.go:144&#xA;      os.(*Process).pidWait.func1(...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec_unix.go:64&#xA;      os.ignoringEINTR2[...](...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file_posix.go:266&#xA;      os.(*Process).pidWait(0x14000434900)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec_unix.go:63&#xA;      os.(*Process).wait(0x1400090a408?)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec_unix.go:28&#xA;      os.(*Process).Wait(...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec.go:340&#xA;      os/exec.(*Cmd).Wait(0x14000908000)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:922&#xA;      os/exec.(*Cmd).Run(0x14000908000)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:626&#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e/executor.CMDExecutor.ExecuteContext({{0x140002a34f0?, 0x102ff5e88?, 0x14000270000?}}, {0x103016488?, 0x14000270000?}, {0x14000e3a0d0?, 0xc233172ab5e082d0?}, {0x102feed80, 0x14000434800}, {0x102feed80, ...})&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/executor/executor.go:76&#xA;          | &#x9;cmd.Stderr = stderr&#xA;          | &#x9;cmd.Stdout = stdout&#xA;          &gt; &#x9;return cmd.Run()&#xA;          | }&#xA;          | &#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e/executor.CMDExecutor.ExecContext({{0x140002a34f0?, 0x104503728?, 0x1044d9fa0?}}, {0x103016488, 0x14000270000}, {0x14000e3a0d0, 0xd0})&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/executor/executor.go:49&#xA;          | stdout := new(Buffer)&#xA;          | stderr := new(Buffer)&#xA;          &gt; err := e.ExecuteContext(ctx, command, stdout, stderr)&#xA;          | cmdResult := &amp;CMDResult{&#xA;          | &#x9;stdOut:  stdout,&#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e/kubectl.KubectlCMD.WaitResource({{0x10301aa38?, 0x1400000fde8?}, {0x102633fba?, 0x1400071fe88?}}, {0x102676a2d, 0x2a}, {0x14000b56a00, 0x28}, {{0x0, 0x0, ...}, ...})&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/kubectl/kubectl.go:260&#xA;          | &#x9;ctx, cancel := context.WithTimeout(context.Background(), timeout)&#xA;          | &#x9;defer cancel()&#xA;          &gt; &#x9;return k.ExecContext(ctx, cmd)&#xA;          | }&#xA;          | &#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e.WaitResources.func1()&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:341&#xA;          | go func() {&#xA;          | &#x9;defer wg.Done()&#xA;          &gt; &#x9;res := kubectl.WaitResource(resource, name, waitOpts)&#xA;          | &#x9;if res.Error() != nil {&#xA;          | &#x9;&#x9;mu.Lock()&#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e.WaitResources in goroutine 508&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:339&#xA;          | for _, name := range resources {&#xA;          | &#x9;wg.Add(1)&#xA;          &gt; &#x9;go func() {&#xA;          | &#x9;&#x9;defer wg.Done()&#xA;          | &#x9;&#x9;res := kubectl.WaitResource(resource, name, waitOpts)&#xA;&#xA;    goroutine 513 [syscall, 6 minutes]&#xA;      syscall.syscall6(0x10067a840?, 0x110a8eaf0?, 0x105250a78?, 0x90?, 0x140000a5008?, 0x14000882090?, 0x1400097ba58?)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/runtime/sys_darwin.go:60&#xA;      syscall.wait4(0x1400097ba88?, 0x100f626fc?, 0x90?, 0x102f5e120?)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/syscall/zsyscall_darwin_arm64.go:44&#xA;      syscall.Wait4(0x14000490380?, 0x1400097bac4, 0x1400067a840?, 0x140004902a0?)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/syscall/syscall_bsd.go:144&#xA;      os.(*Process).pidWait.func1(...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec_unix.go:64&#xA;      os.ignoringEINTR2[...](...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file_posix.go:266&#xA;      os.(*Process).pidWait(0x14000596600)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec_unix.go:63&#xA;      os.(*Process).wait(0x140008c4408?)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec_unix.go:28&#xA;      os.(*Process).Wait(...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec.go:340&#xA;      os/exec.(*Cmd).Wait(0x140008c0000)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:922&#xA;      os/exec.(*Cmd).Run(0x140008c0000)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:626&#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e/executor.CMDExecutor.ExecuteContext({{0x140002a34f0?, 0x102ff5e88?, 0x140004900e0?}}, {0x103016488?, 0x140004900e0?}, {0x140008b6000?, 0xc233172ab5e0ec48?}, {0x102feed80, 0x14000596000}, {0x102feed80, ...})&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/executor/executor.go:76&#xA;          | &#x9;cmd.Stderr = stderr&#xA;          | &#x9;cmd.Stdout = stdout&#xA;          &gt; &#x9;return cmd.Run()&#xA;          | }&#xA;          | &#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e/executor.CMDExecutor.ExecContext({{0x140002a34f0?, 0x104503728?, 0x1044d9fa0?}}, {0x103016488, 0x140004900e0}, {0x140008b6000, 0xc6})&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/executor/executor.go:49&#xA;          | stdout := new(Buffer)&#xA;          | stderr := new(Buffer)&#xA;          &gt; err := e.ExecuteContext(ctx, command, stdout, stderr)&#xA;          | cmdResult := &amp;CMDResult{&#xA;          | &#x9;stdOut:  stdout,&#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e/kubectl.KubectlCMD.WaitResource({{0x10301aa38?, 0x1400000fde8?}, {0x102633fba?, 0x14000a20f40?}}, {0x102676a2d, 0x2a}, {0x14000b56a29, 0x1e}, {{0x0, 0x0, ...}, ...})&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/kubectl/kubectl.go:260&#xA;          | &#x9;ctx, cancel := context.WithTimeout(context.Background(), timeout)&#xA;          | &#x9;defer cancel()&#xA;          &gt; &#x9;return k.ExecContext(ctx, cmd)&#xA;          | }&#xA;          | &#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e.WaitResources.func1()&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:341&#xA;          | go func() {&#xA;          | &#x9;defer wg.Done()&#xA;          &gt; &#x9;res := kubectl.WaitResource(resource, name, waitOpts)&#xA;          | &#x9;if res.Error() != nil {&#xA;          | &#x9;&#x9;mu.Lock()&#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e.WaitResources in goroutine 508&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:339&#xA;          | for _, name := range resources {&#xA;          | &#x9;wg.Add(1)&#xA;          &gt; &#x9;go func() {&#xA;          | &#x9;&#x9;defer wg.Done()&#xA;          | &#x9;&#x9;res := kubectl.WaitResource(resource, name, waitOpts)&#xA;&#xA;    Other Goroutines&#xA;    goroutine 5 [running]&#xA;      github.com/onsi/ginkgo/v2/internal.extractRunningGoroutines()&#xA;        /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/progress_report.go:181&#xA;      github.com/onsi/ginkgo/v2/internal.NewProgressReport(_, {{0x14000956c00, 0x2, 0x2}, {0x14000255340, 0x2, 0x2}, {0x1400028de30, 0x2, 0x2}, ...}, ...)&#xA;        /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/progress_report.go:75&#xA;      github.com/onsi/ginkgo/v2/internal.(*Suite).generateProgressReport(_, _)&#xA;        /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/suite.go:381&#xA;      github.com/onsi/ginkgo/v2/internal.(*Suite).runNode(_, {0x177, 0x20, {0x0, 0x0}, 0x140000a21c0, {{0x10371dce5, 0x56}, 0x47, {0x0, ...}, ...}, ...}, ...)&#xA;        /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/suite.go:980&#xA;      github.com/onsi/ginkgo/v2/internal.(*group).attemptSpec(0x140007537f0, 0x1, {{0x140006ef508?, 0x14000255340?, 0x2?}, 0x0?})&#xA;        /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/group.go:286&#xA;      github.com/onsi/ginkgo/v2/internal.(*group).run(0x140007537f0, {0x14000b58000?, 0x0?, 0x0?})&#xA;        /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/group.go:349&#xA;      github.com/onsi/ginkgo/v2/internal.(*Suite).runSpecs(0x140000fd508, {0x102630f2b, 0x5}, {0x104503728, 0x0, 0x0}, {0x1400005a0f4, 0x3d}, 0x0, {0x14000092c08, ...})&#xA;        /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/suite.go:489&#xA;      github.com/onsi/ginkgo/v2/internal.(*Suite).Run(_, {_, _}, {_, _, _}, {_, _}, _, {_, ...}, ...)&#xA;        /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/suite.go:130&#xA;      github.com/onsi/ginkgo/v2.RunSpecs({0x102fee0a0, 0x14000602c40}, {0x102630f2b, 0x5}, {0x0, 0x0, 0x0})&#xA;        /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/core_dsl.go:300&#xA;      github.com/deckhouse/virtualization/tests/e2e.TestE2E(0x14000602c40)&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/e2e_test.go:76&#xA;      testing.tRunner(0x14000602c40, 0x102fddc50)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/testing/testing.go:1934&#xA;      testing.(*T).Run in goroutine 1&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/testing/testing.go:1997&#xA;&#xA;    goroutine 1 [chan receive, 126 minutes]&#xA;      testing.(*T).Run(0x14000602a80, {0x10263399a?, 0x140005a1b38?}, 0x102fddc50)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/testing/testing.go:2005&#xA;      testing.runTests.func1(0x14000602a80)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/testing/testing.go:2477&#xA;      testing.tRunner(0x14000602a80, 0x140005a1c68)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/testing/testing.go:1934&#xA;      testing.runTests(0x1400000ed50, {0x104488fd0, 0x1, 0x1}, {0x14000708f20?, 0xf?, 0x0?})&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/testing/testing.go:2475&#xA;      testing.(*M).Run(0x140004d6460)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/testing/testing.go:2337&#xA;      main.main()&#xA;        _testmain.go:45&#xA;&#xA;    goroutine 41 [syscall]&#xA;      os/signal.signal_recv()&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/runtime/sigqueue.go:149&#xA;      os/signal.loop()&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/signal/signal_unix.go:23&#xA;      os/signal.Notify.func1.1 in goroutine 5&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/signal/signal.go:152&#xA;&#xA;    goroutine 31 [select, 126 minutes]&#xA;      github.com/onsi/ginkgo/v2/internal.RegisterForProgressSignal.func1()&#xA;        /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/progress_report.go:32&#xA;      github.com/onsi/ginkgo/v2/internal.RegisterForProgressSignal in goroutine 5&#xA;        /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/progress_report.go:30&#xA;&#xA;    goroutine 66 [select]&#xA;      github.com/onsi/ginkgo/v2/internal/interrupt_handler.(*InterruptHandler).registerForInterrupts.func2(0x0?)&#xA;        /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/interrupt_handler/interrupt_handler.go:131&#xA;      github.com/onsi/ginkgo/v2/internal/interrupt_handler.(*InterruptHandler).registerForInterrupts in goroutine 5&#xA;        /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/interrupt_handler/interrupt_handler.go:128&#xA;&#xA;    goroutine 459 [select]&#xA;      os/exec.(*Cmd).watchCtx(0x140008c0180, 0x14000647490)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:789&#xA;      os/exec.(*Cmd).Start in goroutine 456&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:775&#xA;&#xA;    goroutine 458 [IO wait]&#xA;      internal/poll.runtime_pollWait(0x110980000, 0x72)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/runtime/netpoll.go:351&#xA;      internal/poll.(*pollDesc).wait(0x140000753e0?, 0x1400083c000?, 0x1)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_poll_runtime.go:84&#xA;      internal/poll.(*pollDesc).waitRead(...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_poll_runtime.go:89&#xA;      internal/poll.(*FD).Read(0x140000753e0, {0x1400083c000, 0x8000, 0x8000})&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_unix.go:165&#xA;      os.(*File).read(...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file_posix.go:29&#xA;      os.(*File).Read(0x140001262a0, {0x1400083c000?, 0x1400091a5a8?, 0x100ea3a18?})&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:144&#xA;      io.copyBuffer({0x102feed80, 0x14000597140}, {0x102fedec8, 0x1400049e000}, {0x0, 0x0, 0x0})&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:429&#xA;      io.Copy(...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:388&#xA;      os.genericWriteTo(0x140000f0101?, {0x102feed80, 0x14000597140})&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:295&#xA;      os.(*File).WriteTo(0x104489230?, {0x102feed80?, 0x14000597140?})&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:273&#xA;      io.copyBuffer({0x102feed80, 0x14000597140}, {0x102fedfc0, 0x140001262a0}, {0x0, 0x0, 0x0})&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:411&#xA;      io.Copy(...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:388&#xA;      os/exec.(*Cmd).writerDescriptor.func1()&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:596&#xA;      os/exec.(*Cmd).Start.func2(0x140004ca000?)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:749&#xA;      os/exec.(*Cmd).Start in goroutine 456&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:748&#xA;&#xA;    goroutine 396 [IO wait, 6 minutes]&#xA;      internal/poll.runtime_pollWait(0x110980400, 0x72)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/runtime/netpoll.go:351&#xA;      internal/poll.(*pollDesc).wait(0x1400078a2a0?, 0x14000a4c000?, 0x1)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_poll_runtime.go:84&#xA;      internal/poll.(*pollDesc).waitRead(...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_poll_runtime.go:89&#xA;      internal/poll.(*FD).Read(0x1400078a2a0, {0x14000a4c000, 0x8000, 0x8000})&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_unix.go:165&#xA;      os.(*File).read(...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file_posix.go:29&#xA;      os.(*File).Read(0x140004280c8, {0x14000a4c000?, 0x14000978da8?, 0x100ea3a18?})&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:144&#xA;      io.copyBuffer({0x102feed80, 0x14000434880}, {0x102fedec8, 0x140008b4210}, {0x0, 0x0, 0x0})&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:429&#xA;      io.Copy(...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:388&#xA;      os.genericWriteTo(0x1?, {0x102feed80, 0x14000434880})&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:295&#xA;      os.(*File).WriteTo(0x104489230?, {0x102feed80?, 0x14000434880?})&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:273&#xA;      io.copyBuffer({0x102feed80, 0x14000434880}, {0x102fedfc0, 0x140004280c8}, {0x0, 0x0, 0x0})&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:411&#xA;      io.Copy(...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:388&#xA;      os/exec.(*Cmd).writerDescriptor.func1()&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:596&#xA;      os/exec.(*Cmd).Start.func2(0x0?)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:749&#xA;      os/exec.(*Cmd).Start in goroutine 512&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:748&#xA;&#xA;    goroutine 442 [select, 6 minutes]&#xA;      os/exec.(*Cmd).watchCtx(0x140008c0000, 0x1400098c070)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:789&#xA;      os/exec.(*Cmd).Start in goroutine 513&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:775&#xA;&#xA;    goroutine 397 [select, 6 minutes]&#xA;      os/exec.(*Cmd).watchCtx(0x14000908000, 0x1400011a620)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:789&#xA;      os/exec.(*Cmd).Start in goroutine 512&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:775&#xA;&#xA;    goroutine 457 [IO wait]&#xA;      internal/poll.runtime_pollWait(0x110980200, 0x72)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/runtime/netpoll.go:351&#xA;      internal/poll.(*pollDesc).wait(0x14000074cc0?, 0x140007a6000?, 0x1)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_poll_runtime.go:84&#xA;      internal/poll.(*pollDesc).waitRead(...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_poll_runtime.go:89&#xA;      internal/poll.(*FD).Read(0x14000074cc0, {0x140007a6000, 0x8000, 0x8000})&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_unix.go:165&#xA;      os.(*File).read(...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file_posix.go:29&#xA;      os.(*File).Read(0x14000126218, {0x140007a6000?, 0x1400091b5a8?, 0x100ea3a18?})&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:144&#xA;      io.copyBuffer({0x102feed80, 0x14000597080}, {0x102fedec8, 0x14000592020}, {0x0, 0x0, 0x0})&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:429&#xA;      io.Copy(...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:388&#xA;      os.genericWriteTo(0x140000f0901?, {0x102feed80, 0x14000597080})&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:295&#xA;      os.(*File).WriteTo(0x104489230?, {0x102feed80?, 0x14000597080?})&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:273&#xA;      io.copyBuffer({0x102feed80, 0x14000597080}, {0x102fedfc0, 0x14000126218}, {0x0, 0x0, 0x0})&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:411&#xA;      io.Copy(...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:388&#xA;      os/exec.(*Cmd).writerDescriptor.func1()&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:596&#xA;      os/exec.(*Cmd).Start.func2(0x140006473b0?)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:749&#xA;      os/exec.(*Cmd).Start in goroutine 456&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:748&#xA;&#xA;    goroutine 441 [IO wait, 6 minutes]&#xA;      internal/poll.runtime_pollWait(0x11075d600, 0x72)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/runtime/netpoll.go:351&#xA;      internal/poll.(*pollDesc).wait(0x14000074240?, 0x14000a34000?, 0x1)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_poll_runtime.go:84&#xA;      internal/poll.(*pollDesc).waitRead(...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_poll_runtime.go:89&#xA;      internal/poll.(*FD).Read(0x14000074240, {0x14000a34000, 0x8000, 0x8000})&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_unix.go:165&#xA;      os.(*File).read(...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file_posix.go:29&#xA;      os.(*File).Read(0x140001261e8, {0x14000a34000?, 0x14000512da8?, 0x100ea3a18?})&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:144&#xA;      io.copyBuffer({0x102feed80, 0x14000596580}, {0x102fedec8, 0x140008b4208}, {0x0, 0x0, 0x0})&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:429&#xA;      io.Copy(...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:388&#xA;      os.genericWriteTo(0x14000512e01?, {0x102feed80, 0x14000596580})&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:295&#xA;      os.(*File).WriteTo(0x104489230?, {0x102feed80?, 0x14000596580?})&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:273&#xA;      io.copyBuffer({0x102feed80, 0x14000596580}, {0x102fedfc0, 0x140001261e8}, {0x0, 0x0, 0x0})&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:411&#xA;      io.Copy(...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:388&#xA;      os/exec.(*Cmd).writerDescriptor.func1()&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:596&#xA;      os/exec.(*Cmd).Start.func2(0x1400023e070?)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:749&#xA;      os/exec.(*Cmd).Start in goroutine 513&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:748&#xA;&#xA;    goroutine 395 [IO wait, 6 minutes]&#xA;      internal/poll.runtime_pollWait(0x11075e000, 0x72)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/runtime/netpoll.go:351&#xA;      internal/poll.(*pollDesc).wait(0x1400078a1e0?, 0x14000a3c000?, 0x1)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_poll_runtime.go:84&#xA;      internal/poll.(*pollDesc).waitRead(...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_poll_runtime.go:89&#xA;      internal/poll.(*FD).Read(0x1400078a1e0, {0x14000a3c000, 0x8000, 0x8000})&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_unix.go:165&#xA;      os.(*File).read(...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file_posix.go:29&#xA;      os.(*File).Read(0x14000428068, {0x14000a3c000?, 0x14000977da8?, 0x100ea3a18?})&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:144&#xA;      io.copyBuffer({0x102feed80, 0x14000434800}, {0x102fedec8, 0x1400049e6e0}, {0x0, 0x0, 0x0})&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:429&#xA;      io.Copy(...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:388&#xA;      os.genericWriteTo(0x1?, {0x102feed80, 0x14000434800})&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:295&#xA;      os.(*File).WriteTo(0x104489230?, {0x102feed80?, 0x14000434800?})&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:273&#xA;      io.copyBuffer({0x102feed80, 0x14000434800}, {0x102fedfc0, 0x14000428068}, {0x0, 0x0, 0x0})&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:411&#xA;      io.Copy(...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:388&#xA;      os/exec.(*Cmd).writerDescriptor.func1()&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:596&#xA;      os/exec.(*Cmd).Start.func2(0x0?)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:749&#xA;      os/exec.(*Cmd).Start in goroutine 512&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:748&#xA;&#xA;    goroutine 440 [IO wait, 6 minutes]&#xA;      internal/poll.runtime_pollWait(0x11097fc00, 0x72)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/runtime/netpoll.go:351&#xA;      internal/poll.(*pollDesc).wait(0x14000074060?, 0x14000a22000?, 0x1)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_poll_runtime.go:84&#xA;      internal/poll.(*pollDesc).waitRead(...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_poll_runtime.go:89&#xA;      internal/poll.(*FD).Read(0x14000074060, {0x14000a22000, 0x8000, 0x8000})&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/internal/poll/fd_unix.go:165&#xA;      os.(*File).read(...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file_posix.go:29&#xA;      os.(*File).Read(0x140001260d0, {0x14000a22000?, 0x14000515da8?, 0x100ea3a18?})&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:144&#xA;      io.copyBuffer({0x102feed80, 0x14000596000}, {0x102fedec8, 0x1400049e6d8}, {0x0, 0x0, 0x0})&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:429&#xA;      io.Copy(...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:388&#xA;      os.genericWriteTo(0x14000515e01?, {0x102feed80, 0x14000596000})&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:295&#xA;      os.(*File).WriteTo(0x104489230?, {0x102feed80?, 0x14000596000?})&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file.go:273&#xA;      io.copyBuffer({0x102feed80, 0x14000596000}, {0x102fedfc0, 0x140001260d0}, {0x0, 0x0, 0x0})&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:411&#xA;      io.Copy(...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/io/io.go:388&#xA;      os/exec.(*Cmd).writerDescriptor.func1()&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:596&#xA;      os/exec.(*Cmd).Start.func2(0x14000a05be0?)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:749&#xA;      os/exec.(*Cmd).Start in goroutine 513&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:748&#xA;Interrupted by User&#xA;Second interrupt received; Ginkgo will run any reporting nodes but will skip all remaining specs and cleanup nodes.  Interrupt again to bail immediately.&#xA;Here&#39;s a current progress report:&#xA;  VirtualMachineRestoreForce When the virtualization resources are applied checks the resources phase (Spec Runtime: 6m17.35s)&#xA;    /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:111&#xA;    In [AfterEach] (Node Runtime: 2.876s)&#xA;      /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:71&#xA;&#xA;    Spec Goroutine&#xA;    goroutine 456 [syscall]&#xA;      syscall.syscall6(0x10090dc70?, 0x110a8eaf0?, 0x1052505c0?, 0x90?, 0x14000500808?, 0x14000882b40?, 0x1400002eb08?)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/runtime/sys_darwin.go:60&#xA;      syscall.wait4(0x1400002eb38?, 0x100f626fc?, 0x90?, 0x102f5e120?)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/syscall/zsyscall_darwin_arm64.go:44&#xA;      syscall.Wait4(0x14000490b60?, 0x1400002eb74, 0x1400090dc70?, 0x14000490a10?)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/syscall/syscall_bsd.go:144&#xA;      os.(*Process).pidWait.func1(...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec_unix.go:64&#xA;      os.ignoringEINTR2[...](...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file_posix.go:266&#xA;      os.(*Process).pidWait(0x14000597200)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec_unix.go:63&#xA;      os.(*Process).wait(0x140008c4c08?)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec_unix.go:28&#xA;      os.(*Process).Wait(...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec.go:340&#xA;      os/exec.(*Cmd).Wait(0x140008c0180)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:922&#xA;      os/exec.(*Cmd).Run(0x140008c0180)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:626&#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e/executor.CMDExecutor.ExecuteContext({{0x140002a34f0?, 0x102ff5e88?, 0x14000490850?}}, {0x103016488?, 0x14000490850?}, {0x14000884540?, 0xc23316908cec3270?}, {0x102feed80, 0x14000597080}, {0x102feed80, ...})&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/executor/executor.go:76&#xA;          | &#x9;cmd.Stderr = stderr&#xA;          | &#x9;cmd.Stdout = stdout&#xA;          &gt; &#x9;return cmd.Run()&#xA;          | }&#xA;          | &#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e/executor.CMDExecutor.ExecContext({{0x140002a34f0?, 0x104503728?, 0x1044d9fa0?}}, {0x103016488, 0x14000490850}, {0x14000884540, 0xb5})&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/executor/executor.go:49&#xA;          | stdout := new(Buffer)&#xA;          | stderr := new(Buffer)&#xA;          &gt; err := e.ExecuteContext(ctx, command, stdout, stderr)&#xA;          | cmdResult := &amp;CMDResult{&#xA;          | &#x9;stdOut:  stdout,&#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e/kubectl.KubectlCMD.Get({{0x10301aa38?, 0x1400000fde8?}, {0x102633fba?, 0x140004373b0?}}, {0x10268b2e2, 0x31}, {{0x0, 0x0, 0x0}, 0x0, ...})&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/kubectl/kubectl.go:208&#xA;          | &#x9;ctx, cancel := context.WithTimeout(context.Background(), MediumTimeout)&#xA;          | &#x9;defer cancel()&#xA;          &gt; &#x9;return k.ExecContext(ctx, cmd)&#xA;          | }&#xA;          | &#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e.SaveTestCaseResources(0x1400070b350, {0x14000a15c40, 0x1a}, {0x14000bebd70, 0x29}, {0x102630370, 0x4})&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:765&#xA;          | errorFileName := fmt.Sprintf(&#34;%s/e2e_failed__%s__%s_error.txt&#34;, dumpPath, labels[&#34;testcase&#34;], additional)&#xA;          | &#xA;          &gt; cmdr := kubectl.Get(&#xA;          | &#x9;&#34;virtualization,cvi,vmc,intvirt,pod,volumesnapshot&#34;,&#xA;          | &#x9;kc.GetOptions{&#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e.SaveTestCaseDump(0x1400070b350, {0x102655aa3, 0x1a}, {0x14000bebd70, 0x29})&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:757&#xA;          | &#x9;}&#xA;          | &#xA;          &gt; &#x9;SaveTestCaseResources(labels, additional, namespace, tmpDir)&#xA;          | &#x9;SavePodLogsAndDescriptions(labels, additional, namespace, tmpDir)&#xA;          | }&#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e.init.func22.3()&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:73&#xA;          | AfterEach(func() {&#xA;          | &#x9;if CurrentSpecReport().Failed() {&#xA;          &gt; &#x9;&#x9;SaveTestCaseDump(testCaseLabel, CurrentSpecReport().LeafNodeText, namespace)&#xA;          | &#x9;}&#xA;          | &#xA;      github.com/onsi/ginkgo/v2/internal.extractBodyFunction.func3({0x0?, 0x0?})&#xA;        /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/node.go:475&#xA;      github.com/onsi/ginkgo/v2/internal.(*Suite).runNode.func3()&#xA;        /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/suite.go:894&#xA;      github.com/onsi/ginkgo/v2/internal.(*Suite).runNode in goroutine 5&#xA;        /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/suite.go:881&#xA;&#xA;    Goroutines of Interest&#xA;    goroutine 508 [sync.WaitGroup.Wait, 6 minutes]&#xA;      sync.runtime_SemacquireWaitGroup(0x100ee0b30?, 0x80?)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/runtime/sema.go:114&#xA;      sync.(*WaitGroup).Wait(0x14000b871d0)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/sync/waitgroup.go:206&#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e.WaitResources({0x14000956de0, 0x2, 0x102959e58?}, {0x102676a2d, 0x2a}, {{0x0, 0x0, 0x0}, 0x1400070b350, {0x14000bebd70, ...}, ...})&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:349&#xA;          | &#x9;&#x9;}()&#xA;          | &#x9;}&#xA;          &gt; &#x9;wg.Wait()&#xA;          | &#x9;Expect(waitErr).To(BeEmpty(), &#34;should observe resources in &#39;%s&#39; state before %s timeout&#34;, opts.For, opts.Timeout.String())&#xA;          | }&#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e.WaitByLabel({0x102676a2d, 0x2a}, {{0x0, 0x0, 0x0}, 0x1400070b350, {0x14000bebd70, 0x29}, {0x140007f1320, 0x22}, ...})&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:308&#xA;          | &#x9;&#x9;resources = strings.Split(res.StdOut(), &#34; &#34;)&#xA;          | &#x9;}&#xA;          &gt; &#x9;WaitResources(resources, resource, opts)&#xA;          | }&#xA;          | &#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e.WaitPhaseByLabel({0x102676a2d, 0x2a}, {0x102633a0a, 0x7}, {{0x0, 0x0, 0x0}, 0x1400070b350, {0x14000bebd70, 0x29}, ...})&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:290&#xA;          | &#x9;GinkgoHelper()&#xA;          | &#x9;opts.For = fmt.Sprintf(&#34;&#39;jsonpath={.status.phase}=%s&#39;&#34;, phase)&#xA;          &gt; &#x9;WaitByLabel(resource, opts)&#xA;          | }&#xA;          | &#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e.WaitVMAgentReady({{0x0, 0x0, 0x0}, 0x1400070b350, {0x14000bebd70, 0x29}, {0x0, 0x0}, 0xe8d4a51000})&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:274&#xA;          | func WaitVMAgentReady(opts kc.WaitOptions) {&#xA;          | &#x9;GinkgoHelper()&#xA;          &gt; &#x9;WaitPhaseByLabel(kc.ResourceVM, PhaseRunning, opts)&#xA;          | &#x9;WaitConditionIsTrueByLabel(kc.ResourceVM, vmcondition.TypeAgentReady.String(), opts)&#xA;          | }&#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e.init.func22.4.2.1()&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:113&#xA;          | It(&#34;checks the resources phase&#34;, func() {&#xA;          | &#x9;By(&#34;`VirtualMachine` agent should be ready&#34;, func() {&#xA;          &gt; &#x9;&#x9;WaitVMAgentReady(kc.WaitOptions{&#xA;          | &#x9;&#x9;&#x9;Labels:    testCaseLabel,&#xA;          | &#x9;&#x9;&#x9;Namespace: namespace,&#xA;      github.com/onsi/ginkgo/v2/internal.(*Suite).By(0x140000fd508, {0x10266ddb1, 0x26}, {0x14000b79f48, 0x1, 0x1025c3614?})&#xA;        /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/suite.go:323&#xA;      github.com/onsi/ginkgo/v2.By({0x10266ddb1?, 0x102ff5eb0?}, {0x14000918748?, 0x1400049a410?, 0x14000918758?})&#xA;        /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/core_dsl.go:600&#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e.init.func22.4.2()&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:112&#xA;          | &#xA;          | It(&#34;checks the resources phase&#34;, func() {&#xA;          &gt; &#x9;By(&#34;`VirtualMachine` agent should be ready&#34;, func() {&#xA;          | &#x9;&#x9;WaitVMAgentReady(kc.WaitOptions{&#xA;          | &#x9;&#x9;&#x9;Labels:    testCaseLabel,&#xA;      github.com/onsi/ginkgo/v2/internal.extractBodyFunction.func3({0x0?, 0x0?})&#xA;        /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/node.go:475&#xA;      github.com/onsi/ginkgo/v2/internal.(*Suite).runNode.func3()&#xA;        /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/suite.go:894&#xA;      github.com/onsi/ginkgo/v2/internal.(*Suite).runNode in goroutine 5&#xA;        /Users/antont/go/pkg/mod/github.com/onsi/ginkgo/v2@v2.22.0/internal/suite.go:881&#xA;&#xA;    goroutine 512 [syscall, 6 minutes]&#xA;      syscall.syscall6(0x90010100954030?, 0x110a7faa0?, 0x105250f30?, 0x90?, 0x14000580008?, 0x14000968000?, 0x1400071fa58?)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/runtime/sys_darwin.go:60&#xA;      syscall.wait4(0x1400071fa88?, 0x100f626fc?, 0x90?, 0x102f5e120?)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/syscall/zsyscall_darwin_arm64.go:44&#xA;      syscall.Wait4(0x14000270380?, 0x1400071fac4, 0x14000954030?, 0x140002702a0?)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/syscall/syscall_bsd.go:144&#xA;      os.(*Process).pidWait.func1(...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec_unix.go:64&#xA;      os.ignoringEINTR2[...](...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file_posix.go:266&#xA;      os.(*Process).pidWait(0x14000434900)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec_unix.go:63&#xA;      os.(*Process).wait(0x1400090a408?)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec_unix.go:28&#xA;      os.(*Process).Wait(...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec.go:340&#xA;      os/exec.(*Cmd).Wait(0x14000908000)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:922&#xA;      os/exec.(*Cmd).Run(0x14000908000)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:626&#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e/executor.CMDExecutor.ExecuteContext({{0x140002a34f0?, 0x102ff5e88?, 0x14000270000?}}, {0x103016488?, 0x14000270000?}, {0x14000e3a0d0?, 0xc233172ab5e082d0?}, {0x102feed80, 0x14000434800}, {0x102feed80, ...})&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/executor/executor.go:76&#xA;          | &#x9;cmd.Stderr = stderr&#xA;          | &#x9;cmd.Stdout = stdout&#xA;          &gt; &#x9;return cmd.Run()&#xA;          | }&#xA;          | &#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e/executor.CMDExecutor.ExecContext({{0x140002a34f0?, 0x104503728?, 0x1044d9fa0?}}, {0x103016488, 0x14000270000}, {0x14000e3a0d0, 0xd0})&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/executor/executor.go:49&#xA;          | stdout := new(Buffer)&#xA;          | stderr := new(Buffer)&#xA;          &gt; err := e.ExecuteContext(ctx, command, stdout, stderr)&#xA;          | cmdResult := &amp;CMDResult{&#xA;          | &#x9;stdOut:  stdout,&#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e/kubectl.KubectlCMD.WaitResource({{0x10301aa38?, 0x1400000fde8?}, {0x102633fba?, 0x1400071fe88?}}, {0x102676a2d, 0x2a}, {0x14000b56a00, 0x28}, {{0x0, 0x0, ...}, ...})&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/kubectl/kubectl.go:260&#xA;          | &#x9;ctx, cancel := context.WithTimeout(context.Background(), timeout)&#xA;          | &#x9;defer cancel()&#xA;          &gt; &#x9;return k.ExecContext(ctx, cmd)&#xA;          | }&#xA;          | &#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e.WaitResources.func1()&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:341&#xA;          | go func() {&#xA;          | &#x9;defer wg.Done()&#xA;          &gt; &#x9;res := kubectl.WaitResource(resource, name, waitOpts)&#xA;          | &#x9;if res.Error() != nil {&#xA;          | &#x9;&#x9;mu.Lock()&#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e.WaitResources in goroutine 508&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:339&#xA;          | for _, name := range resources {&#xA;          | &#x9;wg.Add(1)&#xA;          &gt; &#x9;go func() {&#xA;          | &#x9;&#x9;defer wg.Done()&#xA;          | &#x9;&#x9;res := kubectl.WaitResource(resource, name, waitOpts)&#xA;&#xA;    goroutine 513 [syscall, 6 minutes]&#xA;      syscall.syscall6(0x10067a840?, 0x110a8eaf0?, 0x105250a78?, 0x90?, 0x140000a5008?, 0x14000882090?, 0x1400097ba58?)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/runtime/sys_darwin.go:60&#xA;      syscall.wait4(0x1400097ba88?, 0x100f626fc?, 0x90?, 0x102f5e120?)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/syscall/zsyscall_darwin_arm64.go:44&#xA;      syscall.Wait4(0x14000490380?, 0x1400097bac4, 0x1400067a840?, 0x140004902a0?)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/syscall/syscall_bsd.go:144&#xA;      os.(*Process).pidWait.func1(...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec_unix.go:64&#xA;      os.ignoringEINTR2[...](...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/file_posix.go:266&#xA;      os.(*Process).pidWait(0x14000596600)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec_unix.go:63&#xA;      os.(*Process).wait(0x140008c4408?)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec_unix.go:28&#xA;      os.(*Process).Wait(...)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec.go:340&#xA;      os/exec.(*Cmd).Wait(0x140008c0000)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:922&#xA;      os/exec.(*Cmd).Run(0x140008c0000)&#xA;        /opt/homebrew/Cellar/go/1.25.1/libexec/src/os/exec/exec.go:626&#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e/executor.CMDExecutor.ExecuteContext({{0x140002a34f0?, 0x102ff5e88?, 0x140004900e0?}}, {0x103016488?, 0x140004900e0?}, {0x140008b6000?, 0xc233172ab5e0ec48?}, {0x102feed80, 0x14000596000}, {0x102feed80, ...})&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/executor/executor.go:76&#xA;          | &#x9;cmd.Stderr = stderr&#xA;          | &#x9;cmd.Stdout = stdout&#xA;          &gt; &#x9;return cmd.Run()&#xA;          | }&#xA;          | &#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e/executor.CMDExecutor.ExecContext({{0x140002a34f0?, 0x104503728?, 0x1044d9fa0?}}, {0x103016488, 0x140004900e0}, {0x140008b6000, 0xc6})&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/executor/executor.go:49&#xA;          | stdout := new(Buffer)&#xA;          | stderr := new(Buffer)&#xA;          &gt; err := e.ExecuteContext(ctx, command, stdout, stderr)&#xA;          | cmdResult := &amp;CMDResult{&#xA;          | &#x9;stdOut:  stdout,&#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e/kubectl.KubectlCMD.WaitResource({{0x10301aa38?, 0x1400000fde8?}, {0x102633fba?, 0x14000a20f40?}}, {0x102676a2d, 0x2a}, {0x14000b56a29, 0x1e}, {{0x0, 0x0, ...}, ...})&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/kubectl/kubectl.go:260&#xA;          | &#x9;ctx, cancel := context.WithTimeout(context.Background(), timeout)&#xA;          | &#x9;defer cancel()&#xA;          &gt; &#x9;return k.ExecContext(ctx, cmd)&#xA;          | }&#xA;          | &#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e.WaitResources.func1()&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:341&#xA;          | go func() {&#xA;          | &#x9;defer wg.Done()&#xA;          &gt; &#x9;res := kubectl.WaitResource(resource, name, waitOpts)&#xA;          | &#x9;if res.Error() != nil {&#xA;          | &#x9;&#x9;mu.Lock()&#xA;    &gt; github.com/deckhouse/virtualization/tests/e2e.WaitResources in goroutine 508&#xA;        /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/util_test.go:339&#xA;          | for _, name := range resources {&#xA;          | &#x9;wg.Add(1)&#xA;          &gt; &#x9;go func() {&#xA;          | &#x9;&#x9;defer wg.Done()&#xA;          | &#x9;&#x9;res := kubectl.WaitResource(resource, name, waitOpts)&#xA;&lt; Exit [AfterEach] VirtualMachineRestoreForce - /Users/antont/ansible_deckhouse/virtualization-full/tests/e2e/vm_restore_force_test.go:71 @ 10/12/25 20:17:27.094 (2.877s)&#xA;</system-err>
          </testcase>
          <testcase name="[It] VirtualMachineRestoreForce When the virtualization resources are applied add additional interface to virtual machines [SIG-Restoration]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualMachineRestoreForce When the resources are ready to use restore the `VirtualMachines` with `forced` mode [SIG-Restoration]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualMachineRestoreForce When the resources are ready to use check the .status.networks of each VM after restore [SIG-Restoration]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualMachineRestoreForce When test is completed deletes test case resources [SIG-Restoration]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualMachineConnectivity When resources are applied result should be succeeded" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualMachineConnectivity When virtual images are applied checks VIs phases" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualMachineConnectivity When virtual disks are applied checks VDs phases" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualMachineConnectivity When virtual machines are applied checks VMs phases" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualMachineConnectivity When run curl-helper status should be in Running phase" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualMachineConnectivity When virtual machine agents are ready gets VMs and SVCs objects" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualMachineConnectivity When virtual machine agents are ready check ssh connection via `d8 v` to VMs" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualMachineConnectivity When virtual machine agents are ready checks VMs connection to external network" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualMachineConnectivity When virtual machine agents are ready check nginx status via `d8 v` on VMs" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualMachineConnectivity When virtual machine agents are ready gets page from service head-5073ae15-vm-connectivity-a" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualMachineConnectivity When virtual machine agents are ready gets page from service head-5073ae15-vm-connectivity-b" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualMachineConnectivity When virtual machine agents are ready changes selector in service head-5073ae15-vm-connectivity-a with selector from service head-5073ae15-vm-connectivity-b" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualMachineConnectivity When virtual machine agents are ready checks selector in service head-5073ae15-vm-connectivity-a" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualMachineConnectivity When virtual machine agents are ready gets page from service head-5073ae15-vm-connectivity-a" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualMachineConnectivity When virtual machine agents are ready changes back selector in service head-5073ae15-vm-connectivity-a" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualMachineConnectivity When virtual machine agents are ready checks selector in service head-5073ae15-vm-connectivity-a" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualMachineConnectivity When test is completed deletes test case resources" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualMachineLiveMigrationTCPSession checks TCP connection [SIG-Migration]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualDiskResizing When the resources are applied result should be succeeded" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualDiskResizing When the virtual images are applied checks `VirtualImages` phase" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualDiskResizing When the virtual disks are applied checks `VirtualDisks` phase" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualDiskResizing When the virtual machine are applied checks `VirtualMachine` phase" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualDiskResizing When the virtual machine are applied retrieves the test objects" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualDiskResizing When the virtual machine block device attachment is applied checks `VirtualMachineBlockDeviceAttachment` phase" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualDiskResizing Resizing When the virtual machine is ready obtains the disks metadata before resizing" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualDiskResizing Resizing When the virtual machine is ready resizes the disks" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualDiskResizing Resizing When the virtual machine is ready checks `VirtualDisks`, `VirtualMachine` and `VirtualMachineBlockDeviceAttachment` phases" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualDiskResizing Resizing When the virtual machine is ready obtains and compares the disks metadata after resizing" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualDiskResizing When test is completed deletes test case resources" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualMachineCancelMigration Cancel migrate [SIG-Migration]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] SizingPolicy When resources are applied result should be succeeded" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] SizingPolicy When virtual images are applied checks VIs phases" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] SizingPolicy When virtual disks are applied checks VDs phases with map[vm:not-existing-vmclass-with-changing] and map[vm:not-existing-vmclass-with-creating] label" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] SizingPolicy When virtual disks are applied checks VDs phases with map[vm:existing-vmclass] label" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] SizingPolicy When virtual machines are applied checks VMs phases with map[vm:not-existing-vmclass-with-changing] and map[vm:not-existing-vmclass-with-creating] label" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] SizingPolicy When virtual machines are applied checks VMs phases with map[vm:existing-vmclass] label" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] SizingPolicy Not existing virtual machine class When virtual machine with label map[vm:not-existing-vmclass-with-changing] in phase Pending checks condition status before changing &#39;virtulaMachineCLass` field with existing class" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] SizingPolicy Not existing virtual machine class When virtual machine with label map[vm:not-existing-vmclass-with-changing] in phase Pending changes VMClassName in VM specification with existing VMClass" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] SizingPolicy Not existing virtual machine class When virtual machine with label map[vm:not-existing-vmclass-with-changing] in phase Pending checks VM phase and condition status after changing" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] SizingPolicy Not existing virtual machine class When virtual machine with label map[vm:not-existing-vmclass-with-creating] in phase Pending checks condition status before creating `VirtualMachineClass`" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] SizingPolicy Not existing virtual machine class When virtual machine with label map[vm:not-existing-vmclass-with-creating] in phase Pending changes VMClassName in VM specification with not existing VMClass which have correct prefix for creating" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] SizingPolicy Not existing virtual machine class When virtual machine with label map[vm:not-existing-vmclass-with-creating] in phase Pending creates new `VirtualMachineClass`" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] SizingPolicy Not existing virtual machine class When virtual machine with label map[vm:not-existing-vmclass-with-creating] in phase Pending checks VM phase and condition after creating" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] SizingPolicy When virtual machines in phase Running checks sizing policy match" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] SizingPolicy When test is completed deletes test case resources" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualDiskAttachment When resources are applied result should be succeeded" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualDiskAttachment When virtual images are applied checks VIs phases" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualDiskAttachment When virtual disks are applied checks VDs phases" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualDiskAttachment When virtual machines are applied checks VMs phases" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualDiskAttachment Attachment When virtual machine agents are ready get disk count before attachment" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualDiskAttachment Attachment When virtual machine agents are ready attaches virtual disk" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualDiskAttachment Attachment When virtual machine agents are ready checks VM and VMBDA phases" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualDiskAttachment Attachment When virtual machine agents are ready compares disk count before and after attachment" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualDiskAttachment Detachment When virtual machines are in Running phases get disk count before detachment" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualDiskAttachment Detachment When virtual machines are in Running phases detaches virtual disk" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualDiskAttachment Detachment When virtual machines are in Running phases checks VM phase" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualDiskAttachment Detachment When virtual machines are in Running phases compares disk count before and after detachment" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualDiskAttachment When test is completed deletes test case resources" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualMachineMigration When resources are applied result should be succeeded [SIG-Migration]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualMachineMigration When virtual machines are applied checks VMs phases [SIG-Migration]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualMachineMigration When virtual machine agents are ready starts migrations [SIG-Migration]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualMachineMigration When VMs migrations are applied checks VMs and VMOPs phases [SIG-Migration]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualMachineMigration When VMs migrations are applied checks VMs external connection after migrations [SIG-Migration]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualMachineMigration When test is completed deletes test case resources [SIG-Migration]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualMachineVersions When virtualization resources are applied: result should be succeeded" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualMachineVersions When virtual disks are applied: checks VDs phases" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualMachineVersions When virtual machines are applied: checks VMs phases" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualMachineVersions When virtual machines are ready: has qemu version in the status" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualMachineVersions When virtual machines are ready: has libvirt version in the status" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] VirtualMachineVersions When test is completed deletes test case resources" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] [sig-storage] LocalVirtualDiskMigration should be successful when only root disk on local storage [SIG-Storage]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] [sig-storage] LocalVirtualDiskMigration should be successful when root disk on local storage and one additional disk [SIG-Storage]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] [sig-storage] LocalVirtualDiskMigration should be successful when only additional disk on local storage [SIG-Storage]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] [sig-storage] LocalVirtualDiskMigration should be reverted when only root disk on local storage [SIG-Storage]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] [sig-storage] LocalVirtualDiskMigration should be reverted when root disk on local storage and one additional disk [SIG-Storage]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] [sig-storage] LocalVirtualDiskMigration should be reverted when only additional disk on local storage [SIG-Storage]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] [sig-storage] LocalVirtualDiskMigration should be successful two migrations in a row [SIG-Storage]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] [sig-storage] LocalVirtualDiskMigration should be reverted first and completed second [SIG-Storage]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] [sig-storage] LocalVirtualDiskMigration should be reverted because virtual machine stopped when virtual machine deleting [SIG-Storage]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] [sig-storage] LocalVirtualDiskMigration should be reverted because virtual machine stopped when virtual machine stopped from OS [SIG-Storage]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] [sig-storage] LocalVirtualDiskMigration Migrate to not matched node should reverted because migration canceled when pod pending [SIG-Storage]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[It] [sig-storage] LocalVirtualDiskMigration should be failed with RWO VMBDA [SIG-Storage]" classname="Tests" status="skipped" time="0">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[SynchronizedAfterSuite]" classname="Tests" status="skipped" time="4.58e-07">
              <skipped message="skipped"></skipped>
          </testcase>
          <testcase name="[DeferCleanup (Suite)]" classname="Tests" status="skipped" time="1.66e-07">
              <skipped message="skipped"></skipped>
          </testcase>
      </testsuite>
  </testsuites>
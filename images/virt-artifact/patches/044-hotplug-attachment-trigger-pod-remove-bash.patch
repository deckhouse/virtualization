diff --git a/pkg/virt-controller/services/template.go b/pkg/virt-controller/services/template.go
index 1221448946..39ffaba6c7 100644
--- a/pkg/virt-controller/services/template.go
+++ b/pkg/virt-controller/services/template.go
@@ -88,16 +88,20 @@ const (
 	varLibSWTPMLocalCAVolumeName = "var-lib-swtpm-localca"
 )
 
-const KvmDevice = "devices.virtualization.deckhouse.io/kvm"
-const TunDevice = "devices.virtualization.deckhouse.io/tun"
-const VhostNetDevice = "devices.virtualization.deckhouse.io/vhost-net"
-const SevDevice = "devices.virtualization.deckhouse.io/sev"
-const VhostVsockDevice = "devices.virtualization.deckhouse.io/vhost-vsock"
-const PrDevice = "devices.virtualization.deckhouse.io/pr-helper"
+const (
+	KvmDevice        = "devices.virtualization.deckhouse.io/kvm"
+	TunDevice        = "devices.virtualization.deckhouse.io/tun"
+	VhostNetDevice   = "devices.virtualization.deckhouse.io/vhost-net"
+	SevDevice        = "devices.virtualization.deckhouse.io/sev"
+	VhostVsockDevice = "devices.virtualization.deckhouse.io/vhost-vsock"
+	PrDevice         = "devices.virtualization.deckhouse.io/pr-helper"
+)
 
-const debugLogs = "debugLogs"
-const logVerbosity = "logVerbosity"
-const virtiofsDebugLogs = "virtiofsdDebugLogs"
+const (
+	debugLogs         = "debugLogs"
+	logVerbosity      = "logVerbosity"
+	virtiofsDebugLogs = "virtiofsdDebugLogs"
+)
 
 const qemuTimeoutJitterRange = 120
 
@@ -115,14 +119,18 @@ const IntelVendorName = "Intel"
 // Istio list of virtual interfaces whose inbound traffic (from VM) will be treated as outbound traffic in envoy
 const ISTIO_KUBEVIRT_ANNOTATION = "traffic.sidecar.istio.io/kubevirtInterfaces"
 
-const VELERO_PREBACKUP_HOOK_CONTAINER_ANNOTATION = "pre.hook.backup.velero.io/container"
-const VELERO_PREBACKUP_HOOK_COMMAND_ANNOTATION = "pre.hook.backup.velero.io/command"
-const VELERO_POSTBACKUP_HOOK_CONTAINER_ANNOTATION = "post.hook.backup.velero.io/container"
-const VELERO_POSTBACKUP_HOOK_COMMAND_ANNOTATION = "post.hook.backup.velero.io/command"
+const (
+	VELERO_PREBACKUP_HOOK_CONTAINER_ANNOTATION  = "pre.hook.backup.velero.io/container"
+	VELERO_PREBACKUP_HOOK_COMMAND_ANNOTATION    = "pre.hook.backup.velero.io/command"
+	VELERO_POSTBACKUP_HOOK_CONTAINER_ANNOTATION = "post.hook.backup.velero.io/container"
+	VELERO_POSTBACKUP_HOOK_COMMAND_ANNOTATION   = "post.hook.backup.velero.io/command"
+)
 
-const ENV_VAR_LIBVIRT_DEBUG_LOGS = "LIBVIRT_DEBUG_LOGS"
-const ENV_VAR_VIRTIOFSD_DEBUG_LOGS = "VIRTIOFSD_DEBUG_LOGS"
-const ENV_VAR_VIRT_LAUNCHER_LOG_VERBOSITY = "VIRT_LAUNCHER_LOG_VERBOSITY"
+const (
+	ENV_VAR_LIBVIRT_DEBUG_LOGS          = "LIBVIRT_DEBUG_LOGS"
+	ENV_VAR_VIRTIOFSD_DEBUG_LOGS        = "VIRTIOFSD_DEBUG_LOGS"
+	ENV_VAR_VIRT_LAUNCHER_LOG_VERBOSITY = "VIRT_LAUNCHER_LOG_VERBOSITY"
+)
 
 const ENV_VAR_POD_NAME = "POD_NAME"
 
@@ -208,7 +216,8 @@ func modifyNodeAffintyToRejectLabel(origAffinity *k8sv1.Affinity, labelToReject
 		Operator: k8sv1.NodeSelectorOpDoesNotExist,
 	}
 	term := k8sv1.NodeSelectorTerm{
-		MatchExpressions: []k8sv1.NodeSelectorRequirement{requirement}}
+		MatchExpressions: []k8sv1.NodeSelectorRequirement{requirement},
+	}
 
 	nodeAffinity := &k8sv1.NodeAffinity{
 		RequiredDuringSchedulingIgnoredDuringExecution: &k8sv1.NodeSelector{
@@ -229,7 +238,6 @@ func modifyNodeAffintyToRejectLabel(origAffinity *k8sv1.Affinity, labelToReject
 				NodeSelectorTerms: []k8sv1.NodeSelectorTerm{term},
 			}
 		}
-
 	} else if affinity != nil {
 		affinity.NodeAffinity = nodeAffinity
 	} else {
@@ -382,11 +390,12 @@ func (t *templateService) renderLaunchManifest(vmi *v1.VirtualMachineInstance, i
 	if tempPod {
 		logger := log.DefaultLogger()
 		logger.Infof("RUNNING doppleganger pod for %s", vmi.Name)
-		command = []string{"/bin/bash",
-			"-c",
-			"echo", "bound PVCs"}
+		command = []string{
+			"temp_pod",
+		}
 	} else {
-		command = []string{"/usr/bin/virt-launcher-monitor",
+		command = []string{
+			"/usr/bin/virt-launcher-monitor",
 			"--qemu-timeout", generateQemuTimeoutWithJitter(t.launcherQemuTimeout),
 			"--name", domain,
 			"--uid", string(vmi.UID),
@@ -501,7 +510,7 @@ func (t *templateService) renderLaunchManifest(vmi *v1.VirtualMachineInstance, i
 			volumeSource := k8sv1.VolumeSource{
 				ConfigMap: &k8sv1.ConfigMapVolumeSource{
 					LocalObjectReference: k8sv1.LocalObjectReference{Name: cm.Name},
-					DefaultMode:          pointer.Int32(0755),
+					DefaultMode:          pointer.Int32(0o755),
 				},
 			}
 			vol := k8sv1.Volume{
@@ -544,7 +553,8 @@ func (t *templateService) renderLaunchManifest(vmi *v1.VirtualMachineInstance, i
 	var initContainers []k8sv1.Container
 
 	if HaveContainerDiskVolume(vmi.Spec.Volumes) || util.HasKernelBootContainerImage(vmi) {
-		initContainerCommand := []string{"/usr/bin/cp",
+		initContainerCommand := []string{
+			"/usr/bin/cp",
 			"/usr/bin/container-disk",
 			"/init/usr/bin/container-disk",
 		}
@@ -819,7 +829,6 @@ func (t *templateService) newVolumeRenderer(vmi *v1.VirtualMachineInstance, name
 		t.containerDiskDir,
 		t.virtShareDir,
 		volumeOpts...)
-
 	if err != nil {
 		return nil, err
 	}
@@ -921,7 +930,7 @@ func (t *templateService) RenderHotplugAttachmentPodTemplate(volumes []*v1.Volum
 	zero := int64(0)
 	runUser := int64(util.NonRootUID)
 	sharedMount := k8sv1.MountPropagationHostToContainer
-	command := []string{"/bin/sh", "-c", "/usr/bin/container-disk --copy-path /path/hp"}
+	command := []string{"/usr/bin/container-disk", "--copy-path", "/path/hp"}
 
 	tmpTolerations := make([]k8sv1.Toleration, len(ownerPod.Spec.Tolerations))
 	copy(tmpTolerations, ownerPod.Spec.Tolerations)
@@ -1005,7 +1014,8 @@ func (t *templateService) RenderHotplugAttachmentPodTemplate(volumes []*v1.Volum
 		if first {
 			first = false
 			userId := int64(util.NonRootUID)
-			initContainerCommand := []string{"/usr/bin/cp",
+			initContainerCommand := []string{
+				"/usr/bin/cp",
 				"/usr/bin/container-disk",
 				"/init/usr/bin/container-disk",
 			}
@@ -1076,11 +1086,9 @@ func (t *templateService) RenderHotplugAttachmentTriggerPodTemplate(volume *v1.V
 	sharedMount := k8sv1.MountPropagationHostToContainer
 	var command []string
 	if tempPod {
-		command = []string{"/bin/bash",
-			"-c",
-			"exit", "0"}
+		command = []string{"temp_pod"}
 	} else {
-		command = []string{"/bin/sh", "-c", "/usr/bin/container-disk --copy-path /path/hp"}
+		command = []string{"/usr/bin/container-disk", "--copy-path", "/path/hp"}
 	}
 
 	annotationsList := make(map[string]string)
@@ -1251,8 +1259,10 @@ func appendUniqueImagePullSecret(secrets []k8sv1.LocalObjectReference, newsecret
 // The virtProbeTotalAdditionalOverhead is added for the virt-probe binary we use for probing and
 // only added once, while the virtProbeOverhead is the general memory consumption of virt-probe
 // that we add per added probe.
-var virtProbeTotalAdditionalOverhead = resource.MustParse("100Mi")
-var virtProbeOverhead = resource.MustParse("10Mi")
+var (
+	virtProbeTotalAdditionalOverhead = resource.MustParse("100Mi")
+	virtProbeOverhead                = resource.MustParse("10Mi")
+)
 
 func addProbeOverheads(vmi *v1.VirtualMachineInstance, to *resource.Quantity) {
 	hasLiveness := addProbeOverhead(vmi.Spec.LivenessProbe, to)
@@ -1308,7 +1318,6 @@ func NewTemplateService(launcherImage string,
 	namespaceStore cache.Store,
 	opts ...templateServiceOption,
 ) TemplateService {
-
 	precond.MustNotBeEmpty(launcherImage)
 	log.Log.V(1).Infof("Exporter Image: %s", exporterImage)
 	svc := templateService{
diff --git a/pkg/virt-controller/watch/vmi_test.go b/pkg/virt-controller/watch/vmi_test.go
index b4b76bd73e..2d494d1c3b 100644
--- a/pkg/virt-controller/watch/vmi_test.go
+++ b/pkg/virt-controller/watch/vmi_test.go
@@ -183,7 +183,8 @@ var _ = Describe("VirtualMachineInstance watcher", func() {
 			ContainElement(
 				MatchFields(IgnoreExtras, Fields{
 					"Type":   BeEquivalentTo(virtv1.VirtualMachineInstanceDataVolumesReady),
-					"Status": BeEquivalentTo(expectedStatus)},
+					"Status": BeEquivalentTo(expectedStatus),
+				},
 				),
 			),
 		)
@@ -347,7 +348,6 @@ var _ = Describe("VirtualMachineInstance watcher", func() {
 	}
 
 	Context("On valid VirtualMachineInstance given with DataVolume source", func() {
-
 		dvVolumeSource := virtv1.VolumeSource{
 			DataVolume: &virtv1.DataVolumeSource{
 				Name: "test1",
@@ -400,7 +400,7 @@ var _ = Describe("VirtualMachineInstance watcher", func() {
 
 					return ""
 				},
-				Equal("/bin/bash -c echo bound PVCs"),
+				Equal("temp_pod"),
 			)
 
 			controller.Execute()
@@ -533,13 +533,14 @@ var _ = Describe("VirtualMachineInstance watcher", func() {
 			},
 			Entry("fail if pod in failed state", k8sv1.PodFailed, nil, virtv1.Failed),
 			Entry("do nothing if pod succeed", k8sv1.PodSucceeded, nil, virtv1.Pending),
-			//The PodReasonUnschedulable is a transient condition. It can clear up if more resources are added to the cluster
+			// The PodReasonUnschedulable is a transient condition. It can clear up if more resources are added to the cluster
 			Entry("do nothing if pod Pending Unschedulable",
 				k8sv1.PodPending,
 				[]k8sv1.PodCondition{{
 					Type:   k8sv1.PodScheduled,
 					Status: k8sv1.ConditionFalse,
-					Reason: k8sv1.PodReasonUnschedulable}}, virtv1.Pending),
+					Reason: k8sv1.PodReasonUnschedulable,
+				}}, virtv1.Pending),
 		)
 
 		It("should not create a corresponding Pod on VMI creation when DataVolume is pending", func() {
@@ -616,12 +617,10 @@ var _ = Describe("VirtualMachineInstance watcher", func() {
 				testutils.ExpectEvent(recorder, kvcontroller.SuccessfulCreatePodReason)
 				expectMatchingPodCreation(vmi)
 			})
-
 		})
 	})
 
 	Context("On valid VirtualMachineInstance given with PVC source, ownedRef of DataVolume", func() {
-
 		pvcVolumeSource := virtv1.VolumeSource{
 			PersistentVolumeClaim: &virtv1.PersistentVolumeClaimVolumeSource{PersistentVolumeClaimVolumeSource: k8sv1.PersistentVolumeClaimVolumeSource{
 				ClaimName: "test1",
@@ -676,7 +675,7 @@ var _ = Describe("VirtualMachineInstance watcher", func() {
 
 					return ""
 				},
-				Equal("/bin/bash -c echo bound PVCs"))
+				Equal("temp_pod"))
 			expectMatchingPodCreation(vmi, IsPodWithoutVmPayload)
 			expectVMIWithMatcherConditions(vmi.Namespace, vmi.Name, ContainElement(MatchFields(IgnoreExtras,
 				Fields{"Type": Equal(virtv1.VirtualMachineInstanceProvisioning)})),
@@ -742,7 +741,6 @@ var _ = Describe("VirtualMachineInstance watcher", func() {
 			testutils.ExpectEvent(recorder, kvcontroller.SuccessfulDeletePodReason)
 			expectPodDoesNotExist(pod.Namespace, pod.Name)
 			expectVMIDataVolumeReadyCondition(vmi.Namespace, vmi.Name, k8sv1.ConditionTrue)
-
 		})
 
 		It("should not create a corresponding Pod on VMI creation when DataVolume is pending", func() {
@@ -782,7 +780,6 @@ var _ = Describe("VirtualMachineInstance watcher", func() {
 			testutils.ExpectEvent(recorder, kvcontroller.SuccessfulCreatePodReason)
 			expectMatchingPodCreation(vmi)
 		})
-
 	})
 
 	Context("with network-status annotation", func() {
@@ -1079,7 +1076,6 @@ var _ = Describe("VirtualMachineInstance watcher", func() {
 		})
 		DescribeTable("should never proceed to creating the launcher pod if not all PVCs are there to determine if they are WFFC and/or an import is done",
 			func(syncReason string, volumeSource virtv1.VolumeSource) {
-
 				expectConditions := func(vmi *virtv1.VirtualMachineInstance) {
 					// PodScheduled and Synchronized (as well as Ready)
 					Expect(vmi.Status.Conditions).To(HaveLen(3), "there should be exactly 3 conditions")
@@ -1925,7 +1921,6 @@ var _ = Describe("VirtualMachineInstance watcher", func() {
 		})
 
 		Context("should update pod labels", func() {
-
 			type testData struct {
 				vmiLabels      map[string]string
 				podLabels      map[string]string
@@ -2916,10 +2911,12 @@ var _ = Describe("VirtualMachineInstance watcher", func() {
 			pvc := &k8sv1.PersistentVolumeClaim{
 				TypeMeta: metav1.TypeMeta{
 					Kind:       "PersistentVolumeClaim",
-					APIVersion: "v1"},
+					APIVersion: "v1",
+				},
 				ObjectMeta: metav1.ObjectMeta{
 					Namespace: "test",
-					Name:      "test"},
+					Name:      "test",
+				},
 				Spec: k8sv1.PersistentVolumeClaimSpec{},
 			}
 
@@ -2996,18 +2993,22 @@ var _ = Describe("VirtualMachineInstance watcher", func() {
 			existingPVC := &k8sv1.PersistentVolumeClaim{
 				TypeMeta: metav1.TypeMeta{
 					Kind:       "PersistentVolumeClaim",
-					APIVersion: "v1"},
+					APIVersion: "v1",
+				},
 				ObjectMeta: metav1.ObjectMeta{
 					Namespace: vmi.Namespace,
-					Name:      "existing"},
+					Name:      "existing",
+				},
 			}
 			hpPVC := &k8sv1.PersistentVolumeClaim{
 				TypeMeta: metav1.TypeMeta{
 					Kind:       "PersistentVolumeClaim",
-					APIVersion: "v1"},
+					APIVersion: "v1",
+				},
 				ObjectMeta: metav1.ObjectMeta{
 					Namespace: vmi.Namespace,
-					Name:      "hotplug"},
+					Name:      "hotplug",
+				},
 				Status: k8sv1.PersistentVolumeClaimStatus{
 					Phase: k8sv1.ClaimBound,
 				},
@@ -3098,18 +3099,22 @@ var _ = Describe("VirtualMachineInstance watcher", func() {
 			existingPVC := &k8sv1.PersistentVolumeClaim{
 				TypeMeta: metav1.TypeMeta{
 					Kind:       "PersistentVolumeClaim",
-					APIVersion: "v1"},
+					APIVersion: "v1",
+				},
 				ObjectMeta: metav1.ObjectMeta{
 					Namespace: vmi.Namespace,
-					Name:      "existing"},
+					Name:      "existing",
+				},
 			}
 			hpPVC := &k8sv1.PersistentVolumeClaim{
 				TypeMeta: metav1.TypeMeta{
 					Kind:       "PersistentVolumeClaim",
-					APIVersion: "v1"},
+					APIVersion: "v1",
+				},
 				ObjectMeta: metav1.ObjectMeta{
 					Namespace: vmi.Namespace,
-					Name:      "hotplug"},
+					Name:      "hotplug",
+				},
 				Status: k8sv1.PersistentVolumeClaimStatus{
 					Phase: k8sv1.ClaimBound,
 				},
@@ -3146,7 +3151,8 @@ var _ = Describe("VirtualMachineInstance watcher", func() {
 					Target: "",
 					PersistentVolumeClaimInfo: &virtv1.PersistentVolumeClaimInfo{
 						ClaimName:          "existing",
-						FilesystemOverhead: pointer.P(cdiv1.Percent("0.055"))},
+						FilesystemOverhead: pointer.P(cdiv1.Percent("0.055")),
+					},
 				},
 				{
 					Name:   "hotplug",
@@ -3263,7 +3269,6 @@ var _ = Describe("VirtualMachineInstance watcher", func() {
 	})
 
 	Context("topology hints", func() {
-
 		getVmiWithInvTsc := func() *virtv1.VirtualMachineInstance {
 			vmi := NewPendingVirtualMachine("testvmi")
 			vmi.Spec.Architecture = "amd64"
@@ -3338,13 +3343,10 @@ var _ = Describe("VirtualMachineInstance watcher", func() {
 						testutils.ExpectEvent(recorder, kvcontroller.SuccessfulCreatePodReason)
 					})
 				})
-
 			})
-
 		})
 
 		Context("pod creation", func() {
-
 			It("does not need to happen if tsc requiredment is of type RequiredForBoot", func() {
 				vmi := getVmiWithInvTsc()
 				Expect(topology.GetTscFrequencyRequirement(vmi).Type).To(Equal(topology.RequiredForBoot))
@@ -3511,15 +3513,19 @@ var _ = Describe("VirtualMachineInstance watcher", func() {
 					vmi = api.NewMinimalVMI(vmName)
 					vmi.Spec.Domain.Devices.Interfaces = []virtv1.Interface{{
 						Name:                   "red",
-						InterfaceBindingMethod: virtv1.InterfaceBindingMethod{Bridge: &virtv1.InterfaceBridge{}}}, {
+						InterfaceBindingMethod: virtv1.InterfaceBindingMethod{Bridge: &virtv1.InterfaceBridge{}},
+					}, {
 						Name:                   "blue",
-						InterfaceBindingMethod: virtv1.InterfaceBindingMethod{Bridge: &virtv1.InterfaceBridge{}}}}
+						InterfaceBindingMethod: virtv1.InterfaceBindingMethod{Bridge: &virtv1.InterfaceBridge{}},
+					}}
 
 					vmi.Spec.Networks = []virtv1.Network{{
 						Name:          "red",
-						NetworkSource: virtv1.NetworkSource{Multus: &virtv1.MultusNetwork{NetworkName: "red-net"}}}, {
+						NetworkSource: virtv1.NetworkSource{Multus: &virtv1.MultusNetwork{NetworkName: "red-net"}},
+					}, {
 						Name:          "blue",
-						NetworkSource: virtv1.NetworkSource{Multus: &virtv1.MultusNetwork{NetworkName: "blue-net"}}}}
+						NetworkSource: virtv1.NetworkSource{Multus: &virtv1.MultusNetwork{NetworkName: "blue-net"}},
+					}}
 
 					pod, err := NewPodForVirtualMachineWithMultusAnnotations(vmi, k8sv1.PodRunning, config, testPodNetworkStatus...)
 					Expect(err).ToNot(HaveOccurred())
@@ -3631,7 +3637,6 @@ var _ = Describe("VirtualMachineInstance watcher", func() {
 	})
 
 	Context("Aggregating DataVolume conditions", func() {
-
 		dvVolumeSource1 := virtv1.VolumeSource{
 			DataVolume: &virtv1.DataVolumeSource{
 				Name: "test1",
@@ -3785,7 +3790,6 @@ var _ = Describe("VirtualMachineInstance watcher", func() {
 				"Not all of the VMI's DVs are ready",
 			),
 		)
-
 	})
 })
 
@@ -3915,7 +3919,8 @@ func NewPvc(namespace string, name string) *k8sv1.PersistentVolumeClaim {
 	return &k8sv1.PersistentVolumeClaim{
 		TypeMeta: metav1.TypeMeta{
 			Kind:       "PersistentVolumeClaim",
-			APIVersion: "v1"},
+			APIVersion: "v1",
+		},
 		ObjectMeta: metav1.ObjectMeta{
 			Namespace: namespace,
 			Name:      name,
@@ -3927,7 +3932,8 @@ func NewPvcWithOwner(namespace string, name string, ownerName string, isControll
 	return &k8sv1.PersistentVolumeClaim{
 		TypeMeta: metav1.TypeMeta{
 			Kind:       "PersistentVolumeClaim",
-			APIVersion: "v1"},
+			APIVersion: "v1",
+		},
 		ObjectMeta: metav1.ObjectMeta{
 			Namespace: namespace,
 			Name:      name,
@@ -3975,7 +3981,7 @@ func setDataVolumeCondition(dv *cdiv1.DataVolume, cond cdiv1.DataVolumeCondition
 func NewNodeForPod(pod *k8sv1.Pod) *k8sv1.Node {
 	return &k8sv1.Node{
 		ObjectMeta: metav1.ObjectMeta{
-			Name:      pod.Spec.NodeName,
+			Name: pod.Spec.NodeName,
 		},
 	}
 }
@@ -4123,7 +4129,6 @@ func addVolumeStatuses(vmi *virtv1.VirtualMachineInstance, volumeStatuses ...vir
 }
 
 func addActivePods(vmi *virtv1.VirtualMachineInstance, podUID types.UID, hostName string) *virtv1.VirtualMachineInstance {
-
 	if vmi.Status.ActivePods != nil {
 		vmi.Status.ActivePods[podUID] = hostName
 	} else {

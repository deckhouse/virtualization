# https://taskfile.dev

version: "3"

vars:
  NAMESPACE:
    sh: yq eval '.namespace' values.yaml
  DEFAULT_USER:
    sh: yq eval '.image.defaultUser' values.yaml
  TMP_DIR: ./tmp
  SSH_DIR: "{{ .TMP_DIR }}/ssh"
  SSH_FILE_NAME: cloud
  SSH_PUB_KEY_FILE: "{{ .SSH_DIR }}/{{ .SSH_FILE_NAME }}.pub"
  SSH_PRIV_KEY_FILE: "{{ .SSH_DIR }}/{{ .SSH_FILE_NAME }}"
  GENERATED_VALUES_FILE: tmp/generated-values.yaml
  PASSWORD_FILE: "{{ .TMP_DIR }}/password.txt"
  PASSWORD_HASH_FILE: "{{ .TMP_DIR }}/password-hash.txt"
tasks:
  default:
    silent: true
    desc: Preflight / Check if all dependencies are installed
    cmds:
      - |
        deps=("kubectl" "jq" "yq" "docker" "helm" "htpasswd")
        for dep in "${deps[@]}"; do
          if ! command -v "$dep" >/dev/null 2>&1; then
            echo "Required utility '$dep' not found!"
            exit 1
          fi
        done
        echo "All dependencies are installed!"

  password-gen:
    desc: Preflight / Generate password for admin@deckhouse.io user
    cmds:
      - mkdir -p {{ .TMP_DIR }}
      - date +%s | sha256sum | base64 | head -c 10 > {{ .PASSWORD_FILE }}
      - |
        echo $(cat {{ .TMP_DIR }}/password.txt) | htpasswd -BinC 10 "" | cut -d: -f2 | base64 -w0 > {{ .PASSWORD_HASH_FILE }}
    status:
      - test -f "{{ .PASSWORD_FILE }}"
      - test -f "{{ .PASSWORD_HASH_FILE }}"

  ssh-gen:
    desc: Preflight / Generate ssh keypair for jump-host
    cmds:
      - mkdir -p "{{ .SSH_DIR }}"
      - yes | ssh-keygen -t ed25519 -b 1024 -f {{ .SSH_PRIV_KEY_FILE }} -N "" -C "cloud" -v
      - chmod 0600 "{{ .SSH_PUB_KEY_FILE }}"
      - chmod 0400 "{{ .SSH_PRIV_KEY_FILE }}"
    status:
      - test -f "{{ .SSH_PRIV_KEY_FILE }}"

  render-infra:
    desc: Preparation / Generate infra manifests
    deps:
      - ssh-gen
    cmds:
      - touch {{ .GENERATED_VALUES_FILE }}
      - |
        export NEW_KUBECONFIG_B64="$(cat {{ .SSH_PUB_KEY_FILE }})"
        yq eval --inplace '.sshPublicKey = env(NEW_KUBECONFIG_B64)' {{ .GENERATED_VALUES_FILE }}
      - |
        export DOMAIN=$(kubectl get mc global -o json | jq '.spec.settings.modules.publicDomainTemplate | split(".")[1:] | join(".")')
        yq eval --inplace '.domain = env(DOMAIN)' {{ .GENERATED_VALUES_FILE }}
      - helm template dvp-over-dvp-infra ./charts/infra -f values.yaml -f {{ .GENERATED_VALUES_FILE }} > {{ .TMP_DIR }}/infra.yaml

  infra-deploy:
    deps:
      - render-infra
    desc: Deploy infra (Namespace/RBAC/Jumphost)
    vars:
      start_time:
        sh: date +%s
    cmds:
      - kubectl apply -f {{ .TMP_DIR }}/infra.yaml
      - kubectl -n {{ .NAMESPACE }} wait --for=condition=Ready pod -l app=jump-host --timeout=300s
      # - kubectl -n {{ .NAMESPACE }} wait --for=condition=Ready pod -l app=nfs-server --timeout=300s
      - |
        export end_time=$(date +%s)
        difference=$((end_time - {{.start_time}}))
        date -ud "@$difference" +'%H:%M:%S'

  infra-undeploy:
    desc: Destroy infra (Namespace/RBAC/Jumphost/...)
    cmds:
      - kubectl delete -f {{ .TMP_DIR }}/infra.yaml || true
      - kubectl wait --for=delete namespace/{{ .NAMESPACE }} --timeout 300s || true

  render-kubeconfig:
    desc: Preparation / Generate kubeconfig (infra required)
    vars:
      SERVER:
        sh: echo https://$(kubectl -n d8-user-authn get ingress kubernetes-api -o json | jq .spec.rules[0].host -r)
      CERT:
        sh: kubectl -n d8-user-authn get secrets kubernetes-tls -o json | jq '.data."tls.crt"' -r
      TOKEN:
        sh: kubectl -n {{ .NAMESPACE }} get secret dkp-sa-secret -ojson | jq -r '.data.token' | base64 -d
    silent: true
    cmds:
      - |
        cat <<EOF > {{ .TMP_DIR }}/kubeconfig.yaml
        apiVersion: v1
        clusters:
        - cluster:
            server: {{ .SERVER }}
          name: dvp
        contexts:
        - context:
            cluster: dvp
            namespace: {{ .NAMESPACE }}
            user: {{ .NAMESPACE }}@dvp
          name: {{ .NAMESPACE }}@dvp
        current-context: {{ .NAMESPACE }}@dvp
        kind: Config
        preferences: {}
        users:
        - name: {{ .NAMESPACE }}@dvp
          user:
            token: {{ .TOKEN }}
        EOF

  render-cluster-config:
    desc: Preparation / Generate cluster config (infra required)
    deps:
      - render-kubeconfig
      - password-gen
    cmds:
      - touch {{ .GENERATED_VALUES_FILE }}
      - |
        export PASSWORD_HASH="$(cat {{ .PASSWORD_HASH_FILE }})"
        yq eval --inplace '.passwordHash = env(PASSWORD_HASH)' {{ .GENERATED_VALUES_FILE }}
      - |
        export NEW_KUBECONFIG_B64="$(cat {{ .TMP_DIR }}/kubeconfig.yaml | base64 -w 0)"
        yq eval --inplace '.kubeconfigDataBase64 = env(NEW_KUBECONFIG_B64)' {{ .GENERATED_VALUES_FILE }}
      - helm template dvp-over-dvp-cluster-config ./charts/cluster-config -f values.yaml -f {{ .GENERATED_VALUES_FILE }} > {{ .TMP_DIR }}/config.yaml

  dhctl-bootstrap:
    desc: Bootstrap DKP over DVP
    deps:
      - render-cluster-config
    vars:
      start_time:
        sh: date +%s
      JUMPHOST_EXT_IP:
        sh: kubectl -n {{ .NAMESPACE }} exec deployment/jump-host -- dig @resolver4.opendns.com myip.opendns.com +short
      JUMPHOST_NODEPORT:
        sh: kubectl -n {{ .NAMESPACE }} get svc jump-host -o json | jq ".spec.ports[] | select(.port==2222) | .nodePort"
    cmds:
      - |
        docker run --pull=always \
        -v "{{ .TMP_DIR }}/config.yaml:/config.yaml" \
        -v "{{ .SSH_DIR }}:/tmp/.ssh/" \
        -v "{{ .TMP_DIR }}/dhctl:/tmp/dhctl/" \
        dev-registry.deckhouse.io/sys/deckhouse-oss/install:{{ .DECKHOUSE_TAG }} \
            dhctl bootstrap \
            --config=/config.yaml \
            --ssh-agent-private-keys=/tmp/.ssh/{{ .SSH_FILE_NAME }} \
            --ssh-user={{ .DEFAULT_USER }} \
              --ssh-bastion-port={{ .JUMPHOST_NODEPORT }} \
              --ssh-bastion-host={{ .JUMPHOST_EXT_IP }} \
              --ssh-bastion-user=user \
            {{.CLI_ARGS}}
      - |
        export end_time=$(date +%s)
        difference=$((end_time - {{.start_time}}))
        date -ud "@$difference" +'%H:%M:%S'

  show-connection-info:
    desc: Show connection info
    vars:
      DOMAIN:
        sh: yq eval '.domain' {{ .GENERATED_VALUES_FILE }}
      PASSWORD:
        sh: cat {{ .PASSWORD_FILE }}
    silent: true
    cmds:
      - echo "Connect to master task ssh-to-master"
      - echo "Grafana URL https://grafana.{{ .NAMESPACE }}.{{ .DOMAIN }}"
      - echo "Default user/password admin@deckhouse.io/{{ .PASSWORD}}"

  install:
    cmds:
      - task: infra-deploy
      - task: dhctl-bootstrap
      - task: show-connection-info

  ssh-to-master:
    desc: ssh to master
    vars:
      MASTER_NAME:
        sh: kubectl -n {{ .NAMESPACE }} get vm -l dvp.deckhouse.io/node-group=master -o jsonpath="{.items[0].metadata.name}"
    cmds:
      - /usr/bin/ssh -i {{ .SSH_PRIV_KEY_FILE }} -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o 'ProxyCommand=d8 v port-forward --stdio=true {{ .MASTER_NAME }}.{{ .NAMESPACE }} 22' {{ .DEFAULT_USER }}@{{ .MASTER_NAME }}

  kill-dvp-resources:
    cmds:
      - kubectl -n {{ .NAMESPACE }} delete vm --all --force --grace-period=0
      - kubectl -n {{ .NAMESPACE }} delete vd --all --force --grace-period=0
      - kubectl -n {{ .NAMESPACE }} delete vmip --all --force --grace-period=0

  clean:
    cmds:
      - task: infra-undeploy
      - rm -rf "{{ .TMP_DIR }}"

  __ssh-command:
    silent: true
    internal: true
    vars:
      MASTER_NAME:
        sh: kubectl -n {{ .NAMESPACE }} get vm -l dvp.deckhouse.io/node-group=master -o jsonpath="{.items[0].metadata.name}"
    cmds:
      - /usr/bin/ssh -t -i {{ .SSH_PRIV_KEY_FILE }} -o LogLevel=ERROR -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o 'ProxyCommand=d8 v port-forward --stdio=true {{ .MASTER_NAME }}.{{ .NAMESPACE }} 22' {{ .DEFAULT_USER }}@{{ .MASTER_NAME }} {{ .CMD }}

  kubectl:
    desc: Run kubectl on master. Usage example "task kubectl -- get pods -A"
    cmds:
      - task: __ssh-command
        vars:
          CMD: sudo /opt/deckhouse/bin/kubectl {{ .CLI_ARGS }}

  k9s:
    desc: Run kubectl on master. Usage example "task kubectl -- get pods -A"
    cmds:
      - task: __ssh-command
        vars:
          CMD: TERM=xterm-256color sudo /usr/local/bin/k9s {{ .CLI_ARGS }}

  configure:cluster:sa:
    desc: Configure kubeconfig for nested cluster
    vars:
      script: gen-sa.sh
    cmds:
      - rsync -azv -e "ssh -i {{ .SSH_PRIV_KEY_FILE }} -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o 'ProxyCommand=d8 v port-forward --stdio=true master-0.{{ .NAMESPACE }} 22'" ./nested-sa-config/{{ .script }} cloud@master-0:/tmp/
      - task: __ssh-command
        vars:
          CMD: sudo chmod +x /tmp/{{ .script }}
      - task: __ssh-command
        vars:
          CMD: sudo /tmp/{{ .script }}
      - task: __ssh-command
        vars:
          CMD: sudo /opt/deckhouse/bin/kubectl apply -f {{ .config }}
